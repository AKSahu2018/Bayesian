{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Fraud Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries\n",
    "    * Libraries for data preparation\n",
    "    * Fast ML Libraries for data imputation and encoding\n",
    "        - for installing fast-ml use command \"pip install fast-ml\" in command prompt\n",
    "    * sklearn libraries for modelling, confusion matrix and prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import os, pandas and numpy\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from lightgbm import LGBMClassifier\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_ml.eda import categorical_plots,numerical_plots\n",
    "from fast_ml.missing_data_analysis import MissingDataAnalysis\n",
    "from fast_ml.missing_data_imputation import MissingDataImputer_Categorical, MissingDataImputer_Numerical\n",
    "from fast_ml.utilities import rare_encoding\n",
    "from fast_ml.feature_engineering import FeatureEngineering_Categorical,FeatureEngineering_Numerical\n",
    "from fast_ml.utilities import reduce_memory_usage\n",
    "from fast_ml.eda import categorical_plots,numerical_plots,categorical_plots_with_target,numerical_plots_with_target,numerical_bins_with_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python script for confusion matrix creation. \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions\n",
    "\n",
    "* \"compare_Numerical_distribution\" function to compare distribution of numerical data before and after imputation\n",
    "* \"clustercheck\" to check if the set of variables belong to the same cluster.\n",
    "* \"Browser_transform\",\"OS_transform\" and \"Mail_transform\" to normalize the observation in variables,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_Numerical_distribution(df1,df2,variables):\n",
    "    df = pd.DataFrame()\n",
    "    msg_value = []\n",
    "    data = []\n",
    "    for a in variables:\n",
    "        df_mean = df1[a].mean() - df2[a].mean()\n",
    "        df_std = df1[a].std() - df2[a].std()\n",
    "        if int(df_mean) == 0:\n",
    "            msg_mean = \"Mean of both the dataset is same\" #+ str(df1[a].mean()) + str(df2[a].mean()) \n",
    "        else:\n",
    "            msg_mean = \"Mean of both the dataset differ by \" + str(df_mean)\n",
    "        if int(df_std) == 0:\n",
    "            msg_std = \"Standard Dev. of both the dataset is same\"\n",
    "        else:\n",
    "            msg_std = \"Standard Dev the dataset differ by \" + str(df_std) \n",
    "            \n",
    "        if int(df_mean) == 0 and int(df_std) ==0:\n",
    "            msg_Remark = \"Distribution for dataset is same\"\n",
    "            \n",
    "        else:\n",
    "            msg_Remark = \"Distribution for dataset is different\"\n",
    "            \n",
    "        msg_value = [a,msg_mean,msg_std,msg_Remark] \n",
    "        zipped  = zip([\"Variable\",\"Mean\",\"Stdev\",\"Remark\"],msg_value)\n",
    "        a_dict = dict(zipped)\n",
    "        data.append(a_dict)\n",
    "    df= df.append(data,True)\n",
    "    return(df)\n",
    "\n",
    "\n",
    "def clustercheck(df,base,cluster):\n",
    "    nullcount = df[base].isnull().sum()\n",
    "    LiTrue = []\n",
    "    LiFalse = []\n",
    "    for a in cluster:\n",
    "        if df[a].isnull().sum() == nullcount:\n",
    "            LiTrue.append(a)\n",
    "        else:\n",
    "            LiFalse.append(a)\n",
    "\n",
    "    print(\"List of elements having same missing value is\", LiTrue)\n",
    "    print(\"List of elements having different missing value is\", LiFalse)\n",
    "    \n",
    "def Browser_transform(df,col):\n",
    "    df.loc[df[col].str.contains('chrome', na=False), col] = 'Chrome'\n",
    "    df.loc[df[col].str.contains('firefox', na=False), col] = 'Firefox'\n",
    "    df.loc[df[col].str.contains('safari', na=False), col] = 'Safari'\n",
    "    df.loc[df[col].str.contains('edge', na=False), col] = 'Edge'\n",
    "    df.loc[df[col].str.contains('ie', na=False), col] = 'IE'\n",
    "    df.loc[df[col].str.contains('samsung', na=False), col] = 'Samsung'\n",
    "    df.loc[df[col].str.contains('opera', na=False), col] = 'Opera'\n",
    "    #df.loc[df[col].str.contains('Others', na=False), col] = 'other'\n",
    "    df[col].fillna(\"Missing\", inplace=True)\n",
    "    df.loc[df.id_31.isin(df.id_31.value_counts()[df.id_31.value_counts() < 200].index), col] = \"other\"\n",
    "    \n",
    "def OS_transform(df,col):\n",
    "    df.loc[df[col].str.contains('Windows', na=False), col] = 'Windows'\n",
    "    df.loc[df[col].str.contains('iOS', na=False), col] = 'iOS'\n",
    "    df.loc[df[col].str.contains('Mac OS', na=False), col] = 'Mac'\n",
    "    df.loc[df[col].str.contains('Android', na=False), col] = 'Android'\n",
    "    df[col].fillna(\"Missing\", inplace=True)\n",
    "    \n",
    "def Mail_transform(df,col):\n",
    "    df.loc[df[col].str.contains('gmail', na=False), col] = 'gmail.com'\n",
    "    df.loc[df[col].str.contains('yahoo', na=False), col] = 'yahoo.com'\n",
    "    df.loc[df[col].str.contains('outlook', na=False), col] = 'outlook.com'\n",
    "    df.loc[df[col].str.contains('hotmail', na=False), col] = 'hotmail.com'\n",
    "    df[col].fillna(\"Missing\", inplace=True)\n",
    "    \n",
    "def Remove_dup(x):\n",
    "    return list(dict.fromkeys(x))\n",
    "\n",
    "    #return df   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 590540 #number of records in file\n",
    "s = 50000 #desired sample size\n",
    "filename = \"D:\\\\Kaggle\\\\Fraud_Detection\\\\train_transaction.csv\"\n",
    "skip = sorted(random.sample(range(n),n-s))\n",
    "train = pd.read_csv(filename, skiprows=skip[1:])\n",
    "#train_transaction =  pd.read_csv(\"\")\n",
    "#train_identity = pd.read_csv(\"D:\\\\Kaggle\\\\Fraud_Detection\\\\train_identity.csv\")\n",
    "#train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 150.30 MB\n",
      "Memory usage after optimization is: 45.54 MB\n",
      "Decreased by 69.7%\n"
     ]
    }
   ],
   "source": [
    "train = reduce_memory_usage(train, convert_to_category=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train Split\n",
    "\n",
    "* Create Test, Train and Validate DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['isFraud']\n",
    "x_train = train.drop('isFraud', axis =1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, x_valid, Y_train, y_valid = train_test_split(x_train, y, test_size=0.2, random_state=0)\n",
    "#from sklearn.model_selection import train_test_split\n",
    "x_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "x_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32000, 393), (32000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 393), (8000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10001, 393), (10001,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape,y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Identify variables Based on EDA performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rare_2 =['P_emaildomain']\n",
    "Rare_4 =['R_emaildomain']\n",
    "#'D5' : [0,30,40,50,60,70,80,90,100],\n",
    "Custom_Bin ={\n",
    "'TransactionAmt' : [0,10,20,40,50,60,70,90,100],\n",
    "'C1' : [0,50,70,80,90,100],\n",
    "'C2' : [0,50,70,80,90,100],\n",
    "'C4' : [0,70,90,100],\n",
    "'C5' : [0,60,80,90,100],\n",
    "'C6' : [0,60,80,90,100],\n",
    "'C7' : [0,80,90,100],\n",
    "'C8' : [0,70,90,100],\n",
    "'C9' : [0,60,80,90,100],\n",
    "'C10' : [0,70,90,100],\n",
    "'C11' : [0,60,80,90,100],\n",
    "'C12' : [0,80,90,100],\n",
    "'C13' : [0,10,50,60,70,80,90,100],\n",
    "'C14' : [0,80,90,100],\n",
    "'D1' : [0,50,60,70,80,90,100],\n",
    "'addr1' : [0,90,100],\n",
    "'D10' : [0,50,60,70,80,90,100],\n",
    "'D15' : [0,30,40,50,60,70,80,90,100],\n",
    "'D4' : [0,10,50,60,70,80,90,100],\n",
    "'D3' : [0,30,40,50,60,100],\n",
    "'D2' : [0,10,20,30,40,50,60,70,100],\n",
    "'D11' : [0,40,50,60,70,80,90,100],\n",
    "'D6' : [0,70,80,90,100],\n",
    "'D12' : [0,70,80,90,100],\n",
    "'D14' : [0,70,80,90,100],\n",
    "'D13' : [0,90,100],\n",
    "'D7' : [0,60,90,100],'V330': [0, 90, 100],'V329': [0, 90, 100],'V326': [0, 90, 100],'V334': [0, 98, 100],\n",
    "'V337': [0, 95, 100],'V339': [0, 90, 100],\t'V336': [0, 95, 100],\t'V338': [0, 90, 100],\t'V322': [0, 95, 100],\n",
    "             'V324': [0, 80, 100],\t'V323': [0, 90, 100],\t'V335': [0, 90, 100],\t'V331': [0, 90, 100],\n",
    "             'V333': [0, 80, 100],\t'V332': [0, 80, 100],\t'V311': [0, 98, 100],\t'V319': [0, 98, 100],\n",
    "             'V321': [0, 95, 100],\t'V309': [0, 95, 100],\t'V320': [0, 95, 100],\t'V316': [0, 95, 100],\n",
    "             'V313': [0, 90, 100],\t'V318': [0, 95, 100],\t'V315': [0, 90, 100],\t'V312': [0, 80, 90, 100],\n",
    "             'V317': [0, 90, 100],\t'V306': [0, 90, 100],\t'V314': [0, 90, 100],\t'V308': [0, 80, 100],\n",
    "             'V310': [0, 70, 80, 90, 100],'V307': [0, 60, 80, 100]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adaptive_10p = ['card1' ,'card3','card5' ,'card2' ,'dist1' ,'D8','dist2','V225',\t'V193',\t'V190',\t'V170',\t'V237',\n",
    "                'V176',\t'V192',\t'V199',\t'V261',\t'V171',\t'V243',\t'V254',\t'V236',\t'V246',\t'V255',\t'V256',\t'V257',\t'V227',\n",
    "                'V299',\t'V151',\t'V182',\t'V228',\t'V201',\t'V245',\t'V290',\t'V283',\t'V144',\t'V180',\t'V230',\t'V253',\t'V258',\n",
    "                'V259',\t'V222',\t'V221',\t'V224',\t'V226',\t'V229',\t'V296',\t'V298',\t'V285',\t'V187',\t'V234',\t'V269',\t'V292',\t\n",
    "                'V291',\t'V145',\t'V177',\t'V167',\t'V143',\t'V179',\t'V168',\t'V178',\t'V231',\t'V217',\t'V233',\t'V232',\t'V219',\n",
    "                'V218',\t'V166',\t'V164',\t'V129',\t'V293',\t'V279',\t'V295',\t'V165',\t'V280',\t'V150',\t'V135',\t'V294',\t'V137',\n",
    "                'V206',\t'V159',\t'V136',\t'V266',\t'V131',\t'V205',\t'V132',\t'V270',\t'V160',\t'V272',\t'V208',\t'V210',\t'V276',\n",
    "                'V214',\t'V268',\t'V271',\t'V278',\t'V134',\t'V216',\t'V277',\t'V209',\t'V207',\t'V215',\t'V267',\t'V126',\t'V133',\n",
    "                'V128',\t'V273',\t'V275',\t'V130',\t'V211',\t'V127',\t'V274',\t'V213',\t'V212',\t'V263',\t'V202',\t'V265',\t'V204',\n",
    "                'V264',\t'V203']\n",
    "Adaptive_5p = ['V200',\t'V106',\t'V105',\t'V161',\t'V163',\t'V162',\t'V101',\t'V103',\t'V102']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rare_5 = ['ProductCD',\t'card4',\t'card6',\t'addr2',\t'M6',\t'M1',\t'M2',\t'M3',\t'M4',\t'M7',\t'M8',\t'M9',\t'M5',\t'D9',\n",
    "'V9',\t'V8',\t'V5',\t'V4',\t'V3',\t'V2',\t'V11',\t'V10',\t'V50',\t'V49',\t'V48',\t'V42',\t'V41',\t'V40',\t'V36',\t'V35',\t'V94',\t'V93',\n",
    "          'V92',\t'V91',\t'V90',\t'V89',\t'V88',\t'V87',\t'V86',\t'V85',\t'V84',\t'V83',\t'V82',\t'V81',\t'V80',\t'V79',\t'V77',\t'V74',\t'V73',\n",
    "          'V72',\t'V71',\t'V70',\t'V69',\t'V68',\t'V67',\t'V65',\t'V64',\t'V63',\t'V62',\t'V60',\t'V59',\t'V58',\t'V57',\t'V55',\t'V53',\t'V34',\n",
    "          'V33',\t'V32',\t'V31',\t'V30',\t'V29',\t'V28',\t'V27',\t'V26',\t'V25',\t'V24',\t'V22',\t'V21',\t'V19',\t'V18',\t'V17',\t'V16',\t'V15',\n",
    "          'V14',\t'V13',\t'V12',\t'V98','V141',\t'V173',\t'V325',\t'V142',\t'V174',\t'V194',\t'V197',\t'V301',\t'V153',\t'V302',\t'V304',\t'V148',\t'V154',\n",
    "          'V155',\t'V157',\t'V175',\t'V184',\t'V123',\t'V195',\t'V303',\t'V138',\t'V328',\t'V146',\t'V156',\t'V327',\t'V158',\t'V198',\t'V147',\t'V185',\t'V181',\n",
    "          'V169',\t'V188']\n",
    "Rare_10 = ['V107',\t'V117',\t'V118',\t'V119',\t'V120',\t'V121',\t'V122',\t'V108',\t'V109',\t'V110',\t'V111',\t'V112',\t'V113',\t'V114',\t'V115',\t'V116',\t'V124',\n",
    "           'V125',\t'V104']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable to drop\n",
    "Var_to_Drop = ['C3','TransactionID','TransactionDT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop unwanted Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(Var_to_Drop,axis=1)\n",
    "x_valid = x_valid.drop(Var_to_Drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature engineering to string variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Browser_transform(x_train,'id_31')\n",
    "#OS_transform(x_train,'id_30')\n",
    "Mail_transform(x_train,'P_emaildomain')\n",
    "Mail_transform(x_train,'R_emaildomain')\n",
    "\n",
    "#Browser_transform(x_valid,'id_31')\n",
    "#OS_transform(x_valid,'id_30')\n",
    "Mail_transform(x_valid,'P_emaildomain')\n",
    "Mail_transform(x_valid,'R_emaildomain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rare Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_encoder2 = FeatureEngineering_Categorical( method='rare')\n",
    "rare_encoder2.fit(x_train, Rare_2, target=None, rare_tol=2)\n",
    "x_train = rare_encoder2.transform(x_train)\n",
    "x_valid = rare_encoder2.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_encoder3 = FeatureEngineering_Categorical( method='rare')\n",
    "rare_encoder3.fit(x_train, Rare_4, target=None, rare_tol=4)\n",
    "x_train = rare_encoder3.transform(x_train)\n",
    "x_valid = rare_encoder3.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_encoder4 = FeatureEngineering_Categorical( method='rare')\n",
    "rare_encoder4.fit(x_train, Rare_5, target=None, rare_tol=5)\n",
    "x_train = rare_encoder4.transform(x_train)\n",
    "x_valid = rare_encoder4.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_encoder5 = FeatureEngineering_Categorical( method='rare')\n",
    "rare_encoder5.fit(x_train, Rare_10, target=None, rare_tol=10)\n",
    "x_train = rare_encoder5.transform(x_train)\n",
    "x_valid = rare_encoder5.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rare_encoder4.param_dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1006.0, 2803.0, 4812.0, 6951.0, 8178.200000000001, 9749.0, 11366.799999999985, 12932.0, 15066.0, 16560.0, 18390.0]\n",
      "[-inf, 2803.0, 4812.0, 6951.0, 8178.200000000001, 9749.0, 11366.799999999985, 12932.0, 15066.0, 16560.0, inf]\n",
      "[100.0, 150.0, 159.0, 229.0]\n",
      "[-inf, 150.0, 159.0, inf]\n",
      "[100.0, 126.0, 166.0, 195.0, 224.0, 226.0, 237.0]\n",
      "[-inf, 126.0, 166.0, 195.0, 224.0, 226.0, inf]\n",
      "[100.0, 112.0, 194.0, 264.0, 321.0, 361.0, 445.0, 490.0, 543.0, 555.0, 600.0]\n",
      "[-inf, 112.0, 194.0, 264.0, 321.0, 361.0, 445.0, 490.0, 543.0, 555.0, inf]\n",
      "[0.0, 1.0, 2.0, 4.0, 6.0, 8.0, 12.0, 18.0, 36.0, 278.0, 4894.0]\n",
      "[-inf, 1.0, 2.0, 4.0, 6.0, 8.0, 12.0, 18.0, 36.0, 278.0, inf]\n",
      "[0.0, 0.5, 0.8333330154418945, 2.75, 14.366666603088387, 34.79166412353516, 76.66666412353516, 134.8333343505858, 234.8416687011719, 418.91666870117194, 1707.7916259765625]\n",
      "[-inf, 0.5, 0.8333330154418945, 2.75, 14.366666603088387, 34.79166412353516, 76.66666412353516, 134.8333343505858, 234.8416687011719, 418.91666870117194, inf]\n",
      "[0.0, 1.0, 7.0, 16.0, 49.0, 111.0, 187.0, 352.0, 714.0, 11623.0]\n",
      "[-inf, 1.0, 7.0, 16.0, 49.0, 111.0, 187.0, 352.0, 714.0, inf]\n",
      "[0.0, 1.0, 51.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 36.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 37.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 2.0, 3.0, 41.0]\n",
      "[-inf, 1.0, 2.0, 3.0, inf]\n",
      "[0.0, 1.0, 39.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 2.0, 42.0]\n",
      "[-inf, 1.0, 2.0, inf]\n",
      "[1.0, 43.0]\n",
      "[-inf, inf]\n",
      "[0.0, 1.0, 2.0, 39.0]\n",
      "[-inf, 1.0, 2.0, inf]\n",
      "[0.0, 1.0, 47.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 2.0, 3.0, 46.0]\n",
      "[-inf, 1.0, 2.0, 3.0, inf]\n",
      "[1.0, 57.0]\n",
      "[-inf, inf]\n",
      "[1.0, 60.0]\n",
      "[-inf, inf]\n",
      "[0.0, 1.0, 45.0]\n",
      "[-inf, 1.0, inf]\n",
      "[1.0, 23.0]\n",
      "[-inf, inf]\n",
      "[0.0, 1.0, 24.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 24.0]\n",
      "[-inf, 1.0, inf]\n",
      "[1.0, 2.0, 39.0]\n",
      "[-inf, 2.0, inf]\n",
      "[0.0, 34.0]\n",
      "[-inf, inf]\n",
      "[0.0, 47.0]\n",
      "[-inf, inf]\n",
      "[1.0, 16.0, 57.0]\n",
      "[-inf, 16.0, inf]\n",
      "[0.0, 1.0, 76.0]\n",
      "[-inf, 1.0, inf]\n",
      "[1.0, 2.0, 29.0]\n",
      "[-inf, 2.0, inf]\n",
      "[0.0, 1.0, 2.0, 42.0]\n",
      "[-inf, 1.0, 2.0, inf]\n",
      "[0.0, 1.0, 35.0]\n",
      "[-inf, 1.0, inf]\n",
      "[1.0, 40.0]\n",
      "[-inf, inf]\n",
      "[0.0, 1.0, 2.0, 68.0]\n",
      "[-inf, 1.0, 2.0, inf]\n",
      "[0.0, 1.0, 11.0, 61.0]\n",
      "[-inf, 1.0, 11.0, inf]\n",
      "[0.0, 1.0, 76.0]\n",
      "[-inf, 1.0, inf]\n",
      "[1.0, 2.0, 62.0]\n",
      "[-inf, 2.0, inf]\n",
      "[1.0, 161.0]\n",
      "[-inf, inf]\n",
      "[1.0, 2.0, 61.0]\n",
      "[-inf, 2.0, inf]\n",
      "[0.0, 1.0, 35.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 2.0, 3.0, 43.0]\n",
      "[-inf, 1.0, 2.0, 3.0, inf]\n",
      "[0.0, 1.0, 3.0, 36.0]\n",
      "[-inf, 1.0, 3.0, inf]\n",
      "[0.0, 1.0, 143.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 74.0]\n",
      "[-inf, inf]\n",
      "[1.0, 2.0, 3.0, 175.0]\n",
      "[-inf, 2.0, 3.0, inf]\n",
      "[0.0, 86.0]\n",
      "[-inf, inf]\n",
      "[0.0, 86.0]\n",
      "[-inf, inf]\n",
      "[0.0, 1.0, 2.0, 3.0, 93.0]\n",
      "[-inf, 1.0, 2.0, 3.0, inf]\n",
      "[1.0, 214.0]\n",
      "[-inf, inf]\n",
      "[0.0, 1.0, 121.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 4000.0]\n",
      "[-inf, inf]\n",
      "[1.0, 2.0, 237.0]\n",
      "[-inf, 2.0, inf]\n",
      "[1.0, 2.0, 862.0]\n",
      "[-inf, 2.0, inf]\n",
      "[0.0, 1.0, 39.0, 296.0]\n",
      "[-inf, 1.0, 39.0, inf]\n",
      "[0.0, 1.0, 855.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 2.0, 866.0]\n",
      "[-inf, 1.0, 2.0, inf]\n",
      "[0.0, 1.0, 13.0, 863.0]\n",
      "[-inf, 1.0, 13.0, inf]\n",
      "[0.0, 1.0, 896.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 3.0, 939.0]\n",
      "[-inf, 1.0, 3.0, inf]\n",
      "[0.0, 1.0, 1235.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 291.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 2.0, 298.0]\n",
      "[-inf, 1.0, 2.0, inf]\n",
      "[0.0, 1.0, 326.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 331.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 2.0, 372.0]\n",
      "[-inf, 1.0, 2.0, inf]\n",
      "[0.0, 1.0, 3.0, 394.0]\n",
      "[-inf, 1.0, 3.0, inf]\n",
      "[0.0, 100.0, 1166.0, 29400.0]\n",
      "[-inf, 100.0, 1166.0, inf]\n",
      "[0.0, 50.0, 1265.0, 93100.0]\n",
      "[-inf, 50.0, 1265.0, inf]\n",
      "[0.0, 4159.89990234375]\n",
      "[-inf, inf]\n",
      "[0.0, 863.0]\n",
      "[-inf, inf]\n",
      "[0.0, 1.0, 874.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 922.0]\n",
      "[-inf, inf]\n",
      "[0.0, 100.0, 7245.0, 97664.0]\n",
      "[-inf, 100.0, 7245.0, inf]\n",
      "[0.0, 1.0, 2.0, 969.0]\n",
      "[-inf, 1.0, 2.0, inf]\n",
      "[1.0, 133.70000000000027, 3387.0]\n",
      "[-inf, 133.70000000000027, inf]\n",
      "[0.0, 29400.0]\n",
      "[-inf, inf]\n",
      "[0.0, 1.0, 1286.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 29400.0]\n",
      "[-inf, inf]\n",
      "[0.0, 2000.0]\n",
      "[-inf, inf]\n",
      "[0.0, 1459.5000000000005, 43936.9296875]\n",
      "[-inf, 1459.5000000000005, inf]\n",
      "[0.0, 29400.0]\n",
      "[-inf, inf]\n",
      "[0.0, 4000.0]\n",
      "[-inf, inf]\n",
      "[0.0, 70.0, 5400.0]\n",
      "[-inf, 70.0, inf]\n",
      "[0.0, 6025.0]\n",
      "[-inf, inf]\n",
      "[0.0, 93100.0]\n",
      "[-inf, inf]\n",
      "[0.0, 4000.0]\n",
      "[-inf, inf]\n",
      "[0.0, 50.0, 67703.7421875, 641201.4375]\n",
      "[-inf, 50.0, 67703.7421875, inf]\n",
      "[0.0, 4000.0]\n",
      "[-inf, inf]\n",
      "[0.0, 15.0, 3000.0]\n",
      "[-inf, 15.0, inf]\n",
      "[0.0, 17.50335922241221, 3000.0]\n",
      "[-inf, 17.50335922241221, inf]\n",
      "[0.0, 29400.0]\n",
      "[-inf, inf]\n",
      "[0.0, 10.0, 16250.0]\n",
      "[-inf, 10.0, inf]\n",
      "[0.0, 15.0, 8175.0]\n",
      "[-inf, 15.0, inf]\n",
      "[0.0, 4000.0]\n",
      "[-inf, inf]\n",
      "[0.0, 15.559099960326996, 29400.0]\n",
      "[-inf, 15.559099960326996, inf]\n",
      "[0.0, 97664.0]\n",
      "[-inf, inf]\n",
      "[0.0, 25.0, 16250.0]\n",
      "[-inf, 25.0, inf]\n",
      "[0.0, 24.01346054077141, 29400.0]\n",
      "[-inf, 24.01346054077141, inf]\n",
      "[0.0, 23.481159400939966, 4575.0]\n",
      "[-inf, 23.481159400939966, inf]\n",
      "[0.0, 20.0, 24550.0]\n",
      "[-inf, 20.0, inf]\n",
      "[0.0, 29.24329948425293, 16250.0]\n",
      "[-inf, 29.24329948425293, inf]\n",
      "[0.0, 30.0, 26900.0]\n",
      "[-inf, 30.0, inf]\n",
      "[0.0, 59.0, 94265.0]\n",
      "[-inf, 59.0, inf]\n",
      "[0.0, 133915.0]\n",
      "[-inf, inf]\n",
      "[0.0, 44.0, 156.0, 102683.0]\n",
      "[-inf, 44.0, 156.0, inf]\n",
      "[0.0, 51.52615890502915, 29785.0]\n",
      "[-inf, 51.52615890502915, inf]\n",
      "[0.0, 65.33226165771482, 32545.0]\n",
      "[-inf, 65.33226165771482, inf]\n",
      "[0.0, 31.95000076293945, 107.9499969482422, 246.81200561523443, 11600.0]\n",
      "[-inf, 31.95000076293945, 107.9499969482422, 246.81200561523443, inf]\n",
      "[0.0, 53.96274032592795, 92252.0]\n",
      "[-inf, 53.96274032592795, inf]\n",
      "[0.0, 61.9000015258789, 151.0, 363.75, 145476.0]\n",
      "[-inf, 61.9000015258789, 151.0, 363.75, inf]\n",
      "[0.0, 75.0, 32970.0]\n",
      "[-inf, 75.0, inf]\n",
      "[0.0, 69.72468261718755, 95896.0]\n",
      "[-inf, 69.72468261718755, inf]\n",
      "[0.0, 79.1097000122071, 129006.0]\n",
      "[-inf, 79.1097000122071, inf]\n",
      "[0.0, 40.743879699707094, 150.0, 30476.0]\n",
      "[-inf, 40.743879699707094, 150.0, inf]\n",
      "[0.0, 37.87764129638678, 150.0, 93417.0]\n",
      "[-inf, 37.87764129638678, 150.0, inf]\n",
      "[0.0, 53.341320800781325, 178.1622772216795, 43200.0]\n",
      "[-inf, 53.341320800781325, 178.1622772216795, inf]\n",
      "[0.0, 50.0, 177.47685852050785, 100537.0]\n",
      "[-inf, 50.0, 177.47685852050785, inf]\n",
      "[0.0, 13.091880035400282, 71.99741821289064, 200.0, 69700.0]\n",
      "[-inf, 13.091880035400282, 71.99741821289064, 200.0, inf]\n",
      "[0.0, 3.3627400398253484, 65.92847900390632, 200.0, 139001.0]\n",
      "[-inf, 3.3627400398253484, 65.92847900390632, 200.0, inf]\n"
     ]
    }
   ],
   "source": [
    "### ADAPTIVE 10 PERCENTILE BINNING \n",
    "\n",
    "from fast_ml.feature_engineering import FeatureEngineering_Numerical\n",
    "num_binner = FeatureEngineering_Numerical(method = '10p', adaptive = True)\n",
    "num_binner.fit(x_train, Adaptive_10p)\n",
    "x_train = num_binner.transform(x_train)\n",
    "x_valid = num_binner.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 2.0, 39.0]\n",
      "[-inf, 1.0, 2.0, inf]\n",
      "[0.0, 1.0, 52.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 92.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 3000.0]\n",
      "[-inf, inf]\n",
      "[0.0, 3000.0]\n",
      "[-inf, inf]\n",
      "[0.0, 3000.0]\n",
      "[-inf, inf]\n",
      "[0.0, 1.0, 863.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 922.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 2.0, 1285.0]\n",
      "[-inf, 2.0, inf]\n"
     ]
    }
   ],
   "source": [
    "### ADAPTIVE 5 PERCENTILE BINNING \n",
    "num_binner2 = FeatureEngineering_Numerical(method = '5p', adaptive = True)\n",
    "num_binner2.fit(x_train, Adaptive_5p)\n",
    "x_train = num_binner2.transform(x_train)\n",
    "x_valid = num_binner2.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5429999999999999, 26.31, 35.95, 57.95, 68.95, 100.0, 117.0, 276.1500000000033, 5279.95]\n",
      "[-inf, 26.31, 35.95, 57.95, 68.95, 100.0, 117.0, 276.1500000000033, inf]\n",
      "TransactionAmt [0, 10, 20, 40, 50, 60, 70, 90, 100]\n",
      "[0.0, 1.0, 2.0, 4.0, 7.0, 4681.0]\n",
      "[-inf, 1.0, 2.0, 4.0, 7.0, inf]\n",
      "C1 [0, 50, 70, 80, 90, 100]\n",
      "[0.0, 1.0, 2.0, 4.0, 7.0, 5690.0]\n",
      "[-inf, 1.0, 2.0, 4.0, 7.0, inf]\n",
      "C2 [0, 50, 70, 80, 90, 100]\n",
      "[0.0, 0.0, 1.0, 2249.0]\n",
      "[-inf, 0.0, 1.0, inf]\n",
      "C4 [0, 70, 90, 100]\n",
      "[0.0, 0.0, 1.0, 3.0, 298.0]\n",
      "[-inf, 0.0, 1.0, 3.0, inf]\n",
      "C5 [0, 60, 80, 90, 100]\n",
      "[0.0, 1.0, 2.0, 5.0, 2249.0]\n",
      "[-inf, 1.0, 2.0, 5.0, inf]\n",
      "C6 [0, 60, 80, 90, 100]\n",
      "[0.0, 0.0, 1.0, 2251.0]\n",
      "[-inf, 0.0, 1.0, inf]\n",
      "C7 [0, 80, 90, 100]\n",
      "[0.0, 0.0, 1.0, 3327.0]\n",
      "[-inf, 0.0, 1.0, inf]\n",
      "C8 [0, 70, 90, 100]\n",
      "[0.0, 1.0, 2.0, 4.0, 204.0]\n",
      "[-inf, 1.0, 2.0, 4.0, inf]\n",
      "C9 [0, 60, 80, 90, 100]\n",
      "[0.0, 0.0, 1.0, 3253.0]\n",
      "[-inf, 0.0, 1.0, inf]\n",
      "C10 [0, 70, 90, 100]\n",
      "[0.0, 1.0, 2.0, 4.0, 3184.0]\n",
      "[-inf, 1.0, 2.0, 4.0, inf]\n",
      "C11 [0, 60, 80, 90, 100]\n",
      "[0.0, 0.0, 1.0, 3184.0]\n",
      "[-inf, 0.0, 1.0, inf]\n",
      "C12 [0, 80, 90, 100]\n",
      "[0.0, 1.0, 3.0, 5.0, 9.0, 17.0, 37.0, 2913.0]\n",
      "[-inf, 1.0, 3.0, 5.0, 9.0, 17.0, 37.0, inf]\n",
      "C13 [0, 10, 50, 60, 70, 80, 90, 100]\n",
      "[0.0, 3.0, 5.0, 1424.0]\n",
      "[-inf, 3.0, 5.0, inf]\n",
      "C14 [0, 80, 90, 100]\n",
      "[0.0, 2.0, 29.0, 81.0, 180.0, 363.0, 640.0]\n",
      "[-inf, 2.0, 29.0, 81.0, 180.0, 363.0, inf]\n",
      "D1 [0, 50, 60, 70, 80, 90, 100]\n",
      "[100.0, 444.0, 536.0]\n",
      "[-inf, 444.0, inf]\n",
      "addr1 [0, 90, 100]\n",
      "[0.0, 15.0, 57.79999999999927, 137.0, 276.0, 462.0, 865.0]\n",
      "[-inf, 15.0, 57.79999999999927, 137.0, 276.0, 462.0, inf]\n",
      "D10 [0, 50, 60, 70, 80, 90, 100]\n",
      "[-60.0, 0.0, 10.0, 51.0, 125.0, 246.0, 384.0, 508.0, 865.0]\n",
      "[-inf, 0.0, 10.0, 51.0, 125.0, 246.0, 384.0, 508.0, inf]\n",
      "D15 [0, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "[-6.0, 0.0, 26.0, 80.0, 187.0, 339.40000000000146, 484.0, 822.0]\n",
      "[-inf, 0.0, 26.0, 80.0, 187.0, 339.40000000000146, 484.0, inf]\n",
      "D4 [0, 10, 50, 60, 70, 80, 90, 100]\n",
      "[0.0, 2.0, 5.0, 8.0, 14.0, 729.0]\n",
      "[-inf, 2.0, 5.0, 8.0, 14.0, inf]\n",
      "D3 [0, 30, 40, 50, 60, 100]\n",
      "[0.0, 4.0, 16.0, 34.0, 60.0, 96.0, 150.0, 228.0, 640.0]\n",
      "[-inf, 4.0, 16.0, 34.0, 60.0, 96.0, 150.0, 228.0, inf]\n",
      "D2 [0, 10, 20, 30, 40, 50, 60, 70, 100]\n",
      "[0.0, 7.0, 42.0, 106.0, 212.0, 338.0, 460.5, 659.0]\n",
      "[-inf, 7.0, 42.0, 106.0, 212.0, 338.0, 460.5, inf]\n",
      "D11 [0, 40, 50, 60, 70, 80, 90, 100]\n",
      "[-6.0, 9.0, 95.0, 303.9000000000001, 865.0]\n",
      "[-inf, 9.0, 95.0, 303.9000000000001, inf]\n",
      "D6 [0, 70, 80, 90, 100]\n",
      "[0.0, 2.0, 39.600000000000364, 251.80000000000018, 628.0]\n",
      "[-inf, 2.0, 39.600000000000364, 251.80000000000018, inf]\n",
      "D12 [0, 70, 80, 90, 100]\n",
      "[0.0, 0.0, 58.80000000000018, 291.4000000000001, 847.0]\n",
      "[-inf, 0.0, 58.80000000000018, 291.4000000000001, inf]\n",
      "D14 [0, 70, 80, 90, 100]\n",
      "[0.0, 26.0, 745.0]\n",
      "[-inf, 26.0, inf]\n",
      "D13 [0, 90, 100]\n",
      "[0.0, 2.0, 161.0, 724.0]\n",
      "[-inf, 2.0, 161.0, inf]\n",
      "D7 [0, 60, 90, 100]\n",
      "[0.0, 1.0, 52.0]\n",
      "[-inf, 1.0, inf]\n",
      "V330 [0, 90, 100]\n",
      "[0.0, 1.0, 92.0]\n",
      "[-inf, 1.0, inf]\n",
      "V329 [0, 90, 100]\n",
      "[0.0, 1.0, 41.0]\n",
      "[-inf, 1.0, inf]\n",
      "V326 [0, 90, 100]\n",
      "[0.0, 100.0, 3000.0]\n",
      "[-inf, 100.0, inf]\n",
      "V334 [0, 98, 100]\n",
      "[0.0, 200.0, 21600.0]\n",
      "[-inf, 200.0, inf]\n",
      "V337 [0, 95, 100]\n",
      "[0.0, 50.0, 21600.0]\n",
      "[-inf, 50.0, inf]\n",
      "V339 [0, 90, 100]\n",
      "[0.0, 100.0, 3000.0]\n",
      "[-inf, 100.0, inf]\n",
      "V336 [0, 95, 100]\n",
      "[0.0, 60.0, 21600.0]\n",
      "[-inf, 60.0, inf]\n",
      "V338 [0, 90, 100]\n",
      "[0.0, 3.0, 874.0]\n",
      "[-inf, 3.0, inf]\n",
      "V322 [0, 95, 100]\n",
      "[0.0, 1.0, 970.0]\n",
      "[-inf, 1.0, inf]\n",
      "V324 [0, 80, 100]\n",
      "[0.0, 2.0, 1404.0]\n",
      "[-inf, 2.0, inf]\n",
      "V323 [0, 90, 100]\n",
      "[0.0, 40.0, 3722.0]\n",
      "[-inf, 40.0, inf]\n",
      "V335 [0, 90, 100]\n",
      "[0.0, 150.0, 94265.0]\n",
      "[-inf, 150.0, inf]\n",
      "V331 [0, 90, 100]\n",
      "[0.0, 50.0, 102683.0]\n",
      "[-inf, 50.0, inf]\n",
      "V333 [0, 80, 100]\n",
      "[0.0, 90.0, 145582.0]\n",
      "[-inf, 90.0, inf]\n",
      "V332 [0, 80, 100]\n",
      "[0.0, 49.0, 4159.89990234375]\n",
      "[-inf, 49.0, inf]\n",
      "V311 [0, 98, 100]\n",
      "[0.0, 171.0, 29400.0]\n",
      "[-inf, 171.0, inf]\n",
      "V319 [0, 98, 100]\n",
      "[0.0, 47.95000076293945, 29400.0]\n",
      "[-inf, 47.95000076293945, inf]\n",
      "V321 [0, 95, 100]\n",
      "[0.0, 57.0, 4159.89990234375]\n",
      "[-inf, 57.0, inf]\n",
      "V309 [0, 95, 100]\n",
      "[0.0, 100.0, 29400.0]\n",
      "[-inf, 100.0, inf]\n",
      "V320 [0, 95, 100]\n",
      "[0.0, 85.11799621582031, 93100.0]\n",
      "[-inf, 85.11799621582031, inf]\n",
      "V316 [0, 95, 100]\n",
      "[0.0, 58.95000076293945, 4159.89990234375]\n",
      "[-inf, 58.95000076293945, inf]\n",
      "V313 [0, 90, 100]\n",
      "[0.0, 150.0, 97664.0]\n",
      "[-inf, 150.0, inf]\n",
      "V318 [0, 95, 100]\n",
      "[0.0, 68.0, 4159.89990234375]\n",
      "[-inf, 68.0, inf]\n",
      "V315 [0, 90, 100]\n",
      "[0.0, 25.002000045776377, 107.9499969482422, 4159.89990234375]\n",
      "[-inf, 25.002000045776377, 107.9499969482422, inf]\n",
      "V312 [0, 80, 90, 100]\n",
      "[0.0, 59.0, 134021.0]\n",
      "[-inf, 59.0, inf]\n",
      "V317 [0, 90, 100]\n",
      "[0.0, 97.0, 94265.0]\n",
      "[-inf, 97.0, inf]\n",
      "V306 [0, 90, 100]\n",
      "[0.0, 108.9499969482422, 5565.0]\n",
      "[-inf, 108.9499969482422, inf]\n",
      "V314 [0, 90, 100]\n",
      "[0.0, 63.95000076293945, 102628.0]\n",
      "[-inf, 63.95000076293945, inf]\n",
      "V308 [0, 80, 100]\n",
      "[0.0, 61.90000152587889, 140.0, 317.8999938964844, 6800.0]\n",
      "[-inf, 61.90000152587889, 140.0, 317.8999938964844, inf]\n",
      "V310 [0, 70, 80, 90, 100]\n",
      "[0.0, 50.0, 210.84727783203124, 144989.0]\n",
      "[-inf, 50.0, 210.84727783203124, inf]\n",
      "V307 [0, 60, 80, 100]\n"
     ]
    }
   ],
   "source": [
    "for key, value in Custom_Bin.items():\n",
    "    num_bin_custom = FeatureEngineering_Numerical(method = 'custom', adaptive = False, custom_buckets= value)\n",
    "    num_bin_custom.fit(x_train,[key])\n",
    "    print(key,value)\n",
    "    x_train = num_bin_custom.transform(x_train)\n",
    "    x_valid = num_bin_custom.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_imputer = MissingDataImputer_Categorical(method = 'custom_value',add_indicator=False,value = 'Missing')\n",
    "cat_imputer.fit(x_train, variables = Rare_5)\n",
    "x_train = cat_imputer.transform(x_train)\n",
    "x_valid = cat_imputer.transform(x_valid)\n",
    "\n",
    "cat_imputer2 = MissingDataImputer_Categorical(method = 'custom_value',add_indicator=False,value = 'Missing')\n",
    "cat_imputer2.fit(x_train, variables = Rare_10)\n",
    "x_train = cat_imputer2.transform(x_train)\n",
    "x_valid = cat_imputer2.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 60.0, 68.0, 69.0]\n",
      "[-inf, 2.0, 60.0, 68.0, inf]\n",
      "[0.0, 1.0, 2.0, 3.0, 28.0]\n",
      "[-inf, 1.0, 2.0, 3.0, inf]\n",
      "[1.0, 2.0, 22.0]\n",
      "[-inf, 2.0, inf]\n",
      "[0.0, 1.0, 36.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 2.0, 33.0]\n",
      "[-inf, 1.0, 2.0, inf]\n",
      "[0.0, 1.0, 38.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 23.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 2.0, 3.0, 5.0, 7.0, 10.0, 13.0, 15.199999999998909, 20.0, 27.0, 32.0, 44.0, 67.0, 120.0, 255.0, 724.0]\n",
      "[-inf, 1.0, 2.0, 3.0, 5.0, 7.0, 10.0, 13.0, 15.199999999998909, 20.0, 27.0, 32.0, 44.0, 67.0, 120.0, 255.0, inf]\n",
      "[0.0, 1.0, 2.0, 22.0]\n",
      "[-inf, 1.0, 2.0, inf]\n",
      "[0.0, 1.0, 2.0, 42.0]\n",
      "[-inf, 1.0, 2.0, inf]\n",
      "[0.0, 1.0, 2.0, 39.0]\n",
      "[-inf, 1.0, 2.0, inf]\n",
      "[0.0, 1.0, 2.0, 39.0]\n",
      "[-inf, 1.0, 2.0, inf]\n",
      "[0.0, 1.0, 2.0, 25.0]\n",
      "[-inf, 1.0, 2.0, inf]\n",
      "[0.0, 1.0, 2.0, 3.0, 4.0, 77.0]\n",
      "[-inf, 1.0, 2.0, 3.0, 4.0, inf]\n",
      "[0.0, 1.0, 874.0]\n",
      "[-inf, 1.0, inf]\n",
      "[0.0, 1.0, 2.0, 3.0, 6.0, 1403.0]\n",
      "[-inf, 1.0, 2.0, 3.0, 6.0, inf]\n",
      "[0.0, 1.0, 3.0, 970.0]\n",
      "[-inf, 1.0, 3.0, inf]\n",
      "[0.0, 1.0, 23.0]\n",
      "[-inf, 1.0, inf]\n"
     ]
    }
   ],
   "source": [
    "licol = x_train.columns\n",
    "mda_obj = MissingDataAnalysis(x_train[licol], target='isfraud', model = 'Classification' )\n",
    "X_miss = mda_obj.calculate_missing_values()\n",
    "x_missvar = X_miss.variables\n",
    "catcol =[]\n",
    "numcol = []\n",
    "for col in x_missvar:\n",
    "    if len(x_train[col].unique()) <=20 :\n",
    "        catcol.append(col)\n",
    "    else:\n",
    "        numcol.append(col)\n",
    "#catcol.extend([\"id_31\",\"id_33\",\"DeviceInfo\"])\n",
    "#numcol.remove(\"id_33\")\n",
    "#numcol.remove(\"DeviceInfo\")\n",
    "rare_encoder1 = FeatureEngineering_Categorical( method='rare')\n",
    "rare_encoder1.fit(x_train, catcol, target=None, rare_tol=5)\n",
    "x_train = rare_encoder1.transform(x_train)\n",
    "x_valid = rare_encoder1.transform(x_valid)\n",
    "\n",
    "num_binner3 = FeatureEngineering_Numerical(method = '5p', adaptive = True)\n",
    "num_binner3.fit(x_train, numcol)\n",
    "x_train = num_binner3.transform(x_train)\n",
    "x_valid = num_binner3.transform(x_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train['variable'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Onehot_Encode = FeatureEngineering_Categorical( method='onehot')\n",
    "Onehot_Encode.fit(x_train,variables= Rare_5)\n",
    "x_train= Onehot_Encode.transform(x_train)\n",
    "x_valid = Onehot_Encode.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Onehot_Encode2 = FeatureEngineering_Categorical( method='onehot')\n",
    "Onehot_Encode2.fit(x_train,variables= Rare_10)\n",
    "x_train= Onehot_Encode2.transform(x_train)\n",
    "x_valid = Onehot_Encode2.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Onehot_Encode4 = FeatureEngineering_Categorical( method='onehot')\n",
    "Onehot_Encode4.fit(x_train,variables= catcol)\n",
    "x_train= Onehot_Encode4.transform(x_train)\n",
    "x_valid = Onehot_Encode4.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Onehot_Encode4 = FeatureEngineering_Categorical( method='Onehot')\n",
    "Onehot_Encode4.fit(x_train,variables= Adaptive_10p)\n",
    "x_train= Onehot_Encode4.transform(x_train)\n",
    "x_valid = Onehot_Encode4.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Onehot_Encode5 = FeatureEngineering_Categorical( method='onehot')\n",
    "Onehot_Encode5.fit(x_train,variables= Adaptive_5p)\n",
    "x_train= Onehot_Encode5.transform(x_train)\n",
    "x_valid = Onehot_Encode5.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Onehot_Encode6 = FeatureEngineering_Categorical( method='onehot')\n",
    "Onehot_Encode6.fit(x_train,variables= numcol)\n",
    "x_train= Onehot_Encode6.transform(x_train)\n",
    "x_valid = Onehot_Encode6.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "listcolumn= ['TransactionAmt','addr1','P_emaildomain','R_emaildomain','C1','C2','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14','D1','D2','D3','D4','D6','D7','D10','D11','D12','D13','D14','D15','V306','V307','V308','V309','V310','V311','V312','V313','V314','V315','V316','V317','V318','V319','V320','V321','V322','V323','V324','V326','V329','V330','V331','V332','V333','V334','V335','V336','V337','V338','V339']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Onehot_Encode7 = FeatureEngineering_Categorical( method='onehot')\n",
    "Onehot_Encode7.fit(x_train,variables= listcolumn)\n",
    "x_train= Onehot_Encode7.transform(x_train)\n",
    "x_valid = Onehot_Encode7.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_Analysis= pd.DataFrame(x_train.dtypes)\n",
    "DF_Analysis.index.name = \"Variable\"\n",
    "DF_Analysis.columns = [\"DType\"]\n",
    "DF_Analysis[\"Unique\"] = x_train.nunique()\n",
    "DF_Analysis[\"Missing_Count\"]=pd.DataFrame(x_train.isnull().sum())\n",
    "DF_Analysis[\"Missing_Rate\"] = round((x_train.isnull().sum()/x_train.shape[0])*100,2)\n",
    "\n",
    "DF_Analysis[\"Cat_Num\"] = np.where(DF_Analysis.Unique >=60,\"Numerical\",(np.where(DF_Analysis.DType == \"object\",\n",
    "                                                                     \"Categorical\",\"Num_Cat\")))\n",
    "DF_Analysis.sort_values(by = [\"Missing_Count\"], ascending= False)\n",
    "DF_Analysis[\"Imputation_Method\"] = np.where(DF_Analysis.Missing_Rate >0,\n",
    "                                            np.where(DF_Analysis.Cat_Num == \"Categorical\",\"Missing\",\n",
    "                                            np.where(DF_Analysis.Cat_Num == \"Num_Cat\",\"Missing\",\"Binning\")),\"Not Applicable\")\n",
    "    #np.where(DF_Analysis.Missing_Rate ==0,\"Not Applicable\",np.where(DF_Analysis.Cat_Num == \"Categorical\",\"Mode\",\n",
    "   # np.where(DF_Analysis.Cat_Num == \"Num_Cat\",\"Mode\",\"Mean_Median\"))))\n",
    "DF_Analysis[\"Drop_Variable\"] =  np.where(DF_Analysis.Missing_Rate >=90, \"Yes\",\"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DType</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Missing_Rate</th>\n",
       "      <th>Cat_Num</th>\n",
       "      <th>Imputation_Method</th>\n",
       "      <th>Drop_Variable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ProductCD_W</th>\n",
       "      <td>int32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Num_Cat</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V273_(54.083, inf]</th>\n",
       "      <td>int32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Num_Cat</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V273_Missing</th>\n",
       "      <td>int32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Num_Cat</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V128_Missing</th>\n",
       "      <td>int32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Num_Cat</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V128_(157.545, inf]</th>\n",
       "      <td>int32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Num_Cat</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V213_(-inf, 76.543]</th>\n",
       "      <td>int32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Num_Cat</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V152_(-inf, 2.0]</th>\n",
       "      <td>int32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Num_Cat</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D5_(45.0, 66.85]</th>\n",
       "      <td>int32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Num_Cat</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D5_(-inf, 1.0]</th>\n",
       "      <td>int32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Num_Cat</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D5_Missing</th>\n",
       "      <td>int32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Num_Cat</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     DType  Unique  Missing_Count  Missing_Rate  Cat_Num  \\\n",
       "Variable                                                                   \n",
       "ProductCD_W          int32       2              0           0.0  Num_Cat   \n",
       "V273_(54.083, inf]   int32       2              0           0.0  Num_Cat   \n",
       "V273_Missing         int32       2              0           0.0  Num_Cat   \n",
       "V128_Missing         int32       2              0           0.0  Num_Cat   \n",
       "V128_(157.545, inf]  int32       2              0           0.0  Num_Cat   \n",
       "...                    ...     ...            ...           ...      ...   \n",
       "V213_(-inf, 76.543]  int32       2              0           0.0  Num_Cat   \n",
       "V152_(-inf, 2.0]     int32       2              0           0.0  Num_Cat   \n",
       "D5_(45.0, 66.85]     int32       2              0           0.0  Num_Cat   \n",
       "D5_(-inf, 1.0]       int32       2              0           0.0  Num_Cat   \n",
       "D5_Missing           int32       2              0           0.0  Num_Cat   \n",
       "\n",
       "                    Imputation_Method Drop_Variable  \n",
       "Variable                                             \n",
       "ProductCD_W            Not Applicable            No  \n",
       "V273_(54.083, inf]     Not Applicable            No  \n",
       "V273_Missing           Not Applicable            No  \n",
       "V128_Missing           Not Applicable            No  \n",
       "V128_(157.545, inf]    Not Applicable            No  \n",
       "...                               ...           ...  \n",
       "V213_(-inf, 76.543]    Not Applicable            No  \n",
       "V152_(-inf, 2.0]       Not Applicable            No  \n",
       "D5_(45.0, 66.85]       Not Applicable            No  \n",
       "D5_(-inf, 1.0]         Not Applicable            No  \n",
       "D5_Missing             Not Applicable            No  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_Analysis.sort_values(by = 'Unique',ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DF_Analysis[DF_Analysis[\"Cat_Num\"] == 'Numerical']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "litraincolOrg = x_train.columns\n",
    "litraincol  =  litraincolOrg\n",
    "livalidcolOrg = x_valid.columns\n",
    "livalidcol  =  livalidcolOrg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V284',\n",
       " 'V286',\n",
       " 'V287',\n",
       " 'V297',\n",
       " 'V305',\n",
       " 'ProductCD_W',\n",
       " 'ProductCD_R',\n",
       " 'ProductCD_C',\n",
       " 'ProductCD_H',\n",
       " 'ProductCD_Rare',\n",
       " 'card4_visa',\n",
       " 'card4_Rare',\n",
       " 'card4_mastercard',\n",
       " 'card6_debit',\n",
       " 'card6_credit',\n",
       " 'card6_Rare',\n",
       " 'addr2_87.0',\n",
       " 'addr2_Rare',\n",
       " 'M6_F',\n",
       " 'M6_T',\n",
       " 'M6_Rare',\n",
       " 'M1_T',\n",
       " 'M1_Rare',\n",
       " 'M2_T',\n",
       " 'M2_Rare',\n",
       " 'M2_F',\n",
       " 'M3_T',\n",
       " 'M3_Rare',\n",
       " 'M3_F',\n",
       " 'M4_M2',\n",
       " 'M4_Rare',\n",
       " 'M4_M0',\n",
       " 'M4_M1',\n",
       " 'M7_Rare',\n",
       " 'M7_F',\n",
       " 'M7_T',\n",
       " 'M8_Rare',\n",
       " 'M8_F',\n",
       " 'M8_T',\n",
       " 'M9_Rare',\n",
       " 'M9_F',\n",
       " 'M9_T',\n",
       " 'M5_T',\n",
       " 'M5_Rare',\n",
       " 'M5_F',\n",
       " 'D9_Rare',\n",
       " 'V9_1.0',\n",
       " 'V9_Rare',\n",
       " 'V8_1.0',\n",
       " 'V8_Rare',\n",
       " 'V5_1.0',\n",
       " 'V5_0.0',\n",
       " 'V5_Rare',\n",
       " 'V4_1.0',\n",
       " 'V4_0.0',\n",
       " 'V4_Rare',\n",
       " 'V3_1.0',\n",
       " 'V3_Rare',\n",
       " 'V2_1.0',\n",
       " 'V2_Rare',\n",
       " 'V11_0.0',\n",
       " 'V11_1.0',\n",
       " 'V11_Rare',\n",
       " 'V10_0.0',\n",
       " 'V10_1.0',\n",
       " 'V10_Rare',\n",
       " 'V50_0.0',\n",
       " 'V50_Rare',\n",
       " 'V50_1.0',\n",
       " 'V49_0.0',\n",
       " 'V49_Rare',\n",
       " 'V49_1.0',\n",
       " 'V48_0.0',\n",
       " 'V48_Rare',\n",
       " 'V48_1.0',\n",
       " 'V42_0.0',\n",
       " 'V42_Rare',\n",
       " 'V42_1.0',\n",
       " 'V41_1.0',\n",
       " 'V41_Rare',\n",
       " 'V40_0.0',\n",
       " 'V40_Rare',\n",
       " 'V40_1.0',\n",
       " 'V36_1.0',\n",
       " 'V36_Rare',\n",
       " 'V36_0.0',\n",
       " 'V35_1.0',\n",
       " 'V35_Rare',\n",
       " 'V35_0.0',\n",
       " 'V94_0.0',\n",
       " 'V94_Rare',\n",
       " 'V94_1.0',\n",
       " 'V93_0.0',\n",
       " 'V93_Rare',\n",
       " 'V93_1.0',\n",
       " 'V92_0.0',\n",
       " 'V92_Rare',\n",
       " 'V92_1.0',\n",
       " 'V91_0.0',\n",
       " 'V91_Rare',\n",
       " 'V91_1.0',\n",
       " 'V90_0.0',\n",
       " 'V90_Rare',\n",
       " 'V90_1.0',\n",
       " 'V89_0.0',\n",
       " 'V89_Rare',\n",
       " 'V88_1.0',\n",
       " 'V88_Rare',\n",
       " 'V87_1.0',\n",
       " 'V87_2.0',\n",
       " 'V87_Rare',\n",
       " 'V86_1.0',\n",
       " 'V86_Rare',\n",
       " 'V85_0.0',\n",
       " 'V85_Rare',\n",
       " 'V85_1.0',\n",
       " 'V84_0.0',\n",
       " 'V84_Rare',\n",
       " 'V84_1.0',\n",
       " 'V83_1.0',\n",
       " 'V83_0.0',\n",
       " 'V83_Rare',\n",
       " 'V82_1.0',\n",
       " 'V82_0.0',\n",
       " 'V82_Rare',\n",
       " 'V81_0.0',\n",
       " 'V81_Rare',\n",
       " 'V81_1.0',\n",
       " 'V80_0.0',\n",
       " 'V80_Rare',\n",
       " 'V80_1.0',\n",
       " 'V79_0.0',\n",
       " 'V79_Rare',\n",
       " 'V79_1.0',\n",
       " 'V77_1.0',\n",
       " 'V77_Rare',\n",
       " 'V74_0.0',\n",
       " 'V74_Rare',\n",
       " 'V74_1.0',\n",
       " 'V73_0.0',\n",
       " 'V73_Rare',\n",
       " 'V73_1.0',\n",
       " 'V72_0.0',\n",
       " 'V72_Rare',\n",
       " 'V72_1.0',\n",
       " 'V71_0.0',\n",
       " 'V71_Rare',\n",
       " 'V71_1.0',\n",
       " 'V70_0.0',\n",
       " 'V70_Rare',\n",
       " 'V70_1.0',\n",
       " 'V69_0.0',\n",
       " 'V69_Rare',\n",
       " 'V69_1.0',\n",
       " 'V68_0.0',\n",
       " 'V68_Rare',\n",
       " 'V67_1.0',\n",
       " 'V67_Rare',\n",
       " 'V65_1.0',\n",
       " 'V65_Rare',\n",
       " 'V64_0.0',\n",
       " 'V64_Rare',\n",
       " 'V64_1.0',\n",
       " 'V63_0.0',\n",
       " 'V63_Rare',\n",
       " 'V63_1.0',\n",
       " 'V62_1.0',\n",
       " 'V62_0.0',\n",
       " 'V62_Rare',\n",
       " 'V60_0.0',\n",
       " 'V60_Rare',\n",
       " 'V60_1.0',\n",
       " 'V59_0.0',\n",
       " 'V59_Rare',\n",
       " 'V59_1.0',\n",
       " 'V58_0.0',\n",
       " 'V58_Rare',\n",
       " 'V58_1.0',\n",
       " 'V57_0.0',\n",
       " 'V57_Rare',\n",
       " 'V57_1.0',\n",
       " 'V55_1.0',\n",
       " 'V55_Rare',\n",
       " 'V53_1.0',\n",
       " 'V53_0.0',\n",
       " 'V53_Rare',\n",
       " 'V34_0.0',\n",
       " 'V34_Rare',\n",
       " 'V34_1.0',\n",
       " 'V33_0.0',\n",
       " 'V33_Rare',\n",
       " 'V33_1.0',\n",
       " 'V32_0.0',\n",
       " 'V32_Rare',\n",
       " 'V32_1.0',\n",
       " 'V31_0.0',\n",
       " 'V31_Rare',\n",
       " 'V31_1.0',\n",
       " 'V30_0.0',\n",
       " 'V30_1.0',\n",
       " 'V30_Rare',\n",
       " 'V29_0.0',\n",
       " 'V29_1.0',\n",
       " 'V29_Rare',\n",
       " 'V28_0.0',\n",
       " 'V28_Rare',\n",
       " 'V27_0.0',\n",
       " 'V27_Rare',\n",
       " 'V26_1.0',\n",
       " 'V26_Rare',\n",
       " 'V25_1.0',\n",
       " 'V25_Rare',\n",
       " 'V24_1.0',\n",
       " 'V24_Rare',\n",
       " 'V22_0.0',\n",
       " 'V22_Rare',\n",
       " 'V22_1.0',\n",
       " 'V21_0.0',\n",
       " 'V21_Rare',\n",
       " 'V21_1.0',\n",
       " 'V19_1.0',\n",
       " 'V19_0.0',\n",
       " 'V19_Rare',\n",
       " 'V18_0.0',\n",
       " 'V18_Rare',\n",
       " 'V18_1.0',\n",
       " 'V17_0.0',\n",
       " 'V17_Rare',\n",
       " 'V17_1.0',\n",
       " 'V16_0.0',\n",
       " 'V16_Rare',\n",
       " 'V16_1.0',\n",
       " 'V15_0.0',\n",
       " 'V15_Rare',\n",
       " 'V15_1.0',\n",
       " 'V14_1.0',\n",
       " 'V14_Rare',\n",
       " 'V13_1.0',\n",
       " 'V13_0.0',\n",
       " 'V13_Rare',\n",
       " 'V12_1.0',\n",
       " 'V12_0.0',\n",
       " 'V12_Rare',\n",
       " 'V98_0.0',\n",
       " 'V98_Rare',\n",
       " 'V141_Rare',\n",
       " 'V141_0.0',\n",
       " 'V173_Rare',\n",
       " 'V173_0.0',\n",
       " 'V325_Rare',\n",
       " 'V325_0.0',\n",
       " 'V142_Rare',\n",
       " 'V142_0.0',\n",
       " 'V174_Rare',\n",
       " 'V174_0.0',\n",
       " 'V194_Rare',\n",
       " 'V194_1.0',\n",
       " 'V197_Rare',\n",
       " 'V197_1.0',\n",
       " 'V301_0.0',\n",
       " 'V301_Rare',\n",
       " 'V153_Rare',\n",
       " 'V153_1.0',\n",
       " 'V302_0.0',\n",
       " 'V302_1.0',\n",
       " 'V302_Rare',\n",
       " 'V304_0.0',\n",
       " 'V304_1.0',\n",
       " 'V304_Rare',\n",
       " 'V148_Rare',\n",
       " 'V148_1.0',\n",
       " 'V154_Rare',\n",
       " 'V154_1.0',\n",
       " 'V155_Rare',\n",
       " 'V155_1.0',\n",
       " 'V157_Rare',\n",
       " 'V157_1.0',\n",
       " 'V175_Rare',\n",
       " 'V175_0.0',\n",
       " 'V184_Rare',\n",
       " 'V184_0.0',\n",
       " 'V123_1.0',\n",
       " 'V123_Rare',\n",
       " 'V195_Rare',\n",
       " 'V195_1.0',\n",
       " 'V303_0.0',\n",
       " 'V303_1.0',\n",
       " 'V303_Rare',\n",
       " 'V138_Rare',\n",
       " 'V138_0.0',\n",
       " 'V328_Rare',\n",
       " 'V328_0.0',\n",
       " 'V146_Rare',\n",
       " 'V146_0.0',\n",
       " 'V156_Rare',\n",
       " 'V156_1.0',\n",
       " 'V327_Rare',\n",
       " 'V327_0.0',\n",
       " 'V158_Rare',\n",
       " 'V158_1.0',\n",
       " 'V198_Rare',\n",
       " 'V198_1.0',\n",
       " 'V147_Rare',\n",
       " 'V147_0.0',\n",
       " 'V185_Rare',\n",
       " 'V185_0.0',\n",
       " 'V181_Rare',\n",
       " 'V181_0.0',\n",
       " 'V169_Rare',\n",
       " 'V169_0.0',\n",
       " 'V188_Rare',\n",
       " 'V188_1.0',\n",
       " 'V107_1.0',\n",
       " 'V107_Rare',\n",
       " 'V117_1.0',\n",
       " 'V117_Rare',\n",
       " 'V118_1.0',\n",
       " 'V118_Rare',\n",
       " 'V119_1.0',\n",
       " 'V119_Rare',\n",
       " 'V120_1.0',\n",
       " 'V120_Rare',\n",
       " 'V121_1.0',\n",
       " 'V121_Rare',\n",
       " 'V122_1.0',\n",
       " 'V122_Rare',\n",
       " 'V108_1.0',\n",
       " 'V108_Rare',\n",
       " 'V109_1.0',\n",
       " 'V109_Rare',\n",
       " 'V110_1.0',\n",
       " 'V110_Rare',\n",
       " 'V111_1.0',\n",
       " 'V111_Rare',\n",
       " 'V112_1.0',\n",
       " 'V112_Rare',\n",
       " 'V113_1.0',\n",
       " 'V113_Rare',\n",
       " 'V114_1.0',\n",
       " 'V114_Rare',\n",
       " 'V115_1.0',\n",
       " 'V115_Rare',\n",
       " 'V116_1.0',\n",
       " 'V116_Rare',\n",
       " 'V124_1.0',\n",
       " 'V124_Rare',\n",
       " 'V125_1.0',\n",
       " 'V125_Rare',\n",
       " 'V104_0.0',\n",
       " 'V104_Rare',\n",
       " 'V149_Rare',\n",
       " 'V149_1.0',\n",
       " 'V139_Rare',\n",
       " 'V139_1.0',\n",
       " 'V252_Rare',\n",
       " 'V252_1.0',\n",
       " 'V242_Rare',\n",
       " 'V242_1.0',\n",
       " 'V262_Rare',\n",
       " 'V262_1.0',\n",
       " 'V223_Rare',\n",
       " 'V223_0.0',\n",
       " 'V235_Rare',\n",
       " 'V235_0.0',\n",
       " 'V260_Rare',\n",
       " 'V260_1.0',\n",
       " 'V241_Rare',\n",
       " 'V241_1.0',\n",
       " 'V240_Rare',\n",
       " 'V240_1.0',\n",
       " 'V247_Rare',\n",
       " 'V247_1.0',\n",
       " 'V248_Rare',\n",
       " 'V248_1.0',\n",
       " 'V249_Rare',\n",
       " 'V249_1.0',\n",
       " 'V191_Rare',\n",
       " 'V191_1.0',\n",
       " 'V172_Rare',\n",
       " 'V172_0.0',\n",
       " 'V189_Rare',\n",
       " 'V189_1.0',\n",
       " 'V239_Rare',\n",
       " 'V239_0.0',\n",
       " 'V251_Rare',\n",
       " 'V251_1.0',\n",
       " 'V251_0.0',\n",
       " 'V250_Rare',\n",
       " 'V250_1.0',\n",
       " 'V250_0.0',\n",
       " 'V238_Rare',\n",
       " 'V238_0.0',\n",
       " 'V7_1.0',\n",
       " 'V7_Rare',\n",
       " 'V6_1.0',\n",
       " 'V6_Rare',\n",
       " 'V1_1.0',\n",
       " 'V1_Rare',\n",
       " 'V39_0.0',\n",
       " 'V39_Rare',\n",
       " 'V39_1.0',\n",
       " 'V43_0.0',\n",
       " 'V43_Rare',\n",
       " 'V43_1.0',\n",
       " 'V47_1.0',\n",
       " 'V47_Rare',\n",
       " 'V51_0.0',\n",
       " 'V51_Rare',\n",
       " 'V51_1.0',\n",
       " 'V46_1.0',\n",
       " 'V46_Rare',\n",
       " 'V52_0.0',\n",
       " 'V52_Rare',\n",
       " 'V52_1.0',\n",
       " 'V75_1.0',\n",
       " 'V75_0.0',\n",
       " 'V75_Rare',\n",
       " 'V76_1.0',\n",
       " 'V76_0.0',\n",
       " 'V76_Rare',\n",
       " 'V54_1.0',\n",
       " 'V54_0.0',\n",
       " 'V54_Rare',\n",
       " 'V56_1.0',\n",
       " 'V56_Rare',\n",
       " 'V56_2.0',\n",
       " 'V61_1.0',\n",
       " 'V61_0.0',\n",
       " 'V61_Rare',\n",
       " 'V66_1.0',\n",
       " 'V66_Rare',\n",
       " 'V23_1.0',\n",
       " 'V23_Rare',\n",
       " 'V20_1.0',\n",
       " 'V20_0.0',\n",
       " 'V20_Rare',\n",
       " 'V281_0.0',\n",
       " 'V281_Rare',\n",
       " 'V282_0.0',\n",
       " 'V282_1.0',\n",
       " 'V282_2.0',\n",
       " 'V282_Rare',\n",
       " 'V288_0.0',\n",
       " 'V288_1.0',\n",
       " 'V288_Rare',\n",
       " 'V289_0.0',\n",
       " 'V289_1.0',\n",
       " 'V289_Rare',\n",
       " 'V300_0.0',\n",
       " 'V300_Rare',\n",
       " 'card1_(12932.0, 15066.0]',\n",
       " 'card1_(9749.0, 11366.8]',\n",
       " 'card1_(-inf, 2803.0]',\n",
       " 'card1_(2803.0, 4812.0]',\n",
       " 'card1_(16560.0, inf]',\n",
       " 'card1_(11366.8, 12932.0]',\n",
       " 'card1_(15066.0, 16560.0]',\n",
       " 'card1_(4812.0, 6951.0]',\n",
       " 'card1_(6951.0, 8178.2]',\n",
       " 'card1_(8178.2, 9749.0]',\n",
       " 'card3_(-inf, 150.0]',\n",
       " 'card3_(159.0, inf]',\n",
       " 'card3_Missing',\n",
       " 'card3_(150.0, 159.0]',\n",
       " 'card5_(126.0, 166.0]',\n",
       " 'card5_(224.0, 226.0]',\n",
       " 'card5_(166.0, 195.0]',\n",
       " 'card5_(195.0, 224.0]',\n",
       " 'card5_(-inf, 126.0]',\n",
       " 'card5_(226.0, inf]',\n",
       " 'card5_Missing',\n",
       " 'card2_(321.0, 361.0]',\n",
       " 'card2_(445.0, 490.0]',\n",
       " 'card2_(-inf, 112.0]',\n",
       " 'card2_(264.0, 321.0]',\n",
       " 'card2_(490.0, 543.0]',\n",
       " 'card2_(112.0, 194.0]',\n",
       " 'card2_(361.0, 445.0]',\n",
       " 'card2_(543.0, 555.0]',\n",
       " 'card2_(555.0, inf]',\n",
       " 'card2_(194.0, 264.0]',\n",
       " 'card2_Missing',\n",
       " 'dist1_(1.0, 2.0]',\n",
       " 'dist1_(36.0, 278.0]',\n",
       " 'dist1_Missing',\n",
       " 'dist1_(8.0, 12.0]',\n",
       " 'dist1_(-inf, 1.0]',\n",
       " 'dist1_(12.0, 18.0]',\n",
       " 'dist1_(6.0, 8.0]',\n",
       " 'dist1_(2.0, 4.0]',\n",
       " 'dist1_(18.0, 36.0]',\n",
       " 'dist1_(4.0, 6.0]',\n",
       " 'dist1_(278.0, inf]',\n",
       " 'D8_Missing',\n",
       " 'D8_(2.75, 14.367]',\n",
       " 'D8_(134.833, 234.842]',\n",
       " 'D8_(0.833, 2.75]',\n",
       " 'D8_(34.792, 76.667]',\n",
       " 'D8_(76.667, 134.833]',\n",
       " 'D8_(14.367, 34.792]',\n",
       " 'D8_(0.5, 0.833]',\n",
       " 'D8_(-inf, 0.5]',\n",
       " 'D8_(418.917, inf]',\n",
       " 'D8_(234.842, 418.917]',\n",
       " 'dist2_Missing',\n",
       " 'dist2_(16.0, 49.0]',\n",
       " 'dist2_(111.0, 187.0]',\n",
       " 'dist2_(714.0, inf]',\n",
       " 'dist2_(1.0, 7.0]',\n",
       " 'dist2_(7.0, 16.0]',\n",
       " 'dist2_(49.0, 111.0]',\n",
       " 'dist2_(-inf, 1.0]',\n",
       " 'dist2_(352.0, 714.0]',\n",
       " 'dist2_(187.0, 352.0]',\n",
       " 'V225_Missing',\n",
       " 'V225_(-inf, 1.0]',\n",
       " 'V225_(1.0, inf]',\n",
       " 'V193_Missing',\n",
       " 'V193_(-inf, 1.0]',\n",
       " 'V193_(1.0, inf]',\n",
       " 'V190_Missing',\n",
       " 'V190_(-inf, 1.0]',\n",
       " 'V190_(1.0, inf]',\n",
       " 'V170_Missing',\n",
       " 'V170_(-inf, 1.0]',\n",
       " 'V170_(2.0, 3.0]',\n",
       " 'V170_(3.0, inf]',\n",
       " 'V170_(1.0, 2.0]',\n",
       " 'V237_Missing',\n",
       " 'V237_(-inf, 1.0]',\n",
       " 'V237_(1.0, inf]',\n",
       " 'V176_Missing',\n",
       " 'V176_(-inf, 1.0]',\n",
       " 'V176_(1.0, 2.0]',\n",
       " 'V176_(2.0, inf]',\n",
       " 'V192_Missing',\n",
       " 'V192_(-inf, inf]',\n",
       " 'V199_Missing',\n",
       " 'V199_(-inf, 1.0]',\n",
       " 'V199_(1.0, 2.0]',\n",
       " 'V199_(2.0, inf]',\n",
       " 'V261_Missing',\n",
       " 'V261_(-inf, 1.0]',\n",
       " 'V261_(1.0, inf]',\n",
       " 'V171_Missing',\n",
       " 'V171_(-inf, 1.0]',\n",
       " 'V171_(2.0, 3.0]',\n",
       " 'V171_(3.0, inf]',\n",
       " 'V171_(1.0, 2.0]',\n",
       " 'V243_Missing',\n",
       " 'V243_(-inf, inf]',\n",
       " 'V254_Missing',\n",
       " 'V254_(-inf, inf]',\n",
       " 'V236_Missing',\n",
       " 'V236_(-inf, 1.0]',\n",
       " 'V236_(1.0, inf]',\n",
       " 'V246_Missing',\n",
       " 'V246_(-inf, inf]',\n",
       " 'V255_Missing',\n",
       " 'V255_(-inf, 1.0]',\n",
       " 'V255_(1.0, inf]',\n",
       " 'V256_Missing',\n",
       " 'V256_(-inf, 1.0]',\n",
       " 'V256_(1.0, inf]',\n",
       " 'V257_Missing',\n",
       " 'V257_(-inf, 2.0]',\n",
       " 'V257_(2.0, inf]',\n",
       " 'V227_Missing',\n",
       " 'V227_(-inf, inf]',\n",
       " 'V299_(-inf, inf]',\n",
       " 'V151_Missing',\n",
       " 'V151_(-inf, 16.0]',\n",
       " 'V151_(16.0, inf]',\n",
       " 'V182_Missing',\n",
       " 'V182_(-inf, 1.0]',\n",
       " 'V182_(1.0, inf]',\n",
       " 'V228_Missing',\n",
       " 'V228_(-inf, 2.0]',\n",
       " 'V228_(2.0, inf]',\n",
       " 'V201_Missing',\n",
       " 'V201_(-inf, 1.0]',\n",
       " 'V201_(1.0, 2.0]',\n",
       " 'V201_(2.0, inf]',\n",
       " 'V245_Missing',\n",
       " 'V245_(-inf, 1.0]',\n",
       " 'V245_(1.0, inf]',\n",
       " 'V290_(-inf, inf]',\n",
       " 'V283_(-inf, 1.0]',\n",
       " 'V283_(1.0, 2.0]',\n",
       " 'V283_(2.0, inf]',\n",
       " 'V283_Missing',\n",
       " 'V144_Missing',\n",
       " 'V144_(-inf, 1.0]',\n",
       " 'V144_(1.0, 11.0]',\n",
       " 'V144_(11.0, inf]',\n",
       " 'V180_Missing',\n",
       " 'V180_(-inf, 1.0]',\n",
       " 'V180_(1.0, inf]',\n",
       " 'V230_Missing',\n",
       " 'V230_(-inf, 2.0]',\n",
       " 'V230_(2.0, inf]',\n",
       " 'V253_Missing',\n",
       " 'V253_(-inf, inf]',\n",
       " 'V258_Missing',\n",
       " 'V258_(-inf, 2.0]',\n",
       " 'V258_(2.0, inf]',\n",
       " 'V259_Missing',\n",
       " 'V259_(-inf, 1.0]',\n",
       " 'V259_(1.0, inf]',\n",
       " 'V222_Missing',\n",
       " 'V222_(-inf, 1.0]',\n",
       " 'V222_(2.0, 3.0]',\n",
       " 'V222_(3.0, inf]',\n",
       " 'V222_(1.0, 2.0]',\n",
       " 'V221_Missing',\n",
       " 'V221_(-inf, 1.0]',\n",
       " 'V221_(1.0, 3.0]',\n",
       " 'V221_(3.0, inf]',\n",
       " 'V224_Missing',\n",
       " 'V224_(-inf, 1.0]',\n",
       " 'V224_(1.0, inf]',\n",
       " 'V226_Missing',\n",
       " 'V226_(-inf, inf]',\n",
       " 'V229_Missing',\n",
       " 'V229_(-inf, 2.0]',\n",
       " 'V229_(3.0, inf]',\n",
       " 'V229_(2.0, 3.0]',\n",
       " 'V296_(-inf, inf]',\n",
       " 'V296_Missing',\n",
       " 'V298_(-inf, inf]',\n",
       " 'V285_(2.0, 3.0]',\n",
       " 'V285_(-inf, 1.0]',\n",
       " 'V285_(1.0, 2.0]',\n",
       " 'V285_(3.0, inf]',\n",
       " 'V187_Missing',\n",
       " 'V187_(-inf, inf]',\n",
       " 'V234_Missing',\n",
       " 'V234_(-inf, 1.0]',\n",
       " 'V234_(1.0, inf]',\n",
       " 'V269_Missing',\n",
       " 'V269_(-inf, inf]',\n",
       " 'V292_(-inf, 2.0]',\n",
       " 'V292_(2.0, inf]',\n",
       " 'V291_(-inf, 2.0]',\n",
       " 'V291_(2.0, inf]',\n",
       " 'V145_Missing',\n",
       " 'V145_(-inf, 1.0]',\n",
       " 'V145_(1.0, 39.0]',\n",
       " 'V145_(39.0, inf]',\n",
       " 'V177_Missing',\n",
       " 'V177_(-inf, 1.0]',\n",
       " 'V177_(1.0, inf]',\n",
       " 'V167_Missing',\n",
       " 'V167_(-inf, 1.0]',\n",
       " 'V167_(1.0, 2.0]',\n",
       " 'V167_(2.0, inf]',\n",
       " 'V143_Missing',\n",
       " 'V143_(-inf, 1.0]',\n",
       " 'V143_(1.0, 13.0]',\n",
       " 'V143_(13.0, inf]',\n",
       " 'V179_Missing',\n",
       " 'V179_(-inf, 1.0]',\n",
       " 'V179_(1.0, inf]',\n",
       " 'V168_Missing',\n",
       " 'V168_(-inf, 1.0]',\n",
       " 'V168_(1.0, 3.0]',\n",
       " 'V168_(3.0, inf]',\n",
       " 'V178_Missing',\n",
       " 'V178_(-inf, 1.0]',\n",
       " 'V178_(1.0, inf]',\n",
       " 'V231_Missing',\n",
       " 'V231_(-inf, 1.0]',\n",
       " 'V231_(1.0, inf]',\n",
       " 'V217_Missing',\n",
       " 'V217_(-inf, 1.0]',\n",
       " 'V217_(1.0, 2.0]',\n",
       " 'V217_(2.0, inf]',\n",
       " 'V233_Missing',\n",
       " 'V233_(-inf, 1.0]',\n",
       " 'V233_(1.0, inf]',\n",
       " 'V232_Missing',\n",
       " 'V232_(-inf, 1.0]',\n",
       " 'V232_(1.0, inf]',\n",
       " 'V219_Missing',\n",
       " 'V219_(-inf, 1.0]',\n",
       " 'V219_(1.0, 2.0]',\n",
       " 'V219_(2.0, inf]',\n",
       " 'V218_Missing',\n",
       " 'V218_(-inf, 1.0]',\n",
       " 'V218_(1.0, 3.0]',\n",
       " 'V218_(3.0, inf]',\n",
       " 'V166_Missing',\n",
       " 'V166_(-inf, 100.0]',\n",
       " 'V166_(100.0, 1166.0]',\n",
       " 'V166_(1166.0, inf]',\n",
       " 'V164_Missing',\n",
       " 'V164_(-inf, 50.0]',\n",
       " 'V164_(50.0, 1265.0]',\n",
       " 'V164_(1265.0, inf]',\n",
       " 'V129_(-inf, inf]',\n",
       " 'V129_Missing',\n",
       " 'V293_(-inf, inf]',\n",
       " 'V279_(-inf, 1.0]',\n",
       " 'V279_(1.0, inf]',\n",
       " 'V295_(-inf, inf]',\n",
       " 'V165_Missing',\n",
       " 'V165_(-inf, 100.0]',\n",
       " 'V165_(100.0, 7245.0]',\n",
       " 'V165_(7245.0, inf]',\n",
       " 'V280_(-inf, 1.0]',\n",
       " 'V280_(2.0, inf]',\n",
       " 'V280_(1.0, 2.0]',\n",
       " 'V150_Missing',\n",
       " 'V150_(-inf, 133.7]',\n",
       " 'V150_(133.7, inf]',\n",
       " 'V135_(-inf, inf]',\n",
       " 'V135_Missing',\n",
       " 'V294_(-inf, 1.0]',\n",
       " 'V294_(1.0, inf]',\n",
       " 'V137_(-inf, inf]',\n",
       " 'V137_Missing',\n",
       " 'V206_Missing',\n",
       " 'V206_(-inf, inf]',\n",
       " 'V159_Missing',\n",
       " 'V159_(-inf, 1459.5]',\n",
       " 'V159_(1459.5, inf]',\n",
       " 'V136_(-inf, inf]',\n",
       " 'V136_Missing',\n",
       " 'V266_Missing',\n",
       " 'V266_(-inf, inf]',\n",
       " 'V131_(-inf, 70.0]',\n",
       " 'V131_(70.0, inf]',\n",
       " 'V131_Missing',\n",
       " 'V205_Missing',\n",
       " 'V205_(-inf, inf]',\n",
       " 'V132_(-inf, inf]',\n",
       " 'V132_Missing',\n",
       " 'V270_Missing',\n",
       " 'V270_(-inf, inf]',\n",
       " 'V160_Missing',\n",
       " 'V160_(-inf, 50.0]',\n",
       " 'V160_(50.0, 67703.742]',\n",
       " 'V160_(67703.742, inf]',\n",
       " 'V272_Missing',\n",
       " 'V272_(-inf, inf]',\n",
       " 'V208_Missing',\n",
       " 'V208_(-inf, 15.0]',\n",
       " 'V208_(15.0, inf]',\n",
       " 'V210_Missing',\n",
       " 'V210_(-inf, 17.503]',\n",
       " 'V210_(17.503, inf]',\n",
       " 'V276_Missing',\n",
       " 'V276_(-inf, inf]',\n",
       " 'V214_Missing',\n",
       " 'V214_(-inf, 10.0]',\n",
       " 'V214_(10.0, inf]',\n",
       " 'V268_Missing',\n",
       " 'V268_(-inf, 15.0]',\n",
       " 'V268_(15.0, inf]',\n",
       " 'V271_Missing',\n",
       " 'V271_(-inf, inf]',\n",
       " 'V278_Missing',\n",
       " 'V278_(-inf, 15.559]',\n",
       " 'V278_(15.559, inf]',\n",
       " 'V134_(-inf, inf]',\n",
       " 'V134_Missing',\n",
       " 'V216_Missing',\n",
       " 'V216_(-inf, 25.0]',\n",
       " 'V216_(25.0, inf]',\n",
       " 'V277_Missing',\n",
       " 'V277_(-inf, 24.013]',\n",
       " 'V277_(24.013, inf]',\n",
       " 'V209_Missing',\n",
       " 'V209_(-inf, 23.481]',\n",
       " 'V209_(23.481, inf]',\n",
       " 'V207_Missing',\n",
       " 'V207_(-inf, 20.0]',\n",
       " 'V207_(20.0, inf]',\n",
       " 'V215_Missing',\n",
       " 'V215_(-inf, 29.243]',\n",
       " 'V215_(29.243, inf]',\n",
       " 'V267_Missing',\n",
       " 'V267_(-inf, 30.0]',\n",
       " 'V267_(30.0, inf]',\n",
       " 'V126_(-inf, 59.0]',\n",
       " 'V126_(59.0, inf]',\n",
       " 'V126_Missing',\n",
       " 'V133_(-inf, inf]',\n",
       " 'V133_Missing',\n",
       " 'V128_(-inf, 44.0]',\n",
       " 'V128_(44.0, 156.0]',\n",
       " 'V128_(156.0, inf]',\n",
       " 'V128_Missing',\n",
       " 'V273_Missing',\n",
       " 'V273_(-inf, 51.526]',\n",
       " 'V273_(51.526, inf]',\n",
       " 'V275_Missing',\n",
       " 'V275_(-inf, 65.332]',\n",
       " 'V275_(65.332, inf]',\n",
       " 'V130_(107.95, 246.812]',\n",
       " 'V130_(-inf, 31.95]',\n",
       " 'V130_(246.812, inf]',\n",
       " 'V130_(31.95, 107.95]',\n",
       " 'V130_Missing',\n",
       " 'V211_Missing',\n",
       " 'V211_(-inf, 53.963]',\n",
       " 'V211_(53.963, inf]',\n",
       " 'V127_(61.9, 151.0]',\n",
       " 'V127_(-inf, 61.9]',\n",
       " 'V127_(151.0, 363.75]',\n",
       " 'V127_(363.75, inf]',\n",
       " 'V127_Missing',\n",
       " 'V274_Missing',\n",
       " 'V274_(-inf, 75.0]',\n",
       " 'V274_(75.0, inf]',\n",
       " 'V213_Missing',\n",
       " 'V213_(-inf, 69.725]',\n",
       " 'V213_(69.725, inf]',\n",
       " 'V212_Missing',\n",
       " 'V212_(-inf, 79.11]',\n",
       " 'V212_(79.11, inf]',\n",
       " 'V263_Missing',\n",
       " 'V263_(-inf, 40.744]',\n",
       " 'V263_(150.0, inf]',\n",
       " 'V263_(40.744, 150.0]',\n",
       " 'V202_Missing',\n",
       " 'V202_(-inf, 37.878]',\n",
       " 'V202_(37.878, 150.0]',\n",
       " 'V202_(150.0, inf]',\n",
       " 'V265_Missing',\n",
       " 'V265_(-inf, 53.341]',\n",
       " 'V265_(178.162, inf]',\n",
       " 'V265_(53.341, 178.162]',\n",
       " 'V204_Missing',\n",
       " 'V204_(-inf, 50.0]',\n",
       " 'V204_(50.0, 177.477]',\n",
       " 'V204_(177.477, inf]',\n",
       " 'V264_Missing',\n",
       " 'V264_(-inf, 13.092]',\n",
       " 'V264_(13.092, 71.997]',\n",
       " 'V264_(200.0, inf]',\n",
       " 'V264_(71.997, 200.0]',\n",
       " 'V203_Missing',\n",
       " 'V203_(-inf, 3.363]',\n",
       " 'V203_(65.928, 200.0]',\n",
       " 'V203_(3.363, 65.928]',\n",
       " 'V203_(200.0, inf]',\n",
       " 'V200_Missing',\n",
       " 'V200_(-inf, 1.0]',\n",
       " 'V200_(1.0, 2.0]',\n",
       " 'V200_(2.0, inf]',\n",
       " 'V106_(-inf, 1.0]',\n",
       " 'V106_(1.0, inf]',\n",
       " 'V106_Missing',\n",
       " 'V105_(-inf, 1.0]',\n",
       " 'V105_(1.0, inf]',\n",
       " 'V105_Missing',\n",
       " 'V161_Missing',\n",
       " 'V161_(-inf, inf]',\n",
       " 'V163_Missing',\n",
       " 'V163_(-inf, inf]',\n",
       " 'V162_Missing',\n",
       " 'V162_(-inf, inf]',\n",
       " 'V101_(-inf, 1.0]',\n",
       " 'V101_(1.0, inf]',\n",
       " 'V101_Missing',\n",
       " 'V103_(-inf, 1.0]',\n",
       " 'V103_(1.0, inf]',\n",
       " 'V103_Missing',\n",
       " 'V102_(-inf, 2.0]',\n",
       " 'V102_(2.0, inf]',\n",
       " 'V102_Missing',\n",
       " 'V152_Missing',\n",
       " 'V152_(-inf, 2.0]',\n",
       " 'V152_(2.0, 60.0]',\n",
       " 'V152_(60.0, 68.0]',\n",
       " 'V152_(68.0, inf]',\n",
       " 'V140_Missing',\n",
       " 'V140_(-inf, 1.0]',\n",
       " 'V140_(3.0, inf]',\n",
       " 'V140_(1.0, 2.0]',\n",
       " 'V140_(2.0, 3.0]',\n",
       " 'V244_Missing',\n",
       " 'V244_(-inf, 2.0]',\n",
       " 'V244_(2.0, inf]',\n",
       " 'V196_Missing',\n",
       " 'V196_(-inf, 1.0]',\n",
       " 'V196_(1.0, inf]',\n",
       " 'V186_Missing',\n",
       " 'V186_(-inf, 1.0]',\n",
       " 'V186_(1.0, 2.0]',\n",
       " 'V186_(2.0, inf]',\n",
       " 'V183_Missing',\n",
       " 'V183_(-inf, 1.0]',\n",
       " 'V183_(1.0, inf]',\n",
       " 'V220_Missing',\n",
       " 'V220_(-inf, 1.0]',\n",
       " 'V220_(1.0, inf]',\n",
       " 'D5_(10.0, 13.0]',\n",
       " 'D5_(67.0, 120.0]',\n",
       " 'D5_Missing',\n",
       " 'D5_(120.0, 255.0]',\n",
       " 'D5_(255.0, inf]',\n",
       " 'D5_(-inf, 1.0]',\n",
       " 'D5_(20.0, 27.0]',\n",
       " 'D5_(5.0, 7.0]',\n",
       " 'D5_(32.0, 44.0]',\n",
       " 'D5_(44.0, 67.0]',\n",
       " 'D5_(3.0, 5.0]',\n",
       " 'D5_(15.2, 20.0]',\n",
       " 'D5_(1.0, 2.0]',\n",
       " 'D5_(27.0, 32.0]',\n",
       " 'D5_(7.0, 10.0]',\n",
       " 'D5_(2.0, 3.0]',\n",
       " 'D5_(13.0, 15.2]',\n",
       " 'V37_(-inf, 1.0]',\n",
       " 'V37_Missing',\n",
       " 'V37_(1.0, 2.0]',\n",
       " 'V37_(2.0, inf]',\n",
       " 'V38_(-inf, 1.0]',\n",
       " 'V38_Missing',\n",
       " 'V38_(1.0, 2.0]',\n",
       " 'V38_(2.0, inf]',\n",
       " 'V44_(-inf, 1.0]',\n",
       " 'V44_Missing',\n",
       " 'V44_(1.0, 2.0]',\n",
       " 'V44_(2.0, inf]',\n",
       " 'V45_(-inf, 1.0]',\n",
       " 'V45_Missing',\n",
       " 'V45_(1.0, 2.0]',\n",
       " 'V45_(2.0, inf]',\n",
       " 'V78_(-inf, 1.0]',\n",
       " 'V78_Missing',\n",
       " 'V78_(1.0, 2.0]',\n",
       " 'V78_(2.0, inf]',\n",
       " 'V99_(1.0, 2.0]',\n",
       " 'V99_(-inf, 1.0]',\n",
       " 'V99_(3.0, 4.0]',\n",
       " 'V99_(4.0, inf]',\n",
       " 'V99_(2.0, 3.0]',\n",
       " 'V99_Missing',\n",
       " 'V95_(-inf, 1.0]',\n",
       " 'V95_(1.0, inf]',\n",
       " 'V95_Missing',\n",
       " 'V96_(1.0, 2.0]',\n",
       " 'V96_(-inf, 1.0]',\n",
       " 'V96_(3.0, 6.0]',\n",
       " 'V96_(2.0, 3.0]',\n",
       " 'V96_(6.0, inf]',\n",
       " 'V96_Missing',\n",
       " 'V97_(-inf, 1.0]',\n",
       " 'V97_(1.0, 3.0]',\n",
       " 'V97_(3.0, inf]',\n",
       " 'V97_Missing',\n",
       " 'V100_(-inf, 1.0]',\n",
       " 'V100_(1.0, inf]',\n",
       " 'V100_Missing',\n",
       " 'TransactionAmt_(68.95, 100.0]',\n",
       " 'TransactionAmt_(26.31, 35.95]',\n",
       " 'TransactionAmt_(35.95, 57.95]',\n",
       " 'TransactionAmt_(57.95, 68.95]',\n",
       " 'TransactionAmt_(117.0, 276.15]',\n",
       " 'TransactionAmt_(100.0, 117.0]',\n",
       " 'TransactionAmt_(-inf, 26.31]',\n",
       " 'TransactionAmt_(276.15, inf]',\n",
       " 'addr1_(-inf, 444.0]',\n",
       " 'addr1_(444.0, inf]',\n",
       " 'addr1_Missing',\n",
       " 'P_emaildomain_gmail.com',\n",
       " 'P_emaildomain_aol.com',\n",
       " 'P_emaildomain_Missing',\n",
       " 'P_emaildomain_yahoo.com',\n",
       " 'P_emaildomain_Rare',\n",
       " 'P_emaildomain_anonymous.com',\n",
       " 'P_emaildomain_hotmail.com',\n",
       " 'R_emaildomain_Missing',\n",
       " 'R_emaildomain_Rare',\n",
       " 'R_emaildomain_gmail.com',\n",
       " 'R_emaildomain_hotmail.com',\n",
       " 'C1_(-inf, 1.0]',\n",
       " 'C1_(4.0, 7.0]',\n",
       " 'C1_(2.0, 4.0]',\n",
       " 'C1_(7.0, inf]',\n",
       " 'C1_(1.0, 2.0]',\n",
       " 'C2_(1.0, 2.0]',\n",
       " 'C2_(4.0, 7.0]',\n",
       " 'C2_(-inf, 1.0]',\n",
       " 'C2_(2.0, 4.0]',\n",
       " 'C2_(7.0, inf]',\n",
       " 'C4_(-inf, 0.0]',\n",
       " 'C4_(0.0, 1.0]',\n",
       " 'C4_(1.0, inf]',\n",
       " 'C5_(-inf, 0.0]',\n",
       " 'C5_(1.0, 3.0]',\n",
       " 'C5_(0.0, 1.0]',\n",
       " 'C5_(3.0, inf]',\n",
       " 'C6_(-inf, 1.0]',\n",
       " 'C6_(2.0, 5.0]',\n",
       " 'C6_(1.0, 2.0]',\n",
       " 'C6_(5.0, inf]',\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "[str(sentence).replace(\"' \",\" \") for sentence in litraincol]\n",
    "[str(sentence).replace(\"' \",\" \") for sentence in livalidcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in [\"-\",\".\",\" \",\"(\",\"]\"]:\n",
    "    litraincol = [str(x).replace(a,\"_\") for x in litraincol]\n",
    "    livalidcol = [str(x).replace(a,\"_\") for x in livalidcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in [\"_0_\",\"__\",\"_0,\"]:\n",
    "    litraincol = [str(x).replace(a,\"_\") for x in litraincol]\n",
    "    livalidcol = [str(x).replace(a,\"_\") for x in livalidcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in [\",\"]:\n",
    "    litraincol = [str(x).replace(a,\"_\") for x in litraincol]\n",
    "    livalidcol = [str(x).replace(a,\"_\") for x in livalidcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns = litraincol\n",
    "x_valid.columns = livalidcol\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = LGBMClassifier()\n",
    "model5.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvEAAAGbCAYAAABNv89AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZRcZZ3/8feHBBNQBAV1IqiNGnSEKGhERxTBFcVRGBFhGCX6c/jhMi4zLqC/UdRhjOK44YKIgjooCsiIoALDEEUclwQDAQFliZqIgKhBViX5/v6o21C01d2Vratv9/t1Tp3Ufe5zn/utS53Dp556bnWqCkmSJEntscmgC5AkSZK0dgzxkiRJUssY4iVJkqSWMcRLkiRJLWOIlyRJklpm5qALkCbaNttsU0NDQ4MuQ5IkaVxLliz5bVU9YGS7IV7TztDQEIsXLx50GZIkSeNK8ote7S6nkSRJklrGEC9JkiS1jCFekiRJahlDvCRJktQyhnhJkiSpZQzxkiRJUssY4iVJkqSWMcRLkiRJLeMfe9K0s2zlKoYOO3PQZUiSpJZavnDvQZfgTLwkSZLUNoZ4SZIkqWUM8ZIkSVLLGOIlSZKkljHES5IkSS1jiJckSZJaZqOE+CRbJ1naPH6TZGXX9r02xjn7rGurJK/p2n5wklPWc8xdklSS567DsXskeUof/d6Y5OXN85ckuTTJmiTzu/psneS8JDcn+XhX+xZd135pkt8m+cgo5zk8yZVJrujn9SQ5KsnlSS5OclqSrZr2g0acc02SnZt990pybJKfNce+uMe4PV9Ls29RU9/w2A9s2t+U5Jcj+0uSJE1FG+V34qvqRmA4tB0B3FxVHxzen2RmVd25Mc49jq2A1wCfbOr8NbDfeo55IPC95t+z1vLYPYCbge+P1iHJTOCVwOObpkuAvwM+PaLr7cC/Ajs1DwCq6o80/y2a8ZYAX+txnscABwA7Ag8G/jvJDlW1eoz6zwEOr6o7k7wfOBx4W1WdCJzYjDsP+HpVLW2OeQdwfVXtkGQT4P49xu35WrocVFWLuxuq6sNJfg/M79FfkiRpSpmw5TRJTkjyoSTnAe9PsmuS7yf5SfPvo5p+C5J8Lcm3k/w8yQea9hnNGJckWZbkTU37Pyb5cZKLkpyaZPOm/UHN7PBFzeMpwELgEc0M7lFJhpJc0vSfneT4ZuyfJNlzrHqafaHzIWAB8Jwks5v2oWaW+bim3hOTPCvJBc0YuyYZAg4F3tTU87RRLt0zgAuHP/RU1WVVdcXITlV1S1V9j04AHu2/wVzggcD5PXa/CDipqu6oqmuAK4FdRxurOefZXR/GfgBs16PbgcCXu7ZfCbyvOX5NVf12XV7L2kpySJLFSRavvnXVhhpWkiRpICb6L7buADyrqlYnuS+wezOL+yzg34HhpRU7A7sAdwBXJDmaTvjctqp2gs7SmKbv16rqM03bvwH/Bzga+BjwnaraN8kM4D7AYcBOVTX8LcFQV22vBaiqeUkeDZydZIfR6qmqXwG7AddU1VVJFgHP5+5Z7kcCLwEOAX4M/D3wVOCFwNurap8kxzDiW4oedgOWjHdh+3Qg8JWqqh77tqUTxIetaNr69UrgKz3aX0rnA0L3f7P3JtkDuAp4XVVdtxbnATg+yWrgVODfRnk991BVxwLHAsyaM3fc/pIkSZPZRN/YenLX8owtgZObmfAP01nGMezcqlpVVbcDPwUeBlwNPDzJ0Un2Am5q+u6U5Pwky4CDusZ5BvApgKpaXVXjTb8+Ffhi0/9y4Bd0PnSMVg90QvFJzfOTmu1h11TVsqpaA1zajFHAMmBonFq6zQFuWIv+YzmAe86Kd0uPtr7CbpJ3AHfSLKHpan8ScGtVXdI0zaQzW39BVT0e+F9grA8wvRxUVfOApzWPl63l8ZIkSa030SH+lq7n7wXOa2bW/xaY3bXvjq7nq4GZVfV74HHAIjqz5sc1+0+gM5s7D3j3iHHWRq8QO2o9zez+i4F3JllOZ/b/eUm26HHMmq7tNazdNyC3se6v6S5JHkfnOo42q78CeEjX9nbAr/sY92DgBXTC9cjQP/JDw43ArcBpzfbJ3L3Wvy9VtbL594/AlxhnyY8kSdJUNMifmNwSWNk8XzBe5yTbAJtU1al0bnocDn9bANcm2ZTOTPywc4FXN8fOaJbv/LHp38t3h49vltE8FPiLteddngVcVFUPqaqhqnoYneUd+4z3WrqMVc+wy+gszVlfI9emj3Q6cECSWUm2B+YCPwJI8oUkfxGWm29E3ga8sKpuHbFvEzrLiYa/qaAJ+d+gc0MvwDPpfLPRlyQzm/cBzX/vF9C50VeSJGlaGWSI/wDwviQXADP66L8tsCjJUjqz74c37f8K/JDOL6Vc3tX/DcCezTKbJcCOza/mXNDcbHrUiPE/Ccxo+n8FWFBVdzC6A7l7RnnYqXTWvvfrG8C+49zY+i1g9+GNJPsmWQH8DXBmkrO69i0HPgQsSLKi+cWZYfszIsQneWGS9wBU1aXAV+mE6m8Dr+1a+vRY4NoetX2czoeQc5rXcEzXvt2BFVV19Yhj3gYckeRiOkth/mVkLWO8llnAWc2xS+l8CPxMj7okSZKmtPRxT6AGLMlpwFur6ucDOPd9gc9W1Usm+txrK8kCYH5VvW6sfrPmzK05B/f8qXxJkqRxLV+494SdK8mSqvqLn9D2L7a2w2F0bnCdcFV1U0sC/JvofDtz03h9JUmS2m6if2JSo2h+4WVkWD65qo5sfhd+rPX5015VfZjOrxxJkiRNeYb4SaKqjgSOHHQdkiRJmvwM8Zp25m27JYsncC2bJEnShuaaeEmSJKllDPGSJElSyxjiJUmSpJYxxEuSJEktY4iXJEmSWsYQL0mSJLWMIV6SJElqGUO8JEmS1DKGeEmSJKllDPGSJElSyxjiJUmSpJYxxEuSJEktY4iXJEmSWsYQL0mSJLWMIV6SJElqGUO8JEmS1DKGeEmSJKllDPGSJElSy8wcdAHSRFu2chVDh5056DIkSdJ6Wr5w70GXMDDOxEuSJEktY4iXJEmSWsYQL0mSJLWMIV6SJElqGUO8JEmS1DKGeEmSJKllJmWIT7J1kqXN4zdJVnZt32uAdW2V5DVd2w9Ocsp6jrlLkkry3HU4do8kT+mj3xuTvLx5flSSy5NcnOS0JFs17Qd1XeOlSdYk2bnZd68kxyb5WXPsi3ucY+sk5yW5OcnHR+xblOSKrrEfOE6985N8rI/X9foklyU5MclLk1yZ5IzxjpMkSWq7Sfk78VV1IzAcII8Abq6qDw7vTzKzqu4cQGlbAa8BPtnU+Wtgv/Uc80Dge82/Z63lsXsANwPfH61DkpnAK4HHN03nAIdX1Z1J3g8cDrytqk4ETmyOmQd8vaqWNse8A7i+qnZIsglw/x6nuh34V2Cn5jHSQVW1uJ8X1fTrp+9rgOdV1TVN3dcBb+7nHJIkSW02KWfie0lyQpIPJTkPeH+SXZN8P8lPmn8f1fRbkORrSb6d5OdJPtC0z2jGuCTJsiRvatr/McmPk1yU5NQkmzftD2pmqi9qHk8BFgKPaGaTj0oylOSSpv/sJMc3Y/8kyZ5j1dPsC50PAQuA5ySZ3bQPNTPexzX1npjkWUkuaMbYNckQcCjwpqaep41y6Z4BXDj8oaeqzu76APQDYLsexxwIfLlr+5XA+5rj11TVb0ceUFW3VNX36IT59dJ8w3BG8/yIJJ9rZvOvTvL6pv0Y4OHA6cP/LccZ85Aki5MsXn3rqvUtUZIkaaAm5Uz8GHYAnlVVq5PcF9i9mVF+FvDvwPAyj52BXYA7gCuSHA08ENi2qnaCztKYpu/XquozTdu/Af8HOBr4GPCdqto3yQzgPsBhwE5VNfwtwVBXba8FqKp5SR4NnJ1kh9HqqapfAbsB11TVVUkWAc8HvtYc80jgJcAhwI+BvweeCrwQeHtV7dME2Xt8S9HDbsCSUfa9EvhKj/aXAi8acZ3em2QP4CrgdVV13Rjn7OX4JKuBU4F/q6pai2MfDewJbEHn+n2qqg5NshewZ68PFSNV1bHAsQCz5sxdm3NLkiRNOq2ZiW+cXFWrm+dbAic3M+EfBnbs6nduVa2qqtuBnwIPA64GHp7k6Cb83dT03SnJ+UmWAQd1jfMM4FMAVbW6qsabvn0q8MWm/+XAL+h86BitHujMeJ/UPD+p2R52TVUtq6o1wKXNGAUsA4bGqaXbHOCGkY1J3gHcSbOEpqv9ScCtVXVJ0zSTzmz9BVX1eOB/gbE+NPRyUFXNA57WPF62lsefWVV3NGH9euBBa3m8JEnSlNK2EH9L1/P3Auc1M+t/C8zu2ndH1/PVwMyq+j3wOGARnVnz45r9J9CZWZ4HvHvEOGsjY+z7i3qa2f0XA+9MspzO7P/zkmzR45g1XdtrWLtvUG5jxGtKcjDwAjrheuSs9AHccynNjcCtwGnN9sncvb6+L1W1svn3j8CXgF3X5nh6XL+1PF6SJGlKaVuI77YlsLJ5vmC8zkm2ATapqlPp3IA5HES3AK5Nsimdmfhh5wKvbo6d0Szf+WPTv5fvDh/fLKN5KHDFGCU9C7ioqh5SVUNV9TA6S032Ge+1dBmrnmGX0VmaQ1PbXsDbgBdW1a3dHZubVl/C3d8O0IT8b9C5iRbgmXS+TehLkpnNtae5xi8Ahu8j2DfJ+/odS5IkSR1tDvEfAN6X5AJgRh/9twUWJVlKZ/b98Kb9X4Ef0vnVlsu7+r8B2LNZZrME2LH51ZwLmptNjxox/ieBGU3/rwALquoORncgd89uDzuVztr3fn0D2HecG1u/Bezetf1xOsH/nOa4Y7r27Q6sqKqrR4zxNuCIJBfTWQrzLwBJXpjkPcOdmm8UPgQsSLIiyWOAWcBZzbFL6Xzw+kxzyCO4e1mTJEmS+pS1u79QbZTkNOCtVfXzQdfSLcl/Am+qqr9Ys7+O4+0BvLmqXjBWv1lz5tacgz+yIU4pSZIGaPnCvQddwkaXZElVzR/Z3uaZePXvMDo3uE4qVfUPGzDAv5TOtyG/3xDjSZIkTWbeIDhFNL8285IRzSdX1ZFVdQVjr89vvar6Cr1/LlOSJGnKMcRPEVV1JHDkoOuQJEnSxmeI17Qzb9stWTwN1tBJkqSpyzXxkiRJUssY4iVJkqSWMcRLkiRJLWOIlyRJklrGEC9JkiS1jCFekiRJahlDvCRJktQyhnhJkiSpZQzxkiRJUssY4iVJkqSWMcRLkiRJLWOIlyRJklrGEC9JkiS1jCFekiRJahlDvCRJktQyhnhJkiSpZQzxkiRJUssY4iVJkqSWmTnoAqSJtmzlKoYOO3PQZUiStFEsX7j3oEvQBHAmXpIkSWoZQ7wkSZLUMoZ4SZIkqWUM8ZIkSVLLGOIlSZKkljHES5IkSS1jiFffkixPsk3zfKskpyS5PMllSf5mgmo4Icl+zfPjkjymef72iTi/JEnSZGCIV09JxvsbAh8Fvl1VjwYeB1y2HueasS7HVdWrquqnzaYhXpIkTRv+sadpIMnLgTcDBVwMfBX4f8C9gBuBg6rquiRHAA8GhoDfJvkn4MvAA4AfAWnGuy+wO7AAoKr+BPxpjPM/EjimGWc18BLgIcC7gGuBnZPMAxYCewCzgE9U1aeTBDgaeAZwzXANzbiLmte1H7BZkqXApVV1UI8aDgEOAZhx3wf0d+EkSZImKUP8FJdkR+AdwG5V9dsk96cT5p9cVZXkVcBbgX9pDnkC8NSqui3Jx4DvVdV7kuxNE4KBhwM3AMcneRywBHhDVd0yShknAgur6rQks+l8A/QQYFdgp6q6pgnZq6rqiUlmARckORvYBXgUMA94EPBT4HPdg1fVYUleV1U7j3YdqupY4FiAWXPmVn9XT5IkaXJyOc3U9wzglKr6LUBV/Q7YDjgryTLgLcCOXf1Pr6rbmue7A//ZHHcm8PumfSbweOBTVbULcAtwWK+TJ9kC2LaqTmvGub2qbm12/6iqrmmePwd4eTOb/kNga2BuU8OXq2p1Vf0a+J91vxSSJElTgyF+6gudmfduRwMfr6p5wP8FZnftGzmb3mvWegWwoqp+2GyfQifUj3b+0XSfK8A/VdXOzWP7qjp7jBokSZKmLUP81HcusH+SrQGa5TRbAiub/QePcex3gYOa454H3A+gqn4D/CrJo5p+z6SzzOUvVNVNwIok+zTjzEqyeY+uZwGvTrJp02+HJPduajggyYwkc4A9R6n1z8PHSpIkTXWuiZ/iqurSJEcC30myGvgJcARwcpKVwA+A7Uc5/N3Al5NcCHwH+GXXvn8CTkxyL+Bq4BVjlPEy4NNJ3gP8mc6NrSMdR+eG2gubm1lvAPYBTqOzJGgZ8LOmjl6OBS5OcmGvG1slSZKmklS5UkHTy6w5c2vOwR8ZdBmSJG0UyxfuPegStAElWVJV80e2u5xGkiRJahmX02iDSfIJYLcRzR+tquMHUY8kSdJUZYjXBlNVrx10DZIkSdOBIV7Tzrxtt2Sx6wUlSVKLuSZekiRJahlDvCRJktQyhnhJkiSpZQzxkiRJUssY4iVJkqSWMcRLkiRJLWOIlyRJklrGEC9JkiS1jCFekiRJahlDvCRJktQyhnhJkiSpZQzxkiRJUssY4iVJkqSWMcRLkiRJLWOIlyRJklrGEC9JkiS1jCFekiRJahlDvCRJktQyMwddgDTRlq1cxdBhZw66DEnSBFq+cO9BlyBtUM7ES5IkSS1jiJckSZJaxhAvSZIktYwhXpIkSWoZQ7wkSZLUMoZ4SZIkqWUM8S2W5K+SnJTkqiQ/TfLNJDs0+76d5A9JzhhxzGeTXJTk4iSnJLnPOOfYJ8k7R9n3zSRbjXP8o5MsTfKTJI8Yo9/rklyZpJJsM0a/g5P8vHkc3NV+YpLfJdlvrHokSZKmAkN8SyUJcBqwqKoeUVWPAd4OPKjpchTwsh6HvqmqHldVjwV+CbxunFO9Ffhkrx1V9fyq+sM4x+8DfL2qdqmqq8bodwHwLOAXo3VIcn/gXcCTgF2BdyW5X1PLQcDp49QiSZI0JRji22tP4M9VdcxwQ1Utrarzm+fnAn8ceVBV3QR3fQjYDKjRTtDM6t9RVb8dZf/yJNskGUpyWZLPJLk0ydlJNkvyfOCNwKuSnDfWi6mqn1TV8nFe83OBc6rqd1X1e+AcYK9xjhmu9ZAki5MsXn3rqn4OkSRJmrQM8e21E7BkXQ5McjzwG+DRwNFjdN0NuLDPYecCn6iqHYE/AC+uqm8CxwAfrqo916XWEbYFftW1vaJpG1dVHVtV86tq/ozNt9wApUiSJA2OIX4aqqpXAA8GLgNeOkbXOcANfQ57TVUtbZ4vAYbWucDRpUfbqN8kSJIkTVWG+Pa6FHjCuh5cVauBrwAvHqPbbcBsgCQzmhtUlyZ5T4++d3Q9Xw3MXNfaxrACeEjX9nbArzfCeSRJkiY1Q3x7/Q8wK8k/DjckeWKSp492QDoeOfwc+Fvg8jHOcRnwSOiE/qrauXn0/LWafiQ5N0lfS2B6OAt4TpL7NTe0PqdpkyRJmlYM8S1VVQXsCzy7+YnJS4EjaGamk5wPnAw8M8mKJM+lsxzl80mWAcvoLJfpNas+7LvALk3gX29JNqHzoeB3Pfa9PskKOrPrFyc5rmmfP/y8qn4HvBf4cfN4T9MmSZI0raSTBaXeknwU+EZV/fcGGGsn4JVV9c/rX1nP8U8AzqiqU8bqN2vO3Jpz8Ec2RgmSpElq+cK9B12CtE6SLKmq+SPbnYnXeP4d2HxDDFRVl2zEAH8i8HTg9o0xviRJ0mSyMW4+VMskeQXwhhHNF1TVa6vqOlrwR5SaP/YkSZI0LRjiRVUdDxw/6DokSZLUH0O8pp15227JYtdGSpKkFnNNvCRJktQyhnhJkiSpZQzxkiRJUssY4iVJkqSWMcRLkiRJLWOIlyRJklrGEC9JkiS1jCFekiRJahlDvCRJktQyhnhJkiSpZQzxkiRJUssY4iVJkqSWMcRLkiRJLWOIlyRJklrGEC9JkiS1jCFekiRJahlDvCRJktQyhnhJkiSpZWYOugBpoi1buYqhw84cdBmSpHWwfOHegy5BmhSciZckSZJaxhAvSZIktYwhXpIkSWoZQ7wkSZLUMoZ4SZIkqWUM8ZIkSVLLGOI14ZJUki92bc9MckOSM7ra9kiyNMmlSb4zznirm77Dj6GNV70kSdLg+TvxGoRbgJ2SbFZVtwHPBlYO70yyFfBJYK+q+mWSB44z3m1VtfPGK1eSJGlycSZeg/ItYPgvdhwIfLlr398DX6uqXwJU1fUTXJskSdKkZojXoJwEHJBkNvBY4Idd+3YA7pdkUZIlSV4+zlibdS2lOa1XhySHJFmcZPHqW1dtmFcgSZI0IC6n0UBU1cXN2vUDgW+O2D0TeALwTGAz4H+T/KCqfjbKcOMup6mqY4FjAWbNmVvrUbokSdLAGeI1SKcDHwT2ALbual8B/LaqbgFuSfJd4HHAaCFekiRpWnE5jQbpc8B7qmrZiPavA09rfrVmc+BJwGUTXp0kSdIk5Uy8BqaqVgAf7dF+WZJvAxcDa4DjquqSia5PkiRpsjLEa8JV1X16tC0CFnVtHwUcta7jSZIkTWUup5EkSZJaxpl4tUKSrYFze+x6ZlXdONH1SJIkDZIhXq3QBHX/KqskSRKGeE1D87bdksUL9x6/oyRJ0iTlmnhJkiSpZdY6xCfZJMl9N0YxkiRJksbXV4hP8qUk901yb+CnwBVJ3rJxS5MkSZLUS78z8Y+pqpuAfYBvAg8FXrbRqpIkSZI0qn5D/KZJNqUT4r9eVX8GauOVJUmSJGk0/Yb4TwPLgXsD303yMOCmjVWUJEmSpNH19ROTVfUx4GNdTb9IsufGKUmSJEnSWMYM8Un+eZzjP7QBa5EkSZLUh/Fm4reYkCokSZIk9W3MEF9V756oQiRJkiT1p9/fid8uyWlJrk9yXZJTk2y3sYuTJEmS9Jf6/XWa44HTgQcD2wLfaNokSZIkTbB+Q/wDqur4qrqzeZwAPGAj1iVJkiRpFP2G+N8m+YckM5rHPwA3bszCJEmSJPXWb4h/JbA/8BvgWmA/4BUbqyhJkiRJo+vrjz0B7wUOrqrfAyS5P/BBOuFekiRJ0gTqdyb+scMBHqCqfgfssnFKkiRJkjSWfkP8JknuN7zRzMT3O4svSZIkaQPqN4j/B/D9JKcARWd9/JEbrSppI1q2chVDh5056DIkqdWWL9x70CVI01pfIb6qvpBkMfAMIMDfVdVPN2plkiRJknrqe0lME9oN7pIkSdKA9bsmXpIkSdIkYYiXJEmSWsYQL0mSJLWMIV6SJElqGUO8JlySSvLFru2ZSW5IckazvUeSVUmWNo93jjLO1l19fpNkZdf2vSbq9UiSJE00/2CTBuEWYKckm1XVbcCzgZUj+pxfVS8Ya5CquhHYGSDJEcDNVfXBjVCvJEnSpOJMvAblW8DwXwo5EPjyAGuRJElqFUO8BuUk4IAks4HHAj8csf9vklyU5FtJdlzfkyU5JMniJItX37pqfYeTJEkaKEO8BqKqLgaG6MzCf3PE7guBh1XV44Cjgf/aAOc7tqrmV9X8GZtvub7DSZIkDZQhXoN0OvBBRiylqaqbqurm5vk3gU2TbDOA+iRJkiYlb2zVIH0OWFVVy5LsMdyY5K+A66qqkuxK58PmjQOqUZIkadIxxGtgqmoF8NEeu/YDXp3kTuA24ICqqgktTpIkaRIzxGvCVdV9erQtAhY1zz8OfHwtxzxiA5QmSZLUCq6JlyRJklrGmXi1QpKtgXN77Hpm80efJEmSpg1DvFqh+6+zSpIkTXeGeE0787bdksUL9x6/oyRJ0iTlmnhJkiSpZQzxkiRJUssY4iVJkqSWMcRLkiRJLWOIlyRJklrGEC9JkiS1jCFekiRJahlDvCRJktQyhnhJkiSpZQzxkiRJUssY4iVJkqSWMcRLkiRJLWOIlyRJklrGEC9JkiS1jCFekiRJahlDvCRJktQyhnhJkiSpZQzxkiRJUsvMHHQB0kRbtnIVQ4edOegyJKnVli/ce9AlSNOaM/GSJElSyxjiJUmSpJYxxEuSJEktY4iXJEmSWsYQL0mSJLWMIV6SJElqGUP8FJXkr5KclOSqJD9N8s0kOzT7vp3kD0nO6HOsU5I8vHl+ZJJfJbl5nGMOT3JlkiuSPLePcxyV5PIkFyc5LclWo/TbqxnzyiSHjTj+N0ne3M9rkiRJajND/BSUJMBpwKKqekRVPQZ4O/CgpstRwMv6HGtHYEZVXd00fQPYdZxjHgMcAOwI7AV8MsmMcU51DrBTVT0W+BlweI9xZwCfAJ4HPAY4sDkXVfUW4Jh+XpMkSVLbGeKnpj2BP1fVXaG2qpZW1fnN83OBP/Y51kHA17vG+UFVXTvOMS8CTqqqO6rqGuBKxgn+VXV2Vd3ZbP4A2K5Ht12BK6vq6qr6E3BScy5JkqRpxRA/Ne0ELNlAY+22DmNtC/yqa3tF09avVwLf2pDjJjkkyeIki1ffumotSpEkSZp8DPEazxzghrU8Jj3aqq8Dk3cAdwInbshxq+rYqppfVfNnbL5lP4dIkiRNWob4qelS4AkbaKzbgNlrecwK4CFd29sBvx7voCQHAy8ADqqqXuF8ncaVJEmaagzxU9P/ALOS/ONwQ5InJnn6Oox1GfDItTzmdOCAJLOSbA/MBX7U1PGFJH+xPj7JXsDbgBdW1a2jjPtjYG6S7ZPci87Ns6evZW2SJEmtZ4ifgppZ7H2BZzc/MXkpcATNrHWS84GTgWcmWTHOT0CeCewxvJHkA0lWAJs3xx7RtL8wyXua818KfBX4KfBt4LVVtboZ4rFArxtjPw5sAZyTZGmSY5pxH5zkm824dwKvA86i8+Hiq825JEmSppX0XrUgdSTZDDgP2K0riK/rWPcFPltVL9kgxf3l+EcAN1fVB8fqN2vO3Jpz8Ec2RgmSNG0sX7j3oEuQpoUkS6pq/sh2Z+I1pqq6DXgXa/frMqONddNGDPBHAf8A3LIxxpckSZpMZg66AE0OSU4Dth/R/LaqOquqzhpETWuj+WNPbxl0HZIkSRPBEC8AqmrfQdcgSZKk/hjiNe3M23ZLFruWU5IktZhr4iVJkgN2i1oAABUMSURBVKSWMcRLkiRJLWOIlyRJklrGEC9JkiS1jCFekiRJahlDvCRJktQyhnhJkiSpZQzxkiRJUssY4iVJkqSWMcRLkiRJLWOIlyRJklrGEC9JkiS1jCFekiRJahlDvCRJktQyhnhJkiSpZQzxkiRJUssY4iVJkqSWMcRLkiRJLTNz0AVIE23ZylUMHXbmoMuQpIFbvnDvQZcgaR05Ey9JkiS1jCFekiRJahlDvCRJktQyhnhJkiSpZQzxkiRJUssY4iVJkqSWaXWIT7I6ydIklyQ5OcnmE3z+Byc5pXm+R5IzRum3PMk2G7GO+Uk+trHG7zrPUJJLNvZ5JEmSNLZWh3jgtqrauap2Av4EHDqRJ6+qX1fVfhN5zlHqWFxVrx90HZIkSZoYbQ/x3c4HHjnaziT/kORHzcz9p5PMaNpvTvL+JEuS/HeSXZMsSnJ1khc2fYaSnJ/kwubxlK72v5iZTrJ1krOT/CTJp4F07fvn5puDS5K8sWucy5Mc17SfmORZSS5I8vMkuzb9dk3y/Wbc7yd5VNN+17cASY5I8rmu1zBquE/y3iRv6No+Msnrk9wnybnNa12W5EVdh81I8pkklzavcbPm2J2T/CDJxUlOS3K/sdpH1PGgZt9FzWP4+q7ztZIkSZrKpkSITzITeB6wbJT9fw28FNitqnYGVgMHNbvvDSyqqicAfwT+DXg2sC/wnqbP9cCzq+rxzTjjLV15F/C9qtoFOB14aFPHE4BXAE8Cngz8Y5JdmmMeCXwUeCzwaODvgacCbwbe3vS5HNi9GfedwL+Pcv5HA88FdgXelWTTUfp9Fji4qW0T4ADgROB2YN/m9e4J/EeS4Q8ic4FPVNWOwB+AFzftXwDeVlWPpfPf4V3jtHf7GPCdqnoc8Hjg0g1wre4hySFJFidZvPrWVaNcDkmSpHaYOegC1tNmSZY2z8+nE0p7eSbwBODHTRbdjE4wh84ynG83z5cBd1TVn5MsA4aa9k2BjycZ/gCwwzh17Q78HUBVnZnk9037U4HTquoWgCRfA55GJ+hfU1XLmvZLgXOrqkbUsSXw+SRzgWrq6uXMqroDuCPJ9cCDgBUjO1XV8iQ3NuH4QcBPqurGJvT/e5LdgTXAts1+mjqHr/kSYCjJlsBWVfWdpv3zwMmjtfeo9xnAy5uaVgOrkqzvtRr5Wo8FjgWYNWdujXLdJEmSWqHtIf62ZmZ9PAE+X1WH99j356oaDnVrgDsAqmpNM8MP8CbgOuBxdL69uL2Pc/YKiunRNuyOrudrurbXcPd/p/cC51XVvkmGgEV9jLWasf87HwcsAP4K+FzTdhDwAOAJzQea5cDsUcbebIyx18f6XitJkqQpa0osp+nDucB+SR4IkOT+SR62FsdvCVxbVWuAlwEzxun/XZrlOkmeB9yvq32fJJsnuTedJTvnr2UdK5vnC9biuLGcBuwFPBE4q+s81zcBfk9gzGtVVauA3yd5WtP0MjrLY3q29xjiXODVAElmJLkv63+tJEmSpqxpEeKr6qfA/wPOTnIxcA4wZy2G+CRwcJIf0FlKc8s4/d8N7J7kQuA5wC+bOi4ETgB+BPwQOK6qfrIWdXwAeF+SCxj/g0RfqupPwHnAV5ulLNBZFz8/yWI6H0Yu72Oog4Gjmuu7M3ffT9CzPcl70tw4DLwB2LNZDrME2HEDXCtJkqQpK3evJNF01NzQeiHwkqr6+aDrmQiz5sytOQd/ZNBlSNLALV+496BLkDSOJEuqav7I9mkxE6/ekjwGuJLOjaHTIsBLkiRNBVPqJsAkW9NZXz3SM6vqxomuZ7IY57o8fKLrkSRJ0vqZUiG+Cer9/FrNtOJ1kSRJmlqmVIiX+jFv2y1Z7DpQSZLUYq6JlyRJklrGEC9JkiS1jCFekiRJahlDvCRJktQyhnhJkiSpZQzxkiRJUssY4iVJkqSWMcRLkiRJLWOIlyRJklrGEC9JkiS1jCFekiRJahlDvCRJktQyhnhJkiSpZQzxkiRJUssY4iVJkqSWMcRLkiRJLWOIlyRJklrGEC9JkiS1zMxBFyBNtGUrVzF02JmDLkOSBm75wr0HXYKkdeRMvCRJktQyhnhJkiSpZQzxkiRJUssY4iVJkqSWMcRLkiRJLWOIlyRJklrGEC9JkiS1jCF+EkiyPMk2SR6S5LwklyW5NMkb+jj2I0l2b56fkOSaJEubx84j+j4xyeok+zXbs5P8KMlFzfnePco5kuRjSa5McnGSx/dRV89akuyRZFVX+ztHXIdlTfvitaklyWbNcX9Kss149UmSJLWZf+xpgiWZWVV3jrL7TuBfqurCJFsAS5KcU1U/HWWs+wNPrqo3djW/papO6dF3BvB+4Kyu5juAZ1TVzUk2Bb6X5FtV9YMRhz8PmNs8ngR8qvl3PD1rAc6vqheMcsyeVfXbMcbsWUtV3QbsnGR5H3VJkiS1mjPx6yjJy5uZ4IuSfLFp+9skP0zykyT/neRBTfsRSY5NcjbwhSRbJzm76fdpIABVdW1VXdg8/yNwGbDtGGXsB3y7z5L/CTgVuH64oTpubjY3bR7V49gXAV9o+v8A2CrJnD7Pu6GtUy1JDkmyOMni1beu2vhVSpIkbUSG+HWQZEfgHXRmsR8HDC97+R6dmfFdgJOAt3Yd9gTgRVX198C7gO81/U4HHtrjHEPALsAPxyhlN2DJiLYjmw8XH04yqxlrW2Bf4Jge55mRZCmdcH9OVfU637bAr7q2VzD2h4tRa2n8TfPh51vNtRxWwNlJliQ5ZJQx16mWqjq2quZX1fwZm2/ZR+mSJEmTlyF+3TwDOGV42UdV/a5p3w44K8ky4C1Ad0A9vVnyAbA78J/NsWcCv+8ePMl96Myav7GqbhqjjjnADV3bhwOPBp4I3B94W9P+EeBtVbV65ABVtbqqdm5q3zXJTj3Okx5tvWbsu41Wy4XAw5oPP0cD/9V1zG5V9Xg6S2ZeO7zWfwPUIkmSNKUY4tdN6B0cjwY+XlXzgP8LzO7ad8uIvj2DZ7M2/VTgxKr62jh13NZ9jmY5TlXVHcDxwK7NrvnASc168f2ATybZ5x7FVP0BWATs1eM8K4CHdG1vB/x6rMJGq6WqbhpewlNV3wQ2Hb4Rtap+3fx7PXBaV/3rVYskSdJUY4hfN+cC+yfZGu66wRRgS2Bl8/zgMY7/LnBQc+zzgPs1zwN8Frisqj7URx2XAY8c3hheG96Msw9wCUBVbV9VQ1U1BJwCvKaq/ivJA5Js1RyzGfAs4PIe5zkdeHnzyzBPBlZV1bXNcec2y3XuYbRakvxV00aSXem8B29Mcu/mZl6S3Bt4zvAx/dYiSZI0XfjrNOugqi5NciTwnSSrgZ8AC4AjgJOTrAR+AGw/yhDvBr6c5ELgO8Avm/bdgJcBy5p16gBvb2asezmTzoz/cc32iUkeQOebgqXAoeO8lDnA55tfrtkE+GpVnQGQ5NDmtR4DfBN4PnAlcCvwiqbPJnQ+RPzuL4cetZb9gFcnuZPONwkHVFU1NwGf1uT7mcCXqurb/dYiSZI0naTK5cRtluR7wAua5TATfe6dgFdW1T9P9LlH0ywZmj/Wz1TOmjO35hz8kYkrSpImqeUL9x50CZLGkWRJVc0f2e5ymvb7F3r8us1EqKpLJkuAH/5jT3R+JnPNoOuRJEnamFxO0wJJPkFnqU23j1bV8aP8JOS0M/zHngZdhyRJ0kRwOY2mnfnz59fixYsHXYYkSdK4XE4jSZIkTRGGeEmSJKllDPGSJElSyxjiJUmSpJYxxEuSJEktY4iXJEmSWsYQL0mSJLWMIV6SJElqGUO8JEmS1DKGeEmSJKllDPGSJElSyxjiJUmSpJYxxEuSJEktY4iXJEmSWsYQL0mSJLWMIV6SJElqGUO8JEmS1DKGeEmSJKllZg66AGmiLVu5iqHDzhx0GZI0cMsX7j3oEiStI2fiJUmSpJYxxEuSJEktY4iXJEmSWsYQL0mSJLWMIV6SJElqGX+dRpIkSa3x5z//mRUrVnD77bcPupQNavbs2Wy33XZsuummffU3xEuSJKk1VqxYwRZbbMHQ0BBJBl3OBlFV3HjjjaxYsYLtt9++r2NcTjPJJVmdZGmSS5NclOSfk2zS7Ns6yXlJbk7y8RHHPSHJsiRXJvlYxnmXJ3ljkpePsu/7fdT5tKbGpUk2G6PfkUl+leTmEe0LktzQHL80yatGOb7n60rypiS/HHkdJEnS1HL77bez9dZbT5kAD5CErbfeeq2+XTDET363VdXOVbUj8Gzg+cC7mn23A/8KvLnHcZ8CDgHmNo+9RjtBkpnAK4Ev9dpfVU/po86DgA82td42Rr9vALuOsu8rzfE7V9Vxo/Tp+bqq6sPAO/uoU5IktdxUCvDD1vY1GeJbpKqupxNgX5ckVXVLVX2PTpi/S5I5wH2r6n+rqoAvAPuMMfQzgAur6s5eO4dnzZPskWRRklOSXJ7kxHS8CtgfeGeSE8d5DT+oqmv7fc3r+bq6jz0kyeIki1ffumpdTi9JkjRpuCa+Zarq6mY5zQOB60bpti2womt7RdM2mt2AJX2WsAuwI/Br4AJgt6o6LslTgTOq6pQ+x+nlxUl2B34GvKmqfjVi/9q+rrtU1bHAsQCz5syt9ahRkiRNIkOHnblBx1u+cO9x+zzlKU/h+98fd7XxRuVMfDuN931Lr/1jBdc5wA19nvtHVbWiqtYAS4GhPo8bzzeAoap6LPDfwOd79Fnb1yVJkrTBDTrAgyG+dZI8HFgNXD9GtxXAdl3b29GZOR/NbcDsZvyHdN1cemiPvnd0PV/NBvo2p6purKrhsT8DPKFHt7V9XZIkSRvcfe5zHwAWLVrE05/+dPbff3922GEHDjvsME488UR23XVX5s2bx1VXXQXAggULOPTQQ3na057GDjvswBlnnLHeNRjiWyTJA4BjgI83a8J7atac/zHJk5tfb3k58PUxhr4MeGRz7K+6bi49Zj1qvXwt+8/p2nxhU9M9rMPrkiRJ2qguuugiPvrRj7Js2TK++MUv8rOf/Ywf/ehHvOpVr+Loo4++q9/y5cv5zne+w5lnnsmhhx663r9zb4if/DYb/olJOstMzgbePbwzyXLgQ8CCJCuSPKbZ9WrgOOBK4CrgW2Oc41vA7huq4CTbMMqSnyQfSLIC2Lyp94hm1+uHf0YTeD2woOuYpV1DrM3rkiRJ2qie+MQnMmfOHGbNmsUjHvEInvOc5wAwb948li9ffle//fffn0022YS5c+fy8Ic/nMsvX6v5zr/gja2TXFXNGGf/0Cjti4Gd+jzHL5LcmGRuVf28x/77NP8uAhZ1tb+u6/mCrkOeDHxilHO9FXhrj/bDgcNHOWbnrud9vy5JkqSNbdasWXc932STTe7a3mSTTbjzzrt/+G/kT0iu789kOhOvYYfRucF1vVXVGVX1sQ0xVr+SvInOh4CbJvK8kiRJ/Tj55JNZs2YNV111FVdffTWPetSj1ms8Z+KnkSTvAF4yovnkqjqyqq4ArhhAWRtE88eePjzoOiRJ0sTq5ychJ4NHPepRPP3pT+e6667jmGOOYfbs2es1Xsa4P1KakubPn1+LFy8edBmSJGkdXHbZZfz1X//1oMtYKwsWLOAFL3gB++2335j9er22JEuqav7Ivi6nkSRJklrG5TSSJEnSRnTCCSds8DGdiZckSVKrTMXl4Gv7mgzxkiRJao3Zs2dz4403TqkgX1XceOONa3Wzq8tpJEmS1BrbbbcdK1as4IYbbhh0KRvU7Nmz2W677frub4iXJElSa2y66aZsv/32gy5j4FxOI0mSJLWMIV6SJElqGUO8JEmS1DL+xVZNO0n+CFwx6DomuW2A3w66iBbwOvXH69Qfr1N/vE7j8xr1py3X6WFV9YCRjd7Yqunoil5/vlh3S7LYazQ+r1N/vE798Tr1x+s0Pq9Rf9p+nVxOI0mSJLWMIV6SJElqGUO8pqNjB11AC3iN+uN16o/XqT9ep/54ncbnNepPq6+TN7ZKkiRJLeNMvCRJktQyhnhJkiSpZQzxmjaS7JXkiiRXJjls0PVMVkmWJ1mWZGmSxYOuZ7JI8rkk1ye5pKvt/knOSfLz5t/7DbLGyWCU63REkpXNe2ppkucPssZBS/KQJOcluSzJpUne0LT7fuoyxnXy/dQlyewkP0pyUXOd3t20+37qMsZ1au37yTXxmhaSzAB+BjwbWAH8GDiwqn460MImoSTLgflV1YY/gDFhkuwO3Ax8oap2ato+APyuqhY2HwzvV1VvG2SdgzbKdToCuLmqPjjI2iaLJHOAOVV1YZItgCXAPsACfD/dZYzrtD++n+6SJMC9q+rmJJsC3wPeAPwdvp/uMsZ12ouWvp+cidd0sStwZVVdXVV/Ak4CXjTgmtQiVfVd4Hcjml8EfL55/nk6AWNaG+U6qUtVXVtVFzbP/whcBmyL76d7GOM6qUt13Nxsbto8Ct9P9zDGdWotQ7ymi22BX3Vtr8D/GYymgLOTLElyyKCLmeQeVFXXQidwAA8ccD2T2euSXNwst5nWX+t3SzIE7AL8EN9PoxpxncD30z0kmZFkKXA9cE5V+X7qYZTrBC19PxniNV2kR1urP4FvRLtV1eOB5wGvbZZHSOvjU8AjgJ2Ba4H/GGw5k0OS+wCnAm+sqpsGXc9k1eM6+X4aoapWV9XOwHbArkl2GnRNk9Eo16m17ydDvKaLFcBDura3A349oFomtar6dfPv9cBpdJYiqbfrmnW7w+t3rx9wPZNSVV3X/M9zDfAZfE/RrMk9FTixqr7WNPt+GqHXdfL9NLqq+gOwiM46b99Po+i+Tm1+PxniNV38GJibZPsk9wIOAE4fcE2TTpJ7NzeQkeTewHOAS8Y+alo7HTi4eX4w8PUB1jJpDQeJxr5M8/dUc4PdZ4HLqupDXbt8P3UZ7Tr5frqnJA9IslXzfDPgWcDl+H66h9GuU5vfT/46jaaN5mejPgLMAD5XVUcOuKRJJ8nD6cy+A8wEvuR16kjyZWAPYBvgOuBdwH8BXwUeCvwSeElVTeubOke5TnvQ+aq6gOXA/x1eqzsdJXkqcD6wDFjTNL+dznpv30+NMa7Tgfh+ukuSx9K5cXUGncnZr1bVe5Jsje+nu4xxnb5IS99PhnhJkiSpZVxOI0mSJLWMIV6SJElqGUO8JEmS1DKGeEmSJKllDPGSJElSyxjiJUmSpJYxxEuSJEkt8/8BDTWO6XiInmcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fi=pd.DataFrame({'cols' : litraincolOrg, 'imp' : model5.feature_importances_})\n",
    "fi = fi.sort_values('imp', ascending=False)\n",
    "top_10 = fi[0:10]\n",
    "top_10 = top_10.sort_values('imp', ascending=True)\n",
    "# Plot the bar chart\n",
    "top_10.plot(x='cols', kind='barh' , figsize=(10,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[9608   24]\n",
      " [ 256  113]]\n",
      "Accuracy Score : 0.972002799720028\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      9632\n",
      "           1       0.82      0.31      0.45       369\n",
      "\n",
      "    accuracy                           0.97     10001\n",
      "   macro avg       0.90      0.65      0.72     10001\n",
      "weighted avg       0.97      0.97      0.97     10001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model5.predict(x_valid) \n",
    "results = confusion_matrix(y_valid, predicted) \n",
    "\n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :',accuracy_score(y_valid, predicted)) \n",
    "print('Report : ')\n",
    "print(classification_report(y_valid, predicted)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.integration.lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(x_train, label=y_train)\n",
    "dval = lgb.Dataset(x_valid, label=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-09-29 12:22:07,027] A new study created in memory with name: no-name-5b26d972-c823-4fb2-bfce-853fe142d3c7\n",
      "feature_fraction, val_score: inf:   0%|                  | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.129797\tvalid_1's binary_logloss: 0.133645\n",
      "[4]\ttraining's binary_logloss: 0.121151\tvalid_1's binary_logloss: 0.127244\n",
      "[6]\ttraining's binary_logloss: 0.114893\tvalid_1's binary_logloss: 0.122436\n",
      "[8]\ttraining's binary_logloss: 0.109895\tvalid_1's binary_logloss: 0.118802\n",
      "[10]\ttraining's binary_logloss: 0.10576\tvalid_1's binary_logloss: 0.115958\n",
      "[12]\ttraining's binary_logloss: 0.102676\tvalid_1's binary_logloss: 0.113644\n",
      "[14]\ttraining's binary_logloss: 0.0997022\tvalid_1's binary_logloss: 0.11152\n",
      "[16]\ttraining's binary_logloss: 0.0970673\tvalid_1's binary_logloss: 0.10995\n",
      "[18]\ttraining's binary_logloss: 0.0949698\tvalid_1's binary_logloss: 0.108997\n",
      "[20]\ttraining's binary_logloss: 0.0929268\tvalid_1's binary_logloss: 0.107749\n",
      "[22]\ttraining's binary_logloss: 0.0909968\tvalid_1's binary_logloss: 0.106939\n",
      "[24]\ttraining's binary_logloss: 0.0892666\tvalid_1's binary_logloss: 0.105675\n",
      "[26]\ttraining's binary_logloss: 0.0876859\tvalid_1's binary_logloss: 0.105036\n",
      "[28]\ttraining's binary_logloss: 0.0860537\tvalid_1's binary_logloss: 0.104475\n",
      "[30]\ttraining's binary_logloss: 0.0846956\tvalid_1's binary_logloss: 0.103838\n",
      "[32]\ttraining's binary_logloss: 0.0833975\tvalid_1's binary_logloss: 0.103181\n",
      "[34]\ttraining's binary_logloss: 0.0819905\tvalid_1's binary_logloss: 0.10268\n",
      "[36]\ttraining's binary_logloss: 0.080708\tvalid_1's binary_logloss: 0.102383\n",
      "[38]\ttraining's binary_logloss: 0.0795121\tvalid_1's binary_logloss: 0.101952\n",
      "[40]\ttraining's binary_logloss: 0.0784185\tvalid_1's binary_logloss: 0.1015\n",
      "[42]\ttraining's binary_logloss: 0.0773316\tvalid_1's binary_logloss: 0.101447\n",
      "[44]\ttraining's binary_logloss: 0.0760054\tvalid_1's binary_logloss: 0.101146\n",
      "[46]\ttraining's binary_logloss: 0.0748889\tvalid_1's binary_logloss: 0.100802\n",
      "[48]\ttraining's binary_logloss: 0.0740352\tvalid_1's binary_logloss: 0.10069\n",
      "[50]\ttraining's binary_logloss: 0.0731727\tvalid_1's binary_logloss: 0.100692\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's binary_logloss: 0.0735387\tvalid_1's binary_logloss: 0.100628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.100628:  14%|7    | 1/7 [00:08<00:50,  8.34s/it][I 2020-09-29 12:22:15,911] Trial 0 finished with value: 0.10062792322736178 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.10062792322736178.\n",
      "feature_fraction, val_score: 0.100628:  14%|7    | 1/7 [00:08<00:50,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.12957\tvalid_1's binary_logloss: 0.133867\n",
      "[4]\ttraining's binary_logloss: 0.120638\tvalid_1's binary_logloss: 0.127482\n",
      "[6]\ttraining's binary_logloss: 0.113939\tvalid_1's binary_logloss: 0.12213\n",
      "[8]\ttraining's binary_logloss: 0.109076\tvalid_1's binary_logloss: 0.118334\n",
      "[10]\ttraining's binary_logloss: 0.105107\tvalid_1's binary_logloss: 0.115355\n",
      "[12]\ttraining's binary_logloss: 0.101801\tvalid_1's binary_logloss: 0.112837\n",
      "[14]\ttraining's binary_logloss: 0.0989727\tvalid_1's binary_logloss: 0.11141\n",
      "[16]\ttraining's binary_logloss: 0.0967636\tvalid_1's binary_logloss: 0.110226\n",
      "[18]\ttraining's binary_logloss: 0.0944713\tvalid_1's binary_logloss: 0.108824\n",
      "[20]\ttraining's binary_logloss: 0.0923494\tvalid_1's binary_logloss: 0.107359\n",
      "[22]\ttraining's binary_logloss: 0.0903752\tvalid_1's binary_logloss: 0.106479\n",
      "[24]\ttraining's binary_logloss: 0.0884945\tvalid_1's binary_logloss: 0.105424\n",
      "[26]\ttraining's binary_logloss: 0.0867988\tvalid_1's binary_logloss: 0.1048\n",
      "[28]\ttraining's binary_logloss: 0.085229\tvalid_1's binary_logloss: 0.104065\n",
      "[30]\ttraining's binary_logloss: 0.0837948\tvalid_1's binary_logloss: 0.103565\n",
      "[32]\ttraining's binary_logloss: 0.0823725\tvalid_1's binary_logloss: 0.102964\n",
      "[34]\ttraining's binary_logloss: 0.081045\tvalid_1's binary_logloss: 0.102574\n",
      "[36]\ttraining's binary_logloss: 0.0798239\tvalid_1's binary_logloss: 0.102208\n",
      "[38]\ttraining's binary_logloss: 0.0784971\tvalid_1's binary_logloss: 0.101646\n",
      "[40]\ttraining's binary_logloss: 0.0775547\tvalid_1's binary_logloss: 0.101362\n",
      "[42]\ttraining's binary_logloss: 0.0762753\tvalid_1's binary_logloss: 0.101159\n",
      "[44]\ttraining's binary_logloss: 0.0751298\tvalid_1's binary_logloss: 0.100899\n",
      "[46]\ttraining's binary_logloss: 0.0741238\tvalid_1's binary_logloss: 0.100595\n",
      "[48]\ttraining's binary_logloss: 0.0732264\tvalid_1's binary_logloss: 0.10046\n",
      "[50]\ttraining's binary_logloss: 0.0723867\tvalid_1's binary_logloss: 0.100029\n",
      "[52]\ttraining's binary_logloss: 0.0715515\tvalid_1's binary_logloss: 0.0997975\n",
      "[54]\ttraining's binary_logloss: 0.0706951\tvalid_1's binary_logloss: 0.0996438\n",
      "[56]\ttraining's binary_logloss: 0.0699419\tvalid_1's binary_logloss: 0.0995004\n",
      "[58]\ttraining's binary_logloss: 0.0691193\tvalid_1's binary_logloss: 0.0992568\n",
      "[60]\ttraining's binary_logloss: 0.0683562\tvalid_1's binary_logloss: 0.0992862\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's binary_logloss: 0.0691193\tvalid_1's binary_logloss: 0.0992568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.099257:  29%|#4   | 2/7 [00:13<00:37,  7.51s/it][I 2020-09-29 12:22:21,502] Trial 1 finished with value: 0.09925683534527287 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.09925683534527287.\n",
      "feature_fraction, val_score: 0.099257:  29%|#4   | 2/7 [00:13<00:37,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.128491\tvalid_1's binary_logloss: 0.133686\n",
      "[4]\ttraining's binary_logloss: 0.119889\tvalid_1's binary_logloss: 0.126554\n",
      "[6]\ttraining's binary_logloss: 0.113192\tvalid_1's binary_logloss: 0.121266\n",
      "[8]\ttraining's binary_logloss: 0.10836\tvalid_1's binary_logloss: 0.117521\n",
      "[10]\ttraining's binary_logloss: 0.104527\tvalid_1's binary_logloss: 0.114785\n",
      "[12]\ttraining's binary_logloss: 0.100979\tvalid_1's binary_logloss: 0.11249\n",
      "[14]\ttraining's binary_logloss: 0.0979809\tvalid_1's binary_logloss: 0.110527\n",
      "[16]\ttraining's binary_logloss: 0.0955783\tvalid_1's binary_logloss: 0.109289\n",
      "[18]\ttraining's binary_logloss: 0.0934975\tvalid_1's binary_logloss: 0.108061\n",
      "[20]\ttraining's binary_logloss: 0.0914003\tvalid_1's binary_logloss: 0.10675\n",
      "[22]\ttraining's binary_logloss: 0.0893667\tvalid_1's binary_logloss: 0.105533\n",
      "[24]\ttraining's binary_logloss: 0.0877202\tvalid_1's binary_logloss: 0.104719\n",
      "[26]\ttraining's binary_logloss: 0.0860657\tvalid_1's binary_logloss: 0.104109\n",
      "[28]\ttraining's binary_logloss: 0.0845859\tvalid_1's binary_logloss: 0.103697\n",
      "[30]\ttraining's binary_logloss: 0.0830476\tvalid_1's binary_logloss: 0.103116\n",
      "[32]\ttraining's binary_logloss: 0.0816073\tvalid_1's binary_logloss: 0.102295\n",
      "[34]\ttraining's binary_logloss: 0.0801607\tvalid_1's binary_logloss: 0.101916\n",
      "[36]\ttraining's binary_logloss: 0.078726\tvalid_1's binary_logloss: 0.101698\n",
      "[38]\ttraining's binary_logloss: 0.0774655\tvalid_1's binary_logloss: 0.101512\n",
      "[40]\ttraining's binary_logloss: 0.0761989\tvalid_1's binary_logloss: 0.101185\n",
      "[42]\ttraining's binary_logloss: 0.0750751\tvalid_1's binary_logloss: 0.100801\n",
      "[44]\ttraining's binary_logloss: 0.0740982\tvalid_1's binary_logloss: 0.100457\n",
      "[46]\ttraining's binary_logloss: 0.0729009\tvalid_1's binary_logloss: 0.100521\n",
      "[48]\ttraining's binary_logloss: 0.0719068\tvalid_1's binary_logloss: 0.100383\n",
      "[50]\ttraining's binary_logloss: 0.0709819\tvalid_1's binary_logloss: 0.100207\n",
      "[52]\ttraining's binary_logloss: 0.0700207\tvalid_1's binary_logloss: 0.099984\n",
      "[54]\ttraining's binary_logloss: 0.0691592\tvalid_1's binary_logloss: 0.099841\n",
      "[56]\ttraining's binary_logloss: 0.0681519\tvalid_1's binary_logloss: 0.0997441\n",
      "[58]\ttraining's binary_logloss: 0.0672802\tvalid_1's binary_logloss: 0.0996233\n",
      "[60]\ttraining's binary_logloss: 0.0665503\tvalid_1's binary_logloss: 0.0995087\n",
      "[62]\ttraining's binary_logloss: 0.0657927\tvalid_1's binary_logloss: 0.0992797\n",
      "[64]\ttraining's binary_logloss: 0.0648653\tvalid_1's binary_logloss: 0.0991959\n",
      "[66]\ttraining's binary_logloss: 0.0640104\tvalid_1's binary_logloss: 0.098931\n",
      "[68]\ttraining's binary_logloss: 0.0632511\tvalid_1's binary_logloss: 0.098872\n",
      "[70]\ttraining's binary_logloss: 0.0625474\tvalid_1's binary_logloss: 0.0988672\n",
      "[72]\ttraining's binary_logloss: 0.0617992\tvalid_1's binary_logloss: 0.0988058\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's binary_logloss: 0.0621381\tvalid_1's binary_logloss: 0.0987527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.098753:  43%|##1  | 3/7 [00:19<00:27,  6.95s/it][I 2020-09-29 12:22:27,132] Trial 2 finished with value: 0.09875266413340983 and parameters: {'feature_fraction': 1.0}. Best is trial 2 with value: 0.09875266413340983.\n",
      "feature_fraction, val_score: 0.098753:  43%|##1  | 3/7 [00:19<00:27,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.130956\tvalid_1's binary_logloss: 0.132861\n",
      "[4]\ttraining's binary_logloss: 0.121952\tvalid_1's binary_logloss: 0.126065\n",
      "[6]\ttraining's binary_logloss: 0.115727\tvalid_1's binary_logloss: 0.121278\n",
      "[8]\ttraining's binary_logloss: 0.110855\tvalid_1's binary_logloss: 0.117975\n",
      "[10]\ttraining's binary_logloss: 0.106866\tvalid_1's binary_logloss: 0.115434\n",
      "[12]\ttraining's binary_logloss: 0.103721\tvalid_1's binary_logloss: 0.113208\n",
      "[14]\ttraining's binary_logloss: 0.100734\tvalid_1's binary_logloss: 0.110883\n",
      "[16]\ttraining's binary_logloss: 0.0981651\tvalid_1's binary_logloss: 0.109482\n",
      "[18]\ttraining's binary_logloss: 0.0959017\tvalid_1's binary_logloss: 0.108205\n",
      "[20]\ttraining's binary_logloss: 0.0939181\tvalid_1's binary_logloss: 0.107481\n",
      "[22]\ttraining's binary_logloss: 0.0920976\tvalid_1's binary_logloss: 0.106439\n",
      "[24]\ttraining's binary_logloss: 0.0903334\tvalid_1's binary_logloss: 0.105483\n",
      "[26]\ttraining's binary_logloss: 0.0886887\tvalid_1's binary_logloss: 0.104883\n",
      "[28]\ttraining's binary_logloss: 0.0871125\tvalid_1's binary_logloss: 0.104117\n",
      "[30]\ttraining's binary_logloss: 0.0856962\tvalid_1's binary_logloss: 0.10366\n",
      "[32]\ttraining's binary_logloss: 0.084356\tvalid_1's binary_logloss: 0.103415\n",
      "[34]\ttraining's binary_logloss: 0.0831476\tvalid_1's binary_logloss: 0.103089\n",
      "[36]\ttraining's binary_logloss: 0.0818068\tvalid_1's binary_logloss: 0.102999\n",
      "[38]\ttraining's binary_logloss: 0.0806399\tvalid_1's binary_logloss: 0.102723\n",
      "[40]\ttraining's binary_logloss: 0.0795354\tvalid_1's binary_logloss: 0.102298\n",
      "[42]\ttraining's binary_logloss: 0.0782086\tvalid_1's binary_logloss: 0.101918\n",
      "[44]\ttraining's binary_logloss: 0.0771311\tvalid_1's binary_logloss: 0.101636\n",
      "[46]\ttraining's binary_logloss: 0.0761623\tvalid_1's binary_logloss: 0.101348\n",
      "[48]\ttraining's binary_logloss: 0.0751172\tvalid_1's binary_logloss: 0.101171\n",
      "[50]\ttraining's binary_logloss: 0.0741976\tvalid_1's binary_logloss: 0.101069\n",
      "[52]\ttraining's binary_logloss: 0.0733658\tvalid_1's binary_logloss: 0.100985\n",
      "[54]\ttraining's binary_logloss: 0.0724944\tvalid_1's binary_logloss: 0.100835\n",
      "[56]\ttraining's binary_logloss: 0.0713548\tvalid_1's binary_logloss: 0.100766\n",
      "[58]\ttraining's binary_logloss: 0.0705372\tvalid_1's binary_logloss: 0.100504\n",
      "[60]\ttraining's binary_logloss: 0.0698293\tvalid_1's binary_logloss: 0.100463\n",
      "[62]\ttraining's binary_logloss: 0.0689406\tvalid_1's binary_logloss: 0.100292\n",
      "[64]\ttraining's binary_logloss: 0.0682648\tvalid_1's binary_logloss: 0.10007\n",
      "[66]\ttraining's binary_logloss: 0.0675767\tvalid_1's binary_logloss: 0.100004\n",
      "[68]\ttraining's binary_logloss: 0.0669501\tvalid_1's binary_logloss: 0.100015\n",
      "[70]\ttraining's binary_logloss: 0.0661039\tvalid_1's binary_logloss: 0.0998734\n",
      "[72]\ttraining's binary_logloss: 0.0652993\tvalid_1's binary_logloss: 0.0996107\n",
      "[74]\ttraining's binary_logloss: 0.0646119\tvalid_1's binary_logloss: 0.0995365\n",
      "[76]\ttraining's binary_logloss: 0.0640479\tvalid_1's binary_logloss: 0.0992888\n",
      "[78]\ttraining's binary_logloss: 0.063461\tvalid_1's binary_logloss: 0.0992977\n",
      "[80]\ttraining's binary_logloss: 0.0628661\tvalid_1's binary_logloss: 0.0992741\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's binary_logloss: 0.0631142\tvalid_1's binary_logloss: 0.0992246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.098753:  57%|##8  | 4/7 [00:24<00:18,  6.32s/it][I 2020-09-29 12:22:31,994] Trial 3 finished with value: 0.09922463722342302 and parameters: {'feature_fraction': 0.5}. Best is trial 2 with value: 0.09875266413340983.\n",
      "feature_fraction, val_score: 0.098753:  57%|##8  | 4/7 [00:24<00:18,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.129951\tvalid_1's binary_logloss: 0.133376\n",
      "[4]\ttraining's binary_logloss: 0.121179\tvalid_1's binary_logloss: 0.126295\n",
      "[6]\ttraining's binary_logloss: 0.11492\tvalid_1's binary_logloss: 0.121829\n",
      "[8]\ttraining's binary_logloss: 0.109899\tvalid_1's binary_logloss: 0.118296\n",
      "[10]\ttraining's binary_logloss: 0.105928\tvalid_1's binary_logloss: 0.115372\n",
      "[12]\ttraining's binary_logloss: 0.102591\tvalid_1's binary_logloss: 0.113043\n",
      "[14]\ttraining's binary_logloss: 0.0996781\tvalid_1's binary_logloss: 0.111075\n",
      "[16]\ttraining's binary_logloss: 0.0971182\tvalid_1's binary_logloss: 0.109564\n",
      "[18]\ttraining's binary_logloss: 0.0947926\tvalid_1's binary_logloss: 0.108088\n",
      "[20]\ttraining's binary_logloss: 0.0928146\tvalid_1's binary_logloss: 0.106904\n",
      "[22]\ttraining's binary_logloss: 0.0908635\tvalid_1's binary_logloss: 0.10625\n",
      "[24]\ttraining's binary_logloss: 0.0890829\tvalid_1's binary_logloss: 0.105376\n",
      "[26]\ttraining's binary_logloss: 0.0875088\tvalid_1's binary_logloss: 0.104777\n",
      "[28]\ttraining's binary_logloss: 0.0858923\tvalid_1's binary_logloss: 0.104284\n",
      "[30]\ttraining's binary_logloss: 0.0845233\tvalid_1's binary_logloss: 0.103993\n",
      "[32]\ttraining's binary_logloss: 0.0831938\tvalid_1's binary_logloss: 0.103418\n",
      "[34]\ttraining's binary_logloss: 0.0819321\tvalid_1's binary_logloss: 0.103051\n",
      "[36]\ttraining's binary_logloss: 0.0806522\tvalid_1's binary_logloss: 0.102683\n",
      "[38]\ttraining's binary_logloss: 0.0793229\tvalid_1's binary_logloss: 0.102413\n",
      "[40]\ttraining's binary_logloss: 0.0781374\tvalid_1's binary_logloss: 0.102338\n",
      "[42]\ttraining's binary_logloss: 0.077136\tvalid_1's binary_logloss: 0.102016\n",
      "[44]\ttraining's binary_logloss: 0.0760597\tvalid_1's binary_logloss: 0.101639\n",
      "[46]\ttraining's binary_logloss: 0.0749346\tvalid_1's binary_logloss: 0.101567\n",
      "[48]\ttraining's binary_logloss: 0.0739047\tvalid_1's binary_logloss: 0.10138\n",
      "[50]\ttraining's binary_logloss: 0.0730341\tvalid_1's binary_logloss: 0.101176\n",
      "[52]\ttraining's binary_logloss: 0.0721028\tvalid_1's binary_logloss: 0.101054\n",
      "[54]\ttraining's binary_logloss: 0.0712585\tvalid_1's binary_logloss: 0.101005\n",
      "[56]\ttraining's binary_logloss: 0.0704377\tvalid_1's binary_logloss: 0.100868\n",
      "[58]\ttraining's binary_logloss: 0.0695346\tvalid_1's binary_logloss: 0.10073\n",
      "[60]\ttraining's binary_logloss: 0.0686442\tvalid_1's binary_logloss: 0.100506\n",
      "[62]\ttraining's binary_logloss: 0.0678965\tvalid_1's binary_logloss: 0.100355\n",
      "[64]\ttraining's binary_logloss: 0.0671196\tvalid_1's binary_logloss: 0.100361\n",
      "[66]\ttraining's binary_logloss: 0.0663158\tvalid_1's binary_logloss: 0.100128\n",
      "[68]\ttraining's binary_logloss: 0.0656315\tvalid_1's binary_logloss: 0.100103\n",
      "[70]\ttraining's binary_logloss: 0.0648609\tvalid_1's binary_logloss: 0.099942\n",
      "[72]\ttraining's binary_logloss: 0.064194\tvalid_1's binary_logloss: 0.0999055\n",
      "[74]\ttraining's binary_logloss: 0.0635717\tvalid_1's binary_logloss: 0.0999106\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's binary_logloss: 0.064194\tvalid_1's binary_logloss: 0.0999055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.098753:  71%|###5 | 5/7 [00:29<00:11,  5.93s/it][I 2020-09-29 12:22:37,016] Trial 4 finished with value: 0.09990551579078458 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 0.09875266413340983.\n",
      "feature_fraction, val_score: 0.098753:  71%|###5 | 5/7 [00:29<00:11,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.131138\tvalid_1's binary_logloss: 0.133922\n",
      "[4]\ttraining's binary_logloss: 0.122127\tvalid_1's binary_logloss: 0.126634\n",
      "[6]\ttraining's binary_logloss: 0.115816\tvalid_1's binary_logloss: 0.121504\n",
      "[8]\ttraining's binary_logloss: 0.111018\tvalid_1's binary_logloss: 0.11794\n",
      "[10]\ttraining's binary_logloss: 0.107109\tvalid_1's binary_logloss: 0.11527\n",
      "[12]\ttraining's binary_logloss: 0.104085\tvalid_1's binary_logloss: 0.113387\n",
      "[14]\ttraining's binary_logloss: 0.101201\tvalid_1's binary_logloss: 0.111637\n",
      "[16]\ttraining's binary_logloss: 0.0988131\tvalid_1's binary_logloss: 0.110289\n",
      "[18]\ttraining's binary_logloss: 0.0967204\tvalid_1's binary_logloss: 0.109251\n",
      "[20]\ttraining's binary_logloss: 0.0945115\tvalid_1's binary_logloss: 0.10797\n",
      "[22]\ttraining's binary_logloss: 0.0928184\tvalid_1's binary_logloss: 0.107091\n",
      "[24]\ttraining's binary_logloss: 0.0910954\tvalid_1's binary_logloss: 0.106097\n",
      "[26]\ttraining's binary_logloss: 0.0894179\tvalid_1's binary_logloss: 0.105468\n",
      "[28]\ttraining's binary_logloss: 0.0881144\tvalid_1's binary_logloss: 0.104837\n",
      "[30]\ttraining's binary_logloss: 0.0868301\tvalid_1's binary_logloss: 0.104308\n",
      "[32]\ttraining's binary_logloss: 0.0855522\tvalid_1's binary_logloss: 0.103992\n",
      "[34]\ttraining's binary_logloss: 0.0842605\tvalid_1's binary_logloss: 0.103636\n",
      "[36]\ttraining's binary_logloss: 0.0831171\tvalid_1's binary_logloss: 0.103428\n",
      "[38]\ttraining's binary_logloss: 0.0820298\tvalid_1's binary_logloss: 0.102936\n",
      "[40]\ttraining's binary_logloss: 0.080916\tvalid_1's binary_logloss: 0.102741\n",
      "[42]\ttraining's binary_logloss: 0.0798504\tvalid_1's binary_logloss: 0.102418\n",
      "[44]\ttraining's binary_logloss: 0.0788621\tvalid_1's binary_logloss: 0.102151\n",
      "[46]\ttraining's binary_logloss: 0.0777747\tvalid_1's binary_logloss: 0.101735\n",
      "[48]\ttraining's binary_logloss: 0.076713\tvalid_1's binary_logloss: 0.101457\n",
      "[50]\ttraining's binary_logloss: 0.0756047\tvalid_1's binary_logloss: 0.101204\n",
      "[52]\ttraining's binary_logloss: 0.0746645\tvalid_1's binary_logloss: 0.10123\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.0751091\tvalid_1's binary_logloss: 0.101167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.098753:  86%|####2| 6/7 [00:32<00:05,  5.06s/it][I 2020-09-29 12:22:40,029] Trial 5 finished with value: 0.101167044889705 and parameters: {'feature_fraction': 0.4}. Best is trial 2 with value: 0.09875266413340983.\n",
      "feature_fraction, val_score: 0.098753:  86%|####2| 6/7 [00:32<00:05,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.128642\tvalid_1's binary_logloss: 0.13366\n",
      "[4]\ttraining's binary_logloss: 0.119868\tvalid_1's binary_logloss: 0.12657\n",
      "[6]\ttraining's binary_logloss: 0.11347\tvalid_1's binary_logloss: 0.121606\n",
      "[8]\ttraining's binary_logloss: 0.108817\tvalid_1's binary_logloss: 0.117812\n",
      "[10]\ttraining's binary_logloss: 0.104893\tvalid_1's binary_logloss: 0.114638\n",
      "[12]\ttraining's binary_logloss: 0.101621\tvalid_1's binary_logloss: 0.11244\n",
      "[14]\ttraining's binary_logloss: 0.0987906\tvalid_1's binary_logloss: 0.11083\n",
      "[16]\ttraining's binary_logloss: 0.0964986\tvalid_1's binary_logloss: 0.109498\n",
      "[18]\ttraining's binary_logloss: 0.0940199\tvalid_1's binary_logloss: 0.107872\n",
      "[20]\ttraining's binary_logloss: 0.0920173\tvalid_1's binary_logloss: 0.106783\n",
      "[22]\ttraining's binary_logloss: 0.0899941\tvalid_1's binary_logloss: 0.106002\n",
      "[24]\ttraining's binary_logloss: 0.0882883\tvalid_1's binary_logloss: 0.10511\n",
      "[26]\ttraining's binary_logloss: 0.0867028\tvalid_1's binary_logloss: 0.104436\n",
      "[28]\ttraining's binary_logloss: 0.0849572\tvalid_1's binary_logloss: 0.103856\n",
      "[30]\ttraining's binary_logloss: 0.0835549\tvalid_1's binary_logloss: 0.103255\n",
      "[32]\ttraining's binary_logloss: 0.0820012\tvalid_1's binary_logloss: 0.103102\n",
      "[34]\ttraining's binary_logloss: 0.0807243\tvalid_1's binary_logloss: 0.102742\n",
      "[36]\ttraining's binary_logloss: 0.0795503\tvalid_1's binary_logloss: 0.102378\n",
      "[38]\ttraining's binary_logloss: 0.0783171\tvalid_1's binary_logloss: 0.101777\n",
      "[40]\ttraining's binary_logloss: 0.0770541\tvalid_1's binary_logloss: 0.101586\n",
      "[42]\ttraining's binary_logloss: 0.0759994\tvalid_1's binary_logloss: 0.10142\n",
      "[44]\ttraining's binary_logloss: 0.0750386\tvalid_1's binary_logloss: 0.101135\n",
      "[46]\ttraining's binary_logloss: 0.0740787\tvalid_1's binary_logloss: 0.10089\n",
      "[48]\ttraining's binary_logloss: 0.0731407\tvalid_1's binary_logloss: 0.100867\n",
      "[50]\ttraining's binary_logloss: 0.0721759\tvalid_1's binary_logloss: 0.100465\n",
      "[52]\ttraining's binary_logloss: 0.0712071\tvalid_1's binary_logloss: 0.10042\n",
      "[54]\ttraining's binary_logloss: 0.0704191\tvalid_1's binary_logloss: 0.100453\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's binary_logloss: 0.0712071\tvalid_1's binary_logloss: 0.10042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.098753: 100%|#####| 7/7 [00:36<00:00,  4.71s/it][I 2020-09-29 12:22:43,946] Trial 6 finished with value: 0.10042002116504387 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 0.09875266413340983.\n",
      "feature_fraction, val_score: 0.098753: 100%|#####| 7/7 [00:36<00:00,  5.20s/it]\n",
      "num_leaves, val_score: 0.098753:   0%|                  | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.116435\tvalid_1's binary_logloss: 0.130593\n",
      "[4]\ttraining's binary_logloss: 0.101103\tvalid_1's binary_logloss: 0.122938\n",
      "[6]\ttraining's binary_logloss: 0.0898915\tvalid_1's binary_logloss: 0.118582\n",
      "[8]\ttraining's binary_logloss: 0.0803927\tvalid_1's binary_logloss: 0.114661\n",
      "[10]\ttraining's binary_logloss: 0.0725982\tvalid_1's binary_logloss: 0.111841\n",
      "[12]\ttraining's binary_logloss: 0.0660722\tvalid_1's binary_logloss: 0.109674\n",
      "[14]\ttraining's binary_logloss: 0.0602125\tvalid_1's binary_logloss: 0.10827\n",
      "[16]\ttraining's binary_logloss: 0.0550648\tvalid_1's binary_logloss: 0.106994\n",
      "[18]\ttraining's binary_logloss: 0.0505144\tvalid_1's binary_logloss: 0.106131\n",
      "[20]\ttraining's binary_logloss: 0.0464947\tvalid_1's binary_logloss: 0.105345\n",
      "[22]\ttraining's binary_logloss: 0.0429244\tvalid_1's binary_logloss: 0.10512\n",
      "[24]\ttraining's binary_logloss: 0.0396424\tvalid_1's binary_logloss: 0.104726\n",
      "[26]\ttraining's binary_logloss: 0.0366297\tvalid_1's binary_logloss: 0.104329\n",
      "[28]\ttraining's binary_logloss: 0.0337547\tvalid_1's binary_logloss: 0.103914\n",
      "[30]\ttraining's binary_logloss: 0.0312361\tvalid_1's binary_logloss: 0.103693\n",
      "[32]\ttraining's binary_logloss: 0.0288244\tvalid_1's binary_logloss: 0.103455\n",
      "[34]\ttraining's binary_logloss: 0.0267883\tvalid_1's binary_logloss: 0.103521\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's binary_logloss: 0.0278087\tvalid_1's binary_logloss: 0.10337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098753:   5%|5         | 1/20 [00:06<02:02,  6.45s/it][I 2020-09-29 12:22:50,519] Trial 7 finished with value: 0.10337029441558049 and parameters: {'num_leaves': 237}. Best is trial 7 with value: 0.10337029441558049.\n",
      "num_leaves, val_score: 0.098753:   5%|5         | 1/20 [00:06<02:02,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.122521\tvalid_1's binary_logloss: 0.131769\n",
      "[4]\ttraining's binary_logloss: 0.11077\tvalid_1's binary_logloss: 0.124999\n",
      "[6]\ttraining's binary_logloss: 0.102365\tvalid_1's binary_logloss: 0.120073\n",
      "[8]\ttraining's binary_logloss: 0.0959598\tvalid_1's binary_logloss: 0.116199\n",
      "[10]\ttraining's binary_logloss: 0.0905957\tvalid_1's binary_logloss: 0.113207\n",
      "[12]\ttraining's binary_logloss: 0.0859199\tvalid_1's binary_logloss: 0.110654\n",
      "[14]\ttraining's binary_logloss: 0.081666\tvalid_1's binary_logloss: 0.109252\n",
      "[16]\ttraining's binary_logloss: 0.0780096\tvalid_1's binary_logloss: 0.10783\n",
      "[18]\ttraining's binary_logloss: 0.0742163\tvalid_1's binary_logloss: 0.106293\n",
      "[20]\ttraining's binary_logloss: 0.0712564\tvalid_1's binary_logloss: 0.105395\n",
      "[22]\ttraining's binary_logloss: 0.0684165\tvalid_1's binary_logloss: 0.104572\n",
      "[24]\ttraining's binary_logloss: 0.0659676\tvalid_1's binary_logloss: 0.104105\n",
      "[26]\ttraining's binary_logloss: 0.0634641\tvalid_1's binary_logloss: 0.10307\n",
      "[28]\ttraining's binary_logloss: 0.0611777\tvalid_1's binary_logloss: 0.102725\n",
      "[30]\ttraining's binary_logloss: 0.0591572\tvalid_1's binary_logloss: 0.10231\n",
      "[32]\ttraining's binary_logloss: 0.0572371\tvalid_1's binary_logloss: 0.101908\n",
      "[34]\ttraining's binary_logloss: 0.0554612\tvalid_1's binary_logloss: 0.101558\n",
      "[36]\ttraining's binary_logloss: 0.0534671\tvalid_1's binary_logloss: 0.101288\n",
      "[38]\ttraining's binary_logloss: 0.0517905\tvalid_1's binary_logloss: 0.101271\n",
      "[40]\ttraining's binary_logloss: 0.0502255\tvalid_1's binary_logloss: 0.101258\n",
      "[42]\ttraining's binary_logloss: 0.0485744\tvalid_1's binary_logloss: 0.100938\n",
      "[44]\ttraining's binary_logloss: 0.0473082\tvalid_1's binary_logloss: 0.100821\n",
      "[46]\ttraining's binary_logloss: 0.0460631\tvalid_1's binary_logloss: 0.100575\n",
      "[48]\ttraining's binary_logloss: 0.0447403\tvalid_1's binary_logloss: 0.100649\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's binary_logloss: 0.0460631\tvalid_1's binary_logloss: 0.100575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098753:  10%|#         | 2/20 [00:11<01:46,  5.91s/it][I 2020-09-29 12:22:55,186] Trial 8 finished with value: 0.10057470889970539 and parameters: {'num_leaves': 83}. Best is trial 8 with value: 0.10057470889970539.\n",
      "num_leaves, val_score: 0.098753:  10%|#         | 2/20 [00:11<01:46,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.12047\tvalid_1's binary_logloss: 0.131301\n",
      "[4]\ttraining's binary_logloss: 0.108378\tvalid_1's binary_logloss: 0.123969\n",
      "[6]\ttraining's binary_logloss: 0.0990179\tvalid_1's binary_logloss: 0.119146\n",
      "[8]\ttraining's binary_logloss: 0.0917869\tvalid_1's binary_logloss: 0.115094\n",
      "[10]\ttraining's binary_logloss: 0.0860351\tvalid_1's binary_logloss: 0.111655\n",
      "[12]\ttraining's binary_logloss: 0.0808093\tvalid_1's binary_logloss: 0.109382\n",
      "[14]\ttraining's binary_logloss: 0.076208\tvalid_1's binary_logloss: 0.10744\n",
      "[16]\ttraining's binary_logloss: 0.0720544\tvalid_1's binary_logloss: 0.106217\n",
      "[18]\ttraining's binary_logloss: 0.0681615\tvalid_1's binary_logloss: 0.105153\n",
      "[20]\ttraining's binary_logloss: 0.0647175\tvalid_1's binary_logloss: 0.104203\n",
      "[22]\ttraining's binary_logloss: 0.061555\tvalid_1's binary_logloss: 0.103459\n",
      "[24]\ttraining's binary_logloss: 0.0586579\tvalid_1's binary_logloss: 0.103071\n",
      "[26]\ttraining's binary_logloss: 0.0560763\tvalid_1's binary_logloss: 0.102352\n",
      "[28]\ttraining's binary_logloss: 0.0535861\tvalid_1's binary_logloss: 0.101837\n",
      "[30]\ttraining's binary_logloss: 0.051281\tvalid_1's binary_logloss: 0.101385\n",
      "[32]\ttraining's binary_logloss: 0.0491821\tvalid_1's binary_logloss: 0.101054\n",
      "[34]\ttraining's binary_logloss: 0.0471809\tvalid_1's binary_logloss: 0.100982\n",
      "[36]\ttraining's binary_logloss: 0.0452852\tvalid_1's binary_logloss: 0.100765\n",
      "[38]\ttraining's binary_logloss: 0.0434722\tvalid_1's binary_logloss: 0.100755\n",
      "[40]\ttraining's binary_logloss: 0.0417476\tvalid_1's binary_logloss: 0.100298\n",
      "[42]\ttraining's binary_logloss: 0.0401298\tvalid_1's binary_logloss: 0.0999962\n",
      "[44]\ttraining's binary_logloss: 0.0385085\tvalid_1's binary_logloss: 0.10005\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.0401298\tvalid_1's binary_logloss: 0.0999962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098753:  15%|#5        | 3/20 [00:15<01:33,  5.48s/it][I 2020-09-29 12:22:59,660] Trial 9 finished with value: 0.09999621024471672 and parameters: {'num_leaves': 110}. Best is trial 9 with value: 0.09999621024471672.\n",
      "num_leaves, val_score: 0.098753:  15%|#5        | 3/20 [00:15<01:33,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.116247\tvalid_1's binary_logloss: 0.130495\n",
      "[4]\ttraining's binary_logloss: 0.10071\tvalid_1's binary_logloss: 0.123034\n",
      "[6]\ttraining's binary_logloss: 0.0891503\tvalid_1's binary_logloss: 0.118655\n",
      "[8]\ttraining's binary_logloss: 0.0796436\tvalid_1's binary_logloss: 0.114565\n",
      "[10]\ttraining's binary_logloss: 0.0716259\tvalid_1's binary_logloss: 0.111389\n",
      "[12]\ttraining's binary_logloss: 0.0649469\tvalid_1's binary_logloss: 0.109061\n",
      "[14]\ttraining's binary_logloss: 0.0591685\tvalid_1's binary_logloss: 0.107657\n",
      "[16]\ttraining's binary_logloss: 0.0540088\tvalid_1's binary_logloss: 0.106499\n",
      "[18]\ttraining's binary_logloss: 0.0495438\tvalid_1's binary_logloss: 0.105551\n",
      "[20]\ttraining's binary_logloss: 0.0454284\tvalid_1's binary_logloss: 0.104554\n",
      "[22]\ttraining's binary_logloss: 0.0417023\tvalid_1's binary_logloss: 0.103721\n",
      "[24]\ttraining's binary_logloss: 0.0383912\tvalid_1's binary_logloss: 0.103149\n",
      "[26]\ttraining's binary_logloss: 0.0353357\tvalid_1's binary_logloss: 0.102952\n",
      "[28]\ttraining's binary_logloss: 0.0325563\tvalid_1's binary_logloss: 0.103002\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's binary_logloss: 0.0338639\tvalid_1's binary_logloss: 0.102842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098753:  20%|##        | 4/20 [00:23<01:39,  6.24s/it][I 2020-09-29 12:23:07,680] Trial 10 finished with value: 0.10284166900569558 and parameters: {'num_leaves': 248}. Best is trial 9 with value: 0.09999621024471672.\n",
      "num_leaves, val_score: 0.098753:  20%|##        | 4/20 [00:23<01:39,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.14348\tvalid_1's binary_logloss: 0.142717\n",
      "[4]\ttraining's binary_logloss: 0.138085\tvalid_1's binary_logloss: 0.137762\n",
      "[6]\ttraining's binary_logloss: 0.134309\tvalid_1's binary_logloss: 0.134218\n",
      "[8]\ttraining's binary_logloss: 0.131413\tvalid_1's binary_logloss: 0.131787\n",
      "[10]\ttraining's binary_logloss: 0.128831\tvalid_1's binary_logloss: 0.12928\n",
      "[12]\ttraining's binary_logloss: 0.126877\tvalid_1's binary_logloss: 0.127311\n",
      "[14]\ttraining's binary_logloss: 0.125343\tvalid_1's binary_logloss: 0.125806\n",
      "[16]\ttraining's binary_logloss: 0.123979\tvalid_1's binary_logloss: 0.124324\n",
      "[18]\ttraining's binary_logloss: 0.122848\tvalid_1's binary_logloss: 0.123079\n",
      "[20]\ttraining's binary_logloss: 0.122\tvalid_1's binary_logloss: 0.122211\n",
      "[22]\ttraining's binary_logloss: 0.12112\tvalid_1's binary_logloss: 0.121269\n",
      "[24]\ttraining's binary_logloss: 0.120301\tvalid_1's binary_logloss: 0.120567\n",
      "[26]\ttraining's binary_logloss: 0.119653\tvalid_1's binary_logloss: 0.119908\n",
      "[28]\ttraining's binary_logloss: 0.119082\tvalid_1's binary_logloss: 0.119342\n",
      "[30]\ttraining's binary_logloss: 0.118552\tvalid_1's binary_logloss: 0.118803\n",
      "[32]\ttraining's binary_logloss: 0.118054\tvalid_1's binary_logloss: 0.118259\n",
      "[34]\ttraining's binary_logloss: 0.117619\tvalid_1's binary_logloss: 0.117898\n",
      "[36]\ttraining's binary_logloss: 0.117102\tvalid_1's binary_logloss: 0.117387\n",
      "[38]\ttraining's binary_logloss: 0.116719\tvalid_1's binary_logloss: 0.116916\n",
      "[40]\ttraining's binary_logloss: 0.116337\tvalid_1's binary_logloss: 0.116518\n",
      "[42]\ttraining's binary_logloss: 0.115999\tvalid_1's binary_logloss: 0.116126\n",
      "[44]\ttraining's binary_logloss: 0.115652\tvalid_1's binary_logloss: 0.115807\n",
      "[46]\ttraining's binary_logloss: 0.11536\tvalid_1's binary_logloss: 0.115482\n",
      "[48]\ttraining's binary_logloss: 0.114988\tvalid_1's binary_logloss: 0.115199\n",
      "[50]\ttraining's binary_logloss: 0.114682\tvalid_1's binary_logloss: 0.115008\n",
      "[52]\ttraining's binary_logloss: 0.11436\tvalid_1's binary_logloss: 0.114693\n",
      "[54]\ttraining's binary_logloss: 0.11397\tvalid_1's binary_logloss: 0.114325\n",
      "[56]\ttraining's binary_logloss: 0.113721\tvalid_1's binary_logloss: 0.114163\n",
      "[58]\ttraining's binary_logloss: 0.113406\tvalid_1's binary_logloss: 0.113893\n",
      "[60]\ttraining's binary_logloss: 0.113159\tvalid_1's binary_logloss: 0.113657\n",
      "[62]\ttraining's binary_logloss: 0.112885\tvalid_1's binary_logloss: 0.113403\n",
      "[64]\ttraining's binary_logloss: 0.112594\tvalid_1's binary_logloss: 0.113115\n",
      "[66]\ttraining's binary_logloss: 0.112214\tvalid_1's binary_logloss: 0.11288\n",
      "[68]\ttraining's binary_logloss: 0.111938\tvalid_1's binary_logloss: 0.112744\n",
      "[70]\ttraining's binary_logloss: 0.111736\tvalid_1's binary_logloss: 0.112505\n",
      "[72]\ttraining's binary_logloss: 0.11155\tvalid_1's binary_logloss: 0.11231\n",
      "[74]\ttraining's binary_logloss: 0.111319\tvalid_1's binary_logloss: 0.112103\n",
      "[76]\ttraining's binary_logloss: 0.111036\tvalid_1's binary_logloss: 0.111909\n",
      "[78]\ttraining's binary_logloss: 0.110826\tvalid_1's binary_logloss: 0.111751\n",
      "[80]\ttraining's binary_logloss: 0.110614\tvalid_1's binary_logloss: 0.111533\n",
      "[82]\ttraining's binary_logloss: 0.110435\tvalid_1's binary_logloss: 0.111367\n",
      "[84]\ttraining's binary_logloss: 0.110196\tvalid_1's binary_logloss: 0.111195\n",
      "[86]\ttraining's binary_logloss: 0.110027\tvalid_1's binary_logloss: 0.111066\n",
      "[88]\ttraining's binary_logloss: 0.109885\tvalid_1's binary_logloss: 0.110967\n",
      "[90]\ttraining's binary_logloss: 0.109674\tvalid_1's binary_logloss: 0.110737\n",
      "[92]\ttraining's binary_logloss: 0.109535\tvalid_1's binary_logloss: 0.110556\n",
      "[94]\ttraining's binary_logloss: 0.109378\tvalid_1's binary_logloss: 0.110477\n",
      "[96]\ttraining's binary_logloss: 0.109221\tvalid_1's binary_logloss: 0.110339\n",
      "[98]\ttraining's binary_logloss: 0.108999\tvalid_1's binary_logloss: 0.110185\n",
      "[100]\ttraining's binary_logloss: 0.108864\tvalid_1's binary_logloss: 0.110034\n",
      "[102]\ttraining's binary_logloss: 0.10874\tvalid_1's binary_logloss: 0.109897\n",
      "[104]\ttraining's binary_logloss: 0.108596\tvalid_1's binary_logloss: 0.109762\n",
      "[106]\ttraining's binary_logloss: 0.108474\tvalid_1's binary_logloss: 0.109662\n",
      "[108]\ttraining's binary_logloss: 0.108342\tvalid_1's binary_logloss: 0.109537\n",
      "[110]\ttraining's binary_logloss: 0.108206\tvalid_1's binary_logloss: 0.10946\n",
      "[112]\ttraining's binary_logloss: 0.108097\tvalid_1's binary_logloss: 0.109379\n",
      "[114]\ttraining's binary_logloss: 0.107972\tvalid_1's binary_logloss: 0.109308\n",
      "[116]\ttraining's binary_logloss: 0.107842\tvalid_1's binary_logloss: 0.109165\n",
      "[118]\ttraining's binary_logloss: 0.107608\tvalid_1's binary_logloss: 0.108959\n",
      "[120]\ttraining's binary_logloss: 0.107494\tvalid_1's binary_logloss: 0.108898\n",
      "[122]\ttraining's binary_logloss: 0.107374\tvalid_1's binary_logloss: 0.108856\n",
      "[124]\ttraining's binary_logloss: 0.107239\tvalid_1's binary_logloss: 0.108684\n",
      "[126]\ttraining's binary_logloss: 0.107111\tvalid_1's binary_logloss: 0.108494\n",
      "[128]\ttraining's binary_logloss: 0.107\tvalid_1's binary_logloss: 0.108434\n",
      "[130]\ttraining's binary_logloss: 0.106902\tvalid_1's binary_logloss: 0.108357\n",
      "[132]\ttraining's binary_logloss: 0.106794\tvalid_1's binary_logloss: 0.108257\n",
      "[134]\ttraining's binary_logloss: 0.106661\tvalid_1's binary_logloss: 0.108202\n",
      "[136]\ttraining's binary_logloss: 0.106552\tvalid_1's binary_logloss: 0.1082\n",
      "Early stopping, best iteration is:\n",
      "[135]\ttraining's binary_logloss: 0.106615\tvalid_1's binary_logloss: 0.108183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098753:  25%|##5       | 5/20 [00:29<01:30,  6.03s/it][I 2020-09-29 12:23:13,213] Trial 11 finished with value: 0.10818255387676817 and parameters: {'num_leaves': 3}. Best is trial 9 with value: 0.09999621024471672.\n",
      "num_leaves, val_score: 0.098753:  25%|##5       | 5/20 [00:29<01:30,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.14602\tvalid_1's binary_logloss: 0.144702\n",
      "[4]\ttraining's binary_logloss: 0.141623\tvalid_1's binary_logloss: 0.140612\n",
      "[6]\ttraining's binary_logloss: 0.138929\tvalid_1's binary_logloss: 0.137995\n",
      "[8]\ttraining's binary_logloss: 0.136922\tvalid_1's binary_logloss: 0.135953\n",
      "[10]\ttraining's binary_logloss: 0.135242\tvalid_1's binary_logloss: 0.13425\n",
      "[12]\ttraining's binary_logloss: 0.133848\tvalid_1's binary_logloss: 0.132907\n",
      "[14]\ttraining's binary_logloss: 0.132635\tvalid_1's binary_logloss: 0.131709\n",
      "[16]\ttraining's binary_logloss: 0.131548\tvalid_1's binary_logloss: 0.13062\n",
      "[18]\ttraining's binary_logloss: 0.1306\tvalid_1's binary_logloss: 0.129589\n",
      "[20]\ttraining's binary_logloss: 0.129757\tvalid_1's binary_logloss: 0.128737\n",
      "[22]\ttraining's binary_logloss: 0.128993\tvalid_1's binary_logloss: 0.127921\n",
      "[24]\ttraining's binary_logloss: 0.128314\tvalid_1's binary_logloss: 0.127199\n",
      "[26]\ttraining's binary_logloss: 0.127673\tvalid_1's binary_logloss: 0.126628\n",
      "[28]\ttraining's binary_logloss: 0.127077\tvalid_1's binary_logloss: 0.126162\n",
      "[30]\ttraining's binary_logloss: 0.126516\tvalid_1's binary_logloss: 0.125576\n",
      "[32]\ttraining's binary_logloss: 0.126021\tvalid_1's binary_logloss: 0.125078\n",
      "[34]\ttraining's binary_logloss: 0.125555\tvalid_1's binary_logloss: 0.124565\n",
      "[36]\ttraining's binary_logloss: 0.125117\tvalid_1's binary_logloss: 0.124185\n",
      "[38]\ttraining's binary_logloss: 0.124716\tvalid_1's binary_logloss: 0.123873\n",
      "[40]\ttraining's binary_logloss: 0.124333\tvalid_1's binary_logloss: 0.123591\n",
      "[42]\ttraining's binary_logloss: 0.123965\tvalid_1's binary_logloss: 0.123158\n",
      "[44]\ttraining's binary_logloss: 0.123633\tvalid_1's binary_logloss: 0.122832\n",
      "[46]\ttraining's binary_logloss: 0.123305\tvalid_1's binary_logloss: 0.1224\n",
      "[48]\ttraining's binary_logloss: 0.122994\tvalid_1's binary_logloss: 0.122084\n",
      "[50]\ttraining's binary_logloss: 0.122702\tvalid_1's binary_logloss: 0.121792\n",
      "[52]\ttraining's binary_logloss: 0.122421\tvalid_1's binary_logloss: 0.121454\n",
      "[54]\ttraining's binary_logloss: 0.122158\tvalid_1's binary_logloss: 0.12112\n",
      "[56]\ttraining's binary_logloss: 0.121901\tvalid_1's binary_logloss: 0.120714\n",
      "[58]\ttraining's binary_logloss: 0.121657\tvalid_1's binary_logloss: 0.12058\n",
      "[60]\ttraining's binary_logloss: 0.121423\tvalid_1's binary_logloss: 0.120506\n",
      "[62]\ttraining's binary_logloss: 0.121196\tvalid_1's binary_logloss: 0.120257\n",
      "[64]\ttraining's binary_logloss: 0.120978\tvalid_1's binary_logloss: 0.119954\n",
      "[66]\ttraining's binary_logloss: 0.120772\tvalid_1's binary_logloss: 0.119771\n",
      "[68]\ttraining's binary_logloss: 0.120573\tvalid_1's binary_logloss: 0.119575\n",
      "[70]\ttraining's binary_logloss: 0.12038\tvalid_1's binary_logloss: 0.119403\n",
      "[72]\ttraining's binary_logloss: 0.120193\tvalid_1's binary_logloss: 0.119161\n",
      "[74]\ttraining's binary_logloss: 0.120012\tvalid_1's binary_logloss: 0.118972\n",
      "[76]\ttraining's binary_logloss: 0.119832\tvalid_1's binary_logloss: 0.118818\n",
      "[78]\ttraining's binary_logloss: 0.119659\tvalid_1's binary_logloss: 0.118649\n",
      "[80]\ttraining's binary_logloss: 0.11949\tvalid_1's binary_logloss: 0.118444\n",
      "[82]\ttraining's binary_logloss: 0.119324\tvalid_1's binary_logloss: 0.118234\n",
      "[84]\ttraining's binary_logloss: 0.119162\tvalid_1's binary_logloss: 0.118119\n",
      "[86]\ttraining's binary_logloss: 0.119003\tvalid_1's binary_logloss: 0.117936\n",
      "[88]\ttraining's binary_logloss: 0.118847\tvalid_1's binary_logloss: 0.117808\n",
      "[90]\ttraining's binary_logloss: 0.118693\tvalid_1's binary_logloss: 0.117667\n",
      "[92]\ttraining's binary_logloss: 0.118547\tvalid_1's binary_logloss: 0.117558\n",
      "[94]\ttraining's binary_logloss: 0.118402\tvalid_1's binary_logloss: 0.117343\n",
      "[96]\ttraining's binary_logloss: 0.11826\tvalid_1's binary_logloss: 0.117241\n",
      "[98]\ttraining's binary_logloss: 0.118122\tvalid_1's binary_logloss: 0.117057\n",
      "[100]\ttraining's binary_logloss: 0.117984\tvalid_1's binary_logloss: 0.11693\n",
      "[102]\ttraining's binary_logloss: 0.117851\tvalid_1's binary_logloss: 0.116811\n",
      "[104]\ttraining's binary_logloss: 0.117721\tvalid_1's binary_logloss: 0.116633\n",
      "[106]\ttraining's binary_logloss: 0.117593\tvalid_1's binary_logloss: 0.116531\n",
      "[108]\ttraining's binary_logloss: 0.117469\tvalid_1's binary_logloss: 0.116472\n",
      "[110]\ttraining's binary_logloss: 0.117345\tvalid_1's binary_logloss: 0.116358\n",
      "[112]\ttraining's binary_logloss: 0.117224\tvalid_1's binary_logloss: 0.11622\n",
      "[114]\ttraining's binary_logloss: 0.117107\tvalid_1's binary_logloss: 0.116081\n",
      "[116]\ttraining's binary_logloss: 0.116991\tvalid_1's binary_logloss: 0.115927\n",
      "[118]\ttraining's binary_logloss: 0.116876\tvalid_1's binary_logloss: 0.115821\n",
      "[120]\ttraining's binary_logloss: 0.116761\tvalid_1's binary_logloss: 0.115746\n",
      "[122]\ttraining's binary_logloss: 0.116647\tvalid_1's binary_logloss: 0.115645\n",
      "[124]\ttraining's binary_logloss: 0.116537\tvalid_1's binary_logloss: 0.115502\n",
      "[126]\ttraining's binary_logloss: 0.116428\tvalid_1's binary_logloss: 0.115407\n",
      "[128]\ttraining's binary_logloss: 0.116322\tvalid_1's binary_logloss: 0.115305\n",
      "[130]\ttraining's binary_logloss: 0.116215\tvalid_1's binary_logloss: 0.115197\n",
      "[132]\ttraining's binary_logloss: 0.116112\tvalid_1's binary_logloss: 0.115124\n",
      "[134]\ttraining's binary_logloss: 0.116009\tvalid_1's binary_logloss: 0.115048\n",
      "[136]\ttraining's binary_logloss: 0.115907\tvalid_1's binary_logloss: 0.114958\n",
      "[138]\ttraining's binary_logloss: 0.115808\tvalid_1's binary_logloss: 0.114829\n",
      "[140]\ttraining's binary_logloss: 0.115709\tvalid_1's binary_logloss: 0.114714\n",
      "[142]\ttraining's binary_logloss: 0.115612\tvalid_1's binary_logloss: 0.114658\n",
      "[144]\ttraining's binary_logloss: 0.115517\tvalid_1's binary_logloss: 0.114604\n",
      "[146]\ttraining's binary_logloss: 0.115425\tvalid_1's binary_logloss: 0.114516\n",
      "[148]\ttraining's binary_logloss: 0.115333\tvalid_1's binary_logloss: 0.114397\n",
      "[150]\ttraining's binary_logloss: 0.115241\tvalid_1's binary_logloss: 0.11424\n",
      "[152]\ttraining's binary_logloss: 0.11515\tvalid_1's binary_logloss: 0.114227\n",
      "[154]\ttraining's binary_logloss: 0.115063\tvalid_1's binary_logloss: 0.114137\n",
      "[156]\ttraining's binary_logloss: 0.114977\tvalid_1's binary_logloss: 0.114079\n",
      "[158]\ttraining's binary_logloss: 0.114889\tvalid_1's binary_logloss: 0.113956\n",
      "[160]\ttraining's binary_logloss: 0.114803\tvalid_1's binary_logloss: 0.113858\n",
      "[162]\ttraining's binary_logloss: 0.114718\tvalid_1's binary_logloss: 0.113776\n",
      "[164]\ttraining's binary_logloss: 0.114633\tvalid_1's binary_logloss: 0.113699\n",
      "[166]\ttraining's binary_logloss: 0.11455\tvalid_1's binary_logloss: 0.113625\n",
      "[168]\ttraining's binary_logloss: 0.114465\tvalid_1's binary_logloss: 0.113564\n",
      "[170]\ttraining's binary_logloss: 0.114383\tvalid_1's binary_logloss: 0.113516\n",
      "[172]\ttraining's binary_logloss: 0.114302\tvalid_1's binary_logloss: 0.113458\n",
      "[174]\ttraining's binary_logloss: 0.114222\tvalid_1's binary_logloss: 0.113381\n",
      "[176]\ttraining's binary_logloss: 0.114143\tvalid_1's binary_logloss: 0.113293\n",
      "[178]\ttraining's binary_logloss: 0.114066\tvalid_1's binary_logloss: 0.113225\n",
      "[180]\ttraining's binary_logloss: 0.113989\tvalid_1's binary_logloss: 0.113206\n",
      "[182]\ttraining's binary_logloss: 0.113912\tvalid_1's binary_logloss: 0.113137\n",
      "[184]\ttraining's binary_logloss: 0.113838\tvalid_1's binary_logloss: 0.11303\n",
      "[186]\ttraining's binary_logloss: 0.113765\tvalid_1's binary_logloss: 0.112976\n",
      "[188]\ttraining's binary_logloss: 0.113691\tvalid_1's binary_logloss: 0.112917\n",
      "[190]\ttraining's binary_logloss: 0.113616\tvalid_1's binary_logloss: 0.112793\n",
      "[192]\ttraining's binary_logloss: 0.113544\tvalid_1's binary_logloss: 0.112707\n",
      "[194]\ttraining's binary_logloss: 0.113471\tvalid_1's binary_logloss: 0.112662\n",
      "[196]\ttraining's binary_logloss: 0.113402\tvalid_1's binary_logloss: 0.112606\n",
      "[198]\ttraining's binary_logloss: 0.113333\tvalid_1's binary_logloss: 0.112586\n",
      "Early stopping, best iteration is:\n",
      "[197]\ttraining's binary_logloss: 0.113368\tvalid_1's binary_logloss: 0.112574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098753:  30%|###       | 6/20 [00:39<01:42,  7.32s/it][I 2020-09-29 12:23:23,614] Trial 12 finished with value: 0.11257388077748386 and parameters: {'num_leaves': 2}. Best is trial 9 with value: 0.09999621024471672.\n",
      "num_leaves, val_score: 0.098753:  30%|###       | 6/20 [00:39<01:42,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.117936\tvalid_1's binary_logloss: 0.130889\n",
      "[4]\ttraining's binary_logloss: 0.103808\tvalid_1's binary_logloss: 0.12351\n",
      "[6]\ttraining's binary_logloss: 0.0932588\tvalid_1's binary_logloss: 0.118812\n",
      "[8]\ttraining's binary_logloss: 0.0847292\tvalid_1's binary_logloss: 0.114797\n",
      "[10]\ttraining's binary_logloss: 0.0777852\tvalid_1's binary_logloss: 0.111614\n",
      "[12]\ttraining's binary_logloss: 0.0718371\tvalid_1's binary_logloss: 0.109463\n",
      "[14]\ttraining's binary_logloss: 0.0666515\tvalid_1's binary_logloss: 0.107942\n",
      "[16]\ttraining's binary_logloss: 0.0617102\tvalid_1's binary_logloss: 0.10651\n",
      "[18]\ttraining's binary_logloss: 0.0574425\tvalid_1's binary_logloss: 0.105515\n",
      "[20]\ttraining's binary_logloss: 0.0535715\tvalid_1's binary_logloss: 0.104828\n",
      "[22]\ttraining's binary_logloss: 0.0499851\tvalid_1's binary_logloss: 0.104203\n",
      "[24]\ttraining's binary_logloss: 0.0467952\tvalid_1's binary_logloss: 0.10363\n",
      "[26]\ttraining's binary_logloss: 0.0438095\tvalid_1's binary_logloss: 0.103241\n",
      "[28]\ttraining's binary_logloss: 0.0410028\tvalid_1's binary_logloss: 0.102837\n",
      "[30]\ttraining's binary_logloss: 0.0385627\tvalid_1's binary_logloss: 0.102576\n",
      "[32]\ttraining's binary_logloss: 0.0362466\tvalid_1's binary_logloss: 0.102157\n",
      "[34]\ttraining's binary_logloss: 0.034189\tvalid_1's binary_logloss: 0.101996\n",
      "[36]\ttraining's binary_logloss: 0.0322439\tvalid_1's binary_logloss: 0.101988\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.0331503\tvalid_1's binary_logloss: 0.101962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098753:  35%|###5      | 7/20 [00:44<01:27,  6.70s/it][I 2020-09-29 12:23:28,781] Trial 13 finished with value: 0.10196189145844324 and parameters: {'num_leaves': 177}. Best is trial 9 with value: 0.09999621024471672.\n",
      "num_leaves, val_score: 0.098753:  35%|###5      | 7/20 [00:44<01:27,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125393\tvalid_1's binary_logloss: 0.132404\n",
      "[4]\ttraining's binary_logloss: 0.115239\tvalid_1's binary_logloss: 0.125599\n",
      "[6]\ttraining's binary_logloss: 0.107747\tvalid_1's binary_logloss: 0.120268\n",
      "[8]\ttraining's binary_logloss: 0.102089\tvalid_1's binary_logloss: 0.11653\n",
      "[10]\ttraining's binary_logloss: 0.0971732\tvalid_1's binary_logloss: 0.113765\n",
      "[12]\ttraining's binary_logloss: 0.0932217\tvalid_1's binary_logloss: 0.111333\n",
      "[14]\ttraining's binary_logloss: 0.0898247\tvalid_1's binary_logloss: 0.109693\n",
      "[16]\ttraining's binary_logloss: 0.0869956\tvalid_1's binary_logloss: 0.108299\n",
      "[18]\ttraining's binary_logloss: 0.0842668\tvalid_1's binary_logloss: 0.107277\n",
      "[20]\ttraining's binary_logloss: 0.0814157\tvalid_1's binary_logloss: 0.105943\n",
      "[22]\ttraining's binary_logloss: 0.0787748\tvalid_1's binary_logloss: 0.104845\n",
      "[24]\ttraining's binary_logloss: 0.0764321\tvalid_1's binary_logloss: 0.104147\n",
      "[26]\ttraining's binary_logloss: 0.0742675\tvalid_1's binary_logloss: 0.103318\n",
      "[28]\ttraining's binary_logloss: 0.0723644\tvalid_1's binary_logloss: 0.102717\n",
      "[30]\ttraining's binary_logloss: 0.0703418\tvalid_1's binary_logloss: 0.101887\n",
      "[32]\ttraining's binary_logloss: 0.0684899\tvalid_1's binary_logloss: 0.101362\n",
      "[34]\ttraining's binary_logloss: 0.0668445\tvalid_1's binary_logloss: 0.101041\n",
      "[36]\ttraining's binary_logloss: 0.0652513\tvalid_1's binary_logloss: 0.10086\n",
      "[38]\ttraining's binary_logloss: 0.0636447\tvalid_1's binary_logloss: 0.100468\n",
      "[40]\ttraining's binary_logloss: 0.0621543\tvalid_1's binary_logloss: 0.100096\n",
      "[42]\ttraining's binary_logloss: 0.0608098\tvalid_1's binary_logloss: 0.0996574\n",
      "[44]\ttraining's binary_logloss: 0.0594349\tvalid_1's binary_logloss: 0.099372\n",
      "[46]\ttraining's binary_logloss: 0.0583112\tvalid_1's binary_logloss: 0.099109\n",
      "[48]\ttraining's binary_logloss: 0.0570632\tvalid_1's binary_logloss: 0.0988165\n",
      "[50]\ttraining's binary_logloss: 0.0559554\tvalid_1's binary_logloss: 0.0984941\n",
      "[52]\ttraining's binary_logloss: 0.0546735\tvalid_1's binary_logloss: 0.0985983\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's binary_logloss: 0.0559554\tvalid_1's binary_logloss: 0.0984941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098494:  40%|####      | 8/20 [00:49<01:13,  6.13s/it][I 2020-09-29 12:23:33,604] Trial 14 finished with value: 0.09849414830868149 and parameters: {'num_leaves': 53}. Best is trial 14 with value: 0.09849414830868149.\n",
      "num_leaves, val_score: 0.098494:  40%|####      | 8/20 [00:49<01:13,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.124634\tvalid_1's binary_logloss: 0.132119\n",
      "[4]\ttraining's binary_logloss: 0.114212\tvalid_1's binary_logloss: 0.125417\n",
      "[6]\ttraining's binary_logloss: 0.106422\tvalid_1's binary_logloss: 0.119791\n",
      "[8]\ttraining's binary_logloss: 0.100413\tvalid_1's binary_logloss: 0.116167\n",
      "[10]\ttraining's binary_logloss: 0.0955846\tvalid_1's binary_logloss: 0.113194\n",
      "[12]\ttraining's binary_logloss: 0.0916405\tvalid_1's binary_logloss: 0.11098\n",
      "[14]\ttraining's binary_logloss: 0.0879906\tvalid_1's binary_logloss: 0.109325\n",
      "[16]\ttraining's binary_logloss: 0.0847987\tvalid_1's binary_logloss: 0.108027\n",
      "[18]\ttraining's binary_logloss: 0.0817535\tvalid_1's binary_logloss: 0.107106\n",
      "[20]\ttraining's binary_logloss: 0.0789171\tvalid_1's binary_logloss: 0.106092\n",
      "[22]\ttraining's binary_logloss: 0.0762993\tvalid_1's binary_logloss: 0.105223\n",
      "[24]\ttraining's binary_logloss: 0.0738678\tvalid_1's binary_logloss: 0.104375\n",
      "[26]\ttraining's binary_logloss: 0.071549\tvalid_1's binary_logloss: 0.103935\n",
      "[28]\ttraining's binary_logloss: 0.0694478\tvalid_1's binary_logloss: 0.103232\n",
      "[30]\ttraining's binary_logloss: 0.0675458\tvalid_1's binary_logloss: 0.102544\n",
      "[32]\ttraining's binary_logloss: 0.0655294\tvalid_1's binary_logloss: 0.101934\n",
      "[34]\ttraining's binary_logloss: 0.0636986\tvalid_1's binary_logloss: 0.101687\n",
      "[36]\ttraining's binary_logloss: 0.0619655\tvalid_1's binary_logloss: 0.10121\n",
      "[38]\ttraining's binary_logloss: 0.0604666\tvalid_1's binary_logloss: 0.100974\n",
      "[40]\ttraining's binary_logloss: 0.059041\tvalid_1's binary_logloss: 0.100691\n",
      "[42]\ttraining's binary_logloss: 0.0575937\tvalid_1's binary_logloss: 0.100341\n",
      "[44]\ttraining's binary_logloss: 0.0563486\tvalid_1's binary_logloss: 0.100016\n",
      "[46]\ttraining's binary_logloss: 0.0551171\tvalid_1's binary_logloss: 0.0998488\n",
      "[48]\ttraining's binary_logloss: 0.0539197\tvalid_1's binary_logloss: 0.0997866\n",
      "[50]\ttraining's binary_logloss: 0.0527604\tvalid_1's binary_logloss: 0.0997147\n",
      "[52]\ttraining's binary_logloss: 0.051578\tvalid_1's binary_logloss: 0.0994441\n",
      "[54]\ttraining's binary_logloss: 0.0505111\tvalid_1's binary_logloss: 0.0994157\n",
      "[56]\ttraining's binary_logloss: 0.0494406\tvalid_1's binary_logloss: 0.0992716\n",
      "[58]\ttraining's binary_logloss: 0.0485879\tvalid_1's binary_logloss: 0.0993281\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.0494406\tvalid_1's binary_logloss: 0.0992716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098494:  45%|####5     | 9/20 [00:54<01:04,  5.90s/it][I 2020-09-29 12:23:38,944] Trial 15 finished with value: 0.09927164572542217 and parameters: {'num_leaves': 59}. Best is trial 14 with value: 0.09849414830868149.\n",
      "num_leaves, val_score: 0.098494:  45%|####5     | 9/20 [00:54<01:04,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.12741\tvalid_1's binary_logloss: 0.133456\n",
      "[4]\ttraining's binary_logloss: 0.118225\tvalid_1's binary_logloss: 0.126584\n",
      "[6]\ttraining's binary_logloss: 0.111394\tvalid_1's binary_logloss: 0.12115\n",
      "[8]\ttraining's binary_logloss: 0.106385\tvalid_1's binary_logloss: 0.117529\n",
      "[10]\ttraining's binary_logloss: 0.102145\tvalid_1's binary_logloss: 0.114192\n",
      "[12]\ttraining's binary_logloss: 0.0984986\tvalid_1's binary_logloss: 0.111785\n",
      "[14]\ttraining's binary_logloss: 0.0956753\tvalid_1's binary_logloss: 0.110105\n",
      "[16]\ttraining's binary_logloss: 0.0931316\tvalid_1's binary_logloss: 0.109033\n",
      "[18]\ttraining's binary_logloss: 0.0907075\tvalid_1's binary_logloss: 0.107891\n",
      "[20]\ttraining's binary_logloss: 0.0881666\tvalid_1's binary_logloss: 0.107088\n",
      "[22]\ttraining's binary_logloss: 0.0858699\tvalid_1's binary_logloss: 0.10609\n",
      "[24]\ttraining's binary_logloss: 0.0840974\tvalid_1's binary_logloss: 0.105409\n",
      "[26]\ttraining's binary_logloss: 0.0823099\tvalid_1's binary_logloss: 0.104757\n",
      "[28]\ttraining's binary_logloss: 0.0804944\tvalid_1's binary_logloss: 0.104132\n",
      "[30]\ttraining's binary_logloss: 0.0788118\tvalid_1's binary_logloss: 0.103367\n",
      "[32]\ttraining's binary_logloss: 0.0770965\tvalid_1's binary_logloss: 0.103015\n",
      "[34]\ttraining's binary_logloss: 0.0757105\tvalid_1's binary_logloss: 0.102476\n",
      "[36]\ttraining's binary_logloss: 0.0742788\tvalid_1's binary_logloss: 0.10213\n",
      "[38]\ttraining's binary_logloss: 0.0728446\tvalid_1's binary_logloss: 0.1016\n",
      "[40]\ttraining's binary_logloss: 0.0715952\tvalid_1's binary_logloss: 0.101259\n",
      "[42]\ttraining's binary_logloss: 0.0703756\tvalid_1's binary_logloss: 0.100914\n",
      "[44]\ttraining's binary_logloss: 0.0691941\tvalid_1's binary_logloss: 0.100555\n",
      "[46]\ttraining's binary_logloss: 0.0680145\tvalid_1's binary_logloss: 0.100398\n",
      "[48]\ttraining's binary_logloss: 0.0668821\tvalid_1's binary_logloss: 0.100307\n",
      "[50]\ttraining's binary_logloss: 0.0658367\tvalid_1's binary_logloss: 0.100146\n",
      "[52]\ttraining's binary_logloss: 0.0648991\tvalid_1's binary_logloss: 0.099879\n",
      "[54]\ttraining's binary_logloss: 0.0639052\tvalid_1's binary_logloss: 0.0997734\n",
      "[56]\ttraining's binary_logloss: 0.0630958\tvalid_1's binary_logloss: 0.0998457\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.0639052\tvalid_1's binary_logloss: 0.0997734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098494:  50%|####5    | 10/20 [00:59<00:54,  5.46s/it][I 2020-09-29 12:23:43,376] Trial 16 finished with value: 0.09977336620878657 and parameters: {'num_leaves': 37}. Best is trial 14 with value: 0.09849414830868149.\n",
      "num_leaves, val_score: 0.098494:  50%|####5    | 10/20 [00:59<00:54,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.11894\tvalid_1's binary_logloss: 0.131112\n",
      "[4]\ttraining's binary_logloss: 0.105706\tvalid_1's binary_logloss: 0.123775\n",
      "[6]\ttraining's binary_logloss: 0.0955625\tvalid_1's binary_logloss: 0.118891\n",
      "[8]\ttraining's binary_logloss: 0.0875565\tvalid_1's binary_logloss: 0.115142\n",
      "[10]\ttraining's binary_logloss: 0.0809438\tvalid_1's binary_logloss: 0.112259\n",
      "[12]\ttraining's binary_logloss: 0.0753255\tvalid_1's binary_logloss: 0.109555\n",
      "[14]\ttraining's binary_logloss: 0.0703208\tvalid_1's binary_logloss: 0.107861\n",
      "[16]\ttraining's binary_logloss: 0.0656894\tvalid_1's binary_logloss: 0.106778\n",
      "[18]\ttraining's binary_logloss: 0.0616918\tvalid_1's binary_logloss: 0.105878\n",
      "[20]\ttraining's binary_logloss: 0.0579539\tvalid_1's binary_logloss: 0.104926\n",
      "[22]\ttraining's binary_logloss: 0.0546453\tvalid_1's binary_logloss: 0.104449\n",
      "[24]\ttraining's binary_logloss: 0.0516386\tvalid_1's binary_logloss: 0.103992\n",
      "[26]\ttraining's binary_logloss: 0.0488299\tvalid_1's binary_logloss: 0.10336\n",
      "[28]\ttraining's binary_logloss: 0.0462601\tvalid_1's binary_logloss: 0.102559\n",
      "[30]\ttraining's binary_logloss: 0.043748\tvalid_1's binary_logloss: 0.102031\n",
      "[32]\ttraining's binary_logloss: 0.0414553\tvalid_1's binary_logloss: 0.101779\n",
      "[34]\ttraining's binary_logloss: 0.0393944\tvalid_1's binary_logloss: 0.101792\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's binary_logloss: 0.0403574\tvalid_1's binary_logloss: 0.101698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098494:  55%|####9    | 11/20 [01:03<00:46,  5.12s/it][I 2020-09-29 12:23:47,712] Trial 17 finished with value: 0.10169751472678475 and parameters: {'num_leaves': 146}. Best is trial 14 with value: 0.09849414830868149.\n",
      "num_leaves, val_score: 0.098494:  55%|####9    | 11/20 [01:03<00:46,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.117916\tvalid_1's binary_logloss: 0.130888\n",
      "[4]\ttraining's binary_logloss: 0.103787\tvalid_1's binary_logloss: 0.123537\n",
      "[6]\ttraining's binary_logloss: 0.0931639\tvalid_1's binary_logloss: 0.118778\n",
      "[8]\ttraining's binary_logloss: 0.0845736\tvalid_1's binary_logloss: 0.115204\n",
      "[10]\ttraining's binary_logloss: 0.0776883\tvalid_1's binary_logloss: 0.112379\n",
      "[12]\ttraining's binary_logloss: 0.0716863\tvalid_1's binary_logloss: 0.110012\n",
      "[14]\ttraining's binary_logloss: 0.0664068\tvalid_1's binary_logloss: 0.108553\n",
      "[16]\ttraining's binary_logloss: 0.0616722\tvalid_1's binary_logloss: 0.107196\n",
      "[18]\ttraining's binary_logloss: 0.0573199\tvalid_1's binary_logloss: 0.106484\n",
      "[20]\ttraining's binary_logloss: 0.0533573\tvalid_1's binary_logloss: 0.105382\n",
      "[22]\ttraining's binary_logloss: 0.0499409\tvalid_1's binary_logloss: 0.10479\n",
      "[24]\ttraining's binary_logloss: 0.0465706\tvalid_1's binary_logloss: 0.103894\n",
      "[26]\ttraining's binary_logloss: 0.0437015\tvalid_1's binary_logloss: 0.103332\n",
      "[28]\ttraining's binary_logloss: 0.0411953\tvalid_1's binary_logloss: 0.102808\n",
      "[30]\ttraining's binary_logloss: 0.0386699\tvalid_1's binary_logloss: 0.102803\n",
      "[32]\ttraining's binary_logloss: 0.036475\tvalid_1's binary_logloss: 0.102254\n",
      "[34]\ttraining's binary_logloss: 0.0343283\tvalid_1's binary_logloss: 0.102265\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's binary_logloss: 0.035378\tvalid_1's binary_logloss: 0.102229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098494:  60%|#####3   | 12/20 [01:08<00:41,  5.16s/it][I 2020-09-29 12:23:52,970] Trial 18 finished with value: 0.10222854526175819 and parameters: {'num_leaves': 178}. Best is trial 14 with value: 0.09849414830868149.\n",
      "num_leaves, val_score: 0.098494:  60%|#####3   | 12/20 [01:08<00:41,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125267\tvalid_1's binary_logloss: 0.132384\n",
      "[4]\ttraining's binary_logloss: 0.115081\tvalid_1's binary_logloss: 0.12559\n",
      "[6]\ttraining's binary_logloss: 0.107627\tvalid_1's binary_logloss: 0.120453\n",
      "[8]\ttraining's binary_logloss: 0.101969\tvalid_1's binary_logloss: 0.116465\n",
      "[10]\ttraining's binary_logloss: 0.0971941\tvalid_1's binary_logloss: 0.113581\n",
      "[12]\ttraining's binary_logloss: 0.093115\tvalid_1's binary_logloss: 0.110853\n",
      "[14]\ttraining's binary_logloss: 0.0897096\tvalid_1's binary_logloss: 0.109159\n",
      "[16]\ttraining's binary_logloss: 0.0866494\tvalid_1's binary_logloss: 0.107383\n",
      "[18]\ttraining's binary_logloss: 0.0839164\tvalid_1's binary_logloss: 0.106121\n",
      "[20]\ttraining's binary_logloss: 0.0812072\tvalid_1's binary_logloss: 0.105037\n",
      "[22]\ttraining's binary_logloss: 0.0785051\tvalid_1's binary_logloss: 0.104285\n",
      "[24]\ttraining's binary_logloss: 0.0761164\tvalid_1's binary_logloss: 0.103399\n",
      "[26]\ttraining's binary_logloss: 0.0739609\tvalid_1's binary_logloss: 0.102885\n",
      "[28]\ttraining's binary_logloss: 0.0719805\tvalid_1's binary_logloss: 0.102383\n",
      "[30]\ttraining's binary_logloss: 0.0697965\tvalid_1's binary_logloss: 0.101602\n",
      "[32]\ttraining's binary_logloss: 0.0680342\tvalid_1's binary_logloss: 0.101257\n",
      "[34]\ttraining's binary_logloss: 0.0662931\tvalid_1's binary_logloss: 0.100678\n",
      "[36]\ttraining's binary_logloss: 0.0645954\tvalid_1's binary_logloss: 0.100166\n",
      "[38]\ttraining's binary_logloss: 0.0629894\tvalid_1's binary_logloss: 0.0997781\n",
      "[40]\ttraining's binary_logloss: 0.0614507\tvalid_1's binary_logloss: 0.0994439\n",
      "[42]\ttraining's binary_logloss: 0.0599692\tvalid_1's binary_logloss: 0.0993117\n",
      "[44]\ttraining's binary_logloss: 0.0586993\tvalid_1's binary_logloss: 0.0991086\n",
      "[46]\ttraining's binary_logloss: 0.0575396\tvalid_1's binary_logloss: 0.098902\n",
      "[48]\ttraining's binary_logloss: 0.0563583\tvalid_1's binary_logloss: 0.0988836\n",
      "[50]\ttraining's binary_logloss: 0.0553407\tvalid_1's binary_logloss: 0.0988265\n",
      "[52]\ttraining's binary_logloss: 0.0542419\tvalid_1's binary_logloss: 0.0983729\n",
      "[54]\ttraining's binary_logloss: 0.0532788\tvalid_1's binary_logloss: 0.098301\n",
      "[56]\ttraining's binary_logloss: 0.0521517\tvalid_1's binary_logloss: 0.0982478\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's binary_logloss: 0.0526866\tvalid_1's binary_logloss: 0.0982235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098223:  65%|#####8   | 13/20 [01:14<00:36,  5.18s/it][I 2020-09-29 12:23:58,194] Trial 19 finished with value: 0.09822346584920524 and parameters: {'num_leaves': 54}. Best is trial 19 with value: 0.09822346584920524.\n",
      "num_leaves, val_score: 0.098223:  65%|#####8   | 13/20 [01:14<00:36,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.127325\tvalid_1's binary_logloss: 0.133685\n",
      "[4]\ttraining's binary_logloss: 0.11819\tvalid_1's binary_logloss: 0.126515\n",
      "[6]\ttraining's binary_logloss: 0.111487\tvalid_1's binary_logloss: 0.121428\n",
      "[8]\ttraining's binary_logloss: 0.10627\tvalid_1's binary_logloss: 0.118127\n",
      "[10]\ttraining's binary_logloss: 0.102135\tvalid_1's binary_logloss: 0.115457\n",
      "[12]\ttraining's binary_logloss: 0.0984434\tvalid_1's binary_logloss: 0.11307\n",
      "[14]\ttraining's binary_logloss: 0.095611\tvalid_1's binary_logloss: 0.111285\n",
      "[16]\ttraining's binary_logloss: 0.0927971\tvalid_1's binary_logloss: 0.109598\n",
      "[18]\ttraining's binary_logloss: 0.0903164\tvalid_1's binary_logloss: 0.108312\n",
      "[20]\ttraining's binary_logloss: 0.0879548\tvalid_1's binary_logloss: 0.107253\n",
      "[22]\ttraining's binary_logloss: 0.0860357\tvalid_1's binary_logloss: 0.106622\n",
      "[24]\ttraining's binary_logloss: 0.0839888\tvalid_1's binary_logloss: 0.105853\n",
      "[26]\ttraining's binary_logloss: 0.0820885\tvalid_1's binary_logloss: 0.105012\n",
      "[28]\ttraining's binary_logloss: 0.0804066\tvalid_1's binary_logloss: 0.10444\n",
      "[30]\ttraining's binary_logloss: 0.0786998\tvalid_1's binary_logloss: 0.103944\n",
      "[32]\ttraining's binary_logloss: 0.0772467\tvalid_1's binary_logloss: 0.103495\n",
      "[34]\ttraining's binary_logloss: 0.0755744\tvalid_1's binary_logloss: 0.103077\n",
      "[36]\ttraining's binary_logloss: 0.073981\tvalid_1's binary_logloss: 0.102426\n",
      "[38]\ttraining's binary_logloss: 0.072629\tvalid_1's binary_logloss: 0.102045\n",
      "[40]\ttraining's binary_logloss: 0.071177\tvalid_1's binary_logloss: 0.101774\n",
      "[42]\ttraining's binary_logloss: 0.0699959\tvalid_1's binary_logloss: 0.101541\n",
      "[44]\ttraining's binary_logloss: 0.0688872\tvalid_1's binary_logloss: 0.101517\n",
      "[46]\ttraining's binary_logloss: 0.0678082\tvalid_1's binary_logloss: 0.101204\n",
      "[48]\ttraining's binary_logloss: 0.0668167\tvalid_1's binary_logloss: 0.100884\n",
      "[50]\ttraining's binary_logloss: 0.0658376\tvalid_1's binary_logloss: 0.100816\n",
      "[52]\ttraining's binary_logloss: 0.0647998\tvalid_1's binary_logloss: 0.100874\n",
      "[54]\ttraining's binary_logloss: 0.0638281\tvalid_1's binary_logloss: 0.100547\n",
      "[56]\ttraining's binary_logloss: 0.0628096\tvalid_1's binary_logloss: 0.100248\n",
      "[58]\ttraining's binary_logloss: 0.0618599\tvalid_1's binary_logloss: 0.0999879\n",
      "[60]\ttraining's binary_logloss: 0.0610711\tvalid_1's binary_logloss: 0.099986\n",
      "[62]\ttraining's binary_logloss: 0.0601691\tvalid_1's binary_logloss: 0.0999733\n",
      "[64]\ttraining's binary_logloss: 0.0593148\tvalid_1's binary_logloss: 0.0999576\n",
      "[66]\ttraining's binary_logloss: 0.0585761\tvalid_1's binary_logloss: 0.0999484\n",
      "[68]\ttraining's binary_logloss: 0.0578294\tvalid_1's binary_logloss: 0.0999276\n",
      "[70]\ttraining's binary_logloss: 0.0570845\tvalid_1's binary_logloss: 0.0997753\n",
      "[72]\ttraining's binary_logloss: 0.0564108\tvalid_1's binary_logloss: 0.0998045\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's binary_logloss: 0.0567607\tvalid_1's binary_logloss: 0.0997389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098223:  70%|######3  | 14/20 [01:20<00:33,  5.55s/it][I 2020-09-29 12:24:04,607] Trial 20 finished with value: 0.09973885746652372 and parameters: {'num_leaves': 38}. Best is trial 19 with value: 0.09822346584920524.\n",
      "num_leaves, val_score: 0.098223:  70%|######3  | 14/20 [01:20<00:33,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.122967\tvalid_1's binary_logloss: 0.131969\n",
      "[4]\ttraining's binary_logloss: 0.11162\tvalid_1's binary_logloss: 0.125111\n",
      "[6]\ttraining's binary_logloss: 0.103421\tvalid_1's binary_logloss: 0.119948\n",
      "[8]\ttraining's binary_logloss: 0.097002\tvalid_1's binary_logloss: 0.116121\n",
      "[10]\ttraining's binary_logloss: 0.0916922\tvalid_1's binary_logloss: 0.113086\n",
      "[12]\ttraining's binary_logloss: 0.0870745\tvalid_1's binary_logloss: 0.110612\n",
      "[14]\ttraining's binary_logloss: 0.0828833\tvalid_1's binary_logloss: 0.108711\n",
      "[16]\ttraining's binary_logloss: 0.0792178\tvalid_1's binary_logloss: 0.10733\n",
      "[18]\ttraining's binary_logloss: 0.0758186\tvalid_1's binary_logloss: 0.1063\n",
      "[20]\ttraining's binary_logloss: 0.0727149\tvalid_1's binary_logloss: 0.10517\n",
      "[22]\ttraining's binary_logloss: 0.070078\tvalid_1's binary_logloss: 0.104174\n",
      "[24]\ttraining's binary_logloss: 0.0674598\tvalid_1's binary_logloss: 0.103341\n",
      "[26]\ttraining's binary_logloss: 0.0650648\tvalid_1's binary_logloss: 0.102996\n",
      "[28]\ttraining's binary_logloss: 0.0626827\tvalid_1's binary_logloss: 0.102225\n",
      "[30]\ttraining's binary_logloss: 0.0606464\tvalid_1's binary_logloss: 0.101549\n",
      "[32]\ttraining's binary_logloss: 0.0586156\tvalid_1's binary_logloss: 0.10116\n",
      "[34]\ttraining's binary_logloss: 0.0566287\tvalid_1's binary_logloss: 0.10073\n",
      "[36]\ttraining's binary_logloss: 0.054792\tvalid_1's binary_logloss: 0.100435\n",
      "[38]\ttraining's binary_logloss: 0.0530978\tvalid_1's binary_logloss: 0.100281\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's binary_logloss: 0.0540095\tvalid_1's binary_logloss: 0.100228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098223:  75%|######7  | 15/20 [01:24<00:25,  5.14s/it][I 2020-09-29 12:24:08,775] Trial 21 finished with value: 0.100228081112029 and parameters: {'num_leaves': 77}. Best is trial 19 with value: 0.09822346584920524.\n",
      "num_leaves, val_score: 0.098223:  75%|######7  | 15/20 [01:24<00:25,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.120376\tvalid_1's binary_logloss: 0.131353\n",
      "[4]\ttraining's binary_logloss: 0.108056\tvalid_1's binary_logloss: 0.124214\n",
      "[6]\ttraining's binary_logloss: 0.0988864\tvalid_1's binary_logloss: 0.119347\n",
      "[8]\ttraining's binary_logloss: 0.0916261\tvalid_1's binary_logloss: 0.115033\n",
      "[10]\ttraining's binary_logloss: 0.0855371\tvalid_1's binary_logloss: 0.111856\n",
      "[12]\ttraining's binary_logloss: 0.0803823\tvalid_1's binary_logloss: 0.109367\n",
      "[14]\ttraining's binary_logloss: 0.0755886\tvalid_1's binary_logloss: 0.107679\n",
      "[16]\ttraining's binary_logloss: 0.0714255\tvalid_1's binary_logloss: 0.106344\n",
      "[18]\ttraining's binary_logloss: 0.0679317\tvalid_1's binary_logloss: 0.105473\n",
      "[20]\ttraining's binary_logloss: 0.0646325\tvalid_1's binary_logloss: 0.104748\n",
      "[22]\ttraining's binary_logloss: 0.0615017\tvalid_1's binary_logloss: 0.10407\n",
      "[24]\ttraining's binary_logloss: 0.0585578\tvalid_1's binary_logloss: 0.10358\n",
      "[26]\ttraining's binary_logloss: 0.056129\tvalid_1's binary_logloss: 0.102949\n",
      "[28]\ttraining's binary_logloss: 0.0535413\tvalid_1's binary_logloss: 0.102241\n",
      "[30]\ttraining's binary_logloss: 0.0512355\tvalid_1's binary_logloss: 0.102017\n",
      "[32]\ttraining's binary_logloss: 0.0489098\tvalid_1's binary_logloss: 0.101542\n",
      "[34]\ttraining's binary_logloss: 0.0469495\tvalid_1's binary_logloss: 0.101567\n",
      "[36]\ttraining's binary_logloss: 0.0448863\tvalid_1's binary_logloss: 0.10116\n",
      "[38]\ttraining's binary_logloss: 0.0430653\tvalid_1's binary_logloss: 0.101108\n",
      "[40]\ttraining's binary_logloss: 0.0413824\tvalid_1's binary_logloss: 0.100798\n",
      "[42]\ttraining's binary_logloss: 0.0397285\tvalid_1's binary_logloss: 0.100832\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's binary_logloss: 0.0413824\tvalid_1's binary_logloss: 0.100798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098223:  80%|#######2 | 16/20 [01:30<00:21,  5.47s/it][I 2020-09-29 12:24:15,037] Trial 22 finished with value: 0.10079820041300146 and parameters: {'num_leaves': 112}. Best is trial 19 with value: 0.09822346584920524.\n",
      "num_leaves, val_score: 0.098223:  80%|#######2 | 16/20 [01:30<00:21,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.130111\tvalid_1's binary_logloss: 0.134214\n",
      "[4]\ttraining's binary_logloss: 0.12168\tvalid_1's binary_logloss: 0.127284\n",
      "[6]\ttraining's binary_logloss: 0.115421\tvalid_1's binary_logloss: 0.12209\n",
      "[8]\ttraining's binary_logloss: 0.11094\tvalid_1's binary_logloss: 0.118329\n",
      "[10]\ttraining's binary_logloss: 0.107414\tvalid_1's binary_logloss: 0.115316\n",
      "[12]\ttraining's binary_logloss: 0.104187\tvalid_1's binary_logloss: 0.113081\n",
      "[14]\ttraining's binary_logloss: 0.101478\tvalid_1's binary_logloss: 0.111324\n",
      "[16]\ttraining's binary_logloss: 0.0993708\tvalid_1's binary_logloss: 0.110037\n",
      "[18]\ttraining's binary_logloss: 0.0973155\tvalid_1's binary_logloss: 0.108706\n",
      "[20]\ttraining's binary_logloss: 0.0953461\tvalid_1's binary_logloss: 0.107509\n",
      "[22]\ttraining's binary_logloss: 0.0936565\tvalid_1's binary_logloss: 0.106794\n",
      "[24]\ttraining's binary_logloss: 0.0922461\tvalid_1's binary_logloss: 0.106103\n",
      "[26]\ttraining's binary_logloss: 0.0909289\tvalid_1's binary_logloss: 0.105572\n",
      "[28]\ttraining's binary_logloss: 0.0894381\tvalid_1's binary_logloss: 0.105227\n",
      "[30]\ttraining's binary_logloss: 0.0881152\tvalid_1's binary_logloss: 0.104718\n",
      "[32]\ttraining's binary_logloss: 0.0869045\tvalid_1's binary_logloss: 0.104157\n",
      "[34]\ttraining's binary_logloss: 0.0857481\tvalid_1's binary_logloss: 0.103661\n",
      "[36]\ttraining's binary_logloss: 0.0845304\tvalid_1's binary_logloss: 0.103277\n",
      "[38]\ttraining's binary_logloss: 0.0834192\tvalid_1's binary_logloss: 0.10294\n",
      "[40]\ttraining's binary_logloss: 0.0823092\tvalid_1's binary_logloss: 0.102455\n",
      "[42]\ttraining's binary_logloss: 0.0813066\tvalid_1's binary_logloss: 0.102078\n",
      "[44]\ttraining's binary_logloss: 0.0804442\tvalid_1's binary_logloss: 0.101916\n",
      "[46]\ttraining's binary_logloss: 0.079407\tvalid_1's binary_logloss: 0.101782\n",
      "[48]\ttraining's binary_logloss: 0.07852\tvalid_1's binary_logloss: 0.101517\n",
      "[50]\ttraining's binary_logloss: 0.077783\tvalid_1's binary_logloss: 0.101404\n",
      "[52]\ttraining's binary_logloss: 0.0766232\tvalid_1's binary_logloss: 0.101322\n",
      "[54]\ttraining's binary_logloss: 0.0756336\tvalid_1's binary_logloss: 0.101085\n",
      "[56]\ttraining's binary_logloss: 0.0749334\tvalid_1's binary_logloss: 0.100929\n",
      "[58]\ttraining's binary_logloss: 0.0741828\tvalid_1's binary_logloss: 0.100631\n",
      "[60]\ttraining's binary_logloss: 0.0734549\tvalid_1's binary_logloss: 0.100549\n",
      "[62]\ttraining's binary_logloss: 0.0727723\tvalid_1's binary_logloss: 0.100346\n",
      "[64]\ttraining's binary_logloss: 0.0720356\tvalid_1's binary_logloss: 0.100138\n",
      "[66]\ttraining's binary_logloss: 0.0712617\tvalid_1's binary_logloss: 0.100075\n",
      "[68]\ttraining's binary_logloss: 0.0704777\tvalid_1's binary_logloss: 0.100054\n",
      "[70]\ttraining's binary_logloss: 0.0697959\tvalid_1's binary_logloss: 0.100122\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's binary_logloss: 0.0701124\tvalid_1's binary_logloss: 0.100036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098223:  85%|#######6 | 17/20 [01:35<00:15,  5.26s/it][I 2020-09-29 12:24:19,788] Trial 23 finished with value: 0.10003558878190223 and parameters: {'num_leaves': 24}. Best is trial 19 with value: 0.09822346584920524.\n",
      "num_leaves, val_score: 0.098223:  85%|#######6 | 17/20 [01:35<00:15,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.123658\tvalid_1's binary_logloss: 0.13191\n",
      "[4]\ttraining's binary_logloss: 0.112931\tvalid_1's binary_logloss: 0.124931\n",
      "[6]\ttraining's binary_logloss: 0.10493\tvalid_1's binary_logloss: 0.119819\n",
      "[8]\ttraining's binary_logloss: 0.0990673\tvalid_1's binary_logloss: 0.116128\n",
      "[10]\ttraining's binary_logloss: 0.0940402\tvalid_1's binary_logloss: 0.113113\n",
      "[12]\ttraining's binary_logloss: 0.0894999\tvalid_1's binary_logloss: 0.110924\n",
      "[14]\ttraining's binary_logloss: 0.0856825\tvalid_1's binary_logloss: 0.109117\n",
      "[16]\ttraining's binary_logloss: 0.0819858\tvalid_1's binary_logloss: 0.107309\n",
      "[18]\ttraining's binary_logloss: 0.0790031\tvalid_1's binary_logloss: 0.106001\n",
      "[20]\ttraining's binary_logloss: 0.0762284\tvalid_1's binary_logloss: 0.105165\n",
      "[22]\ttraining's binary_logloss: 0.0734577\tvalid_1's binary_logloss: 0.104432\n",
      "[24]\ttraining's binary_logloss: 0.0711059\tvalid_1's binary_logloss: 0.103694\n",
      "[26]\ttraining's binary_logloss: 0.068779\tvalid_1's binary_logloss: 0.103131\n",
      "[28]\ttraining's binary_logloss: 0.0666639\tvalid_1's binary_logloss: 0.102459\n",
      "[30]\ttraining's binary_logloss: 0.0645692\tvalid_1's binary_logloss: 0.102058\n",
      "[32]\ttraining's binary_logloss: 0.0626505\tvalid_1's binary_logloss: 0.101756\n",
      "[34]\ttraining's binary_logloss: 0.060848\tvalid_1's binary_logloss: 0.101344\n",
      "[36]\ttraining's binary_logloss: 0.0590173\tvalid_1's binary_logloss: 0.101095\n",
      "[38]\ttraining's binary_logloss: 0.0573507\tvalid_1's binary_logloss: 0.100661\n",
      "[40]\ttraining's binary_logloss: 0.0558205\tvalid_1's binary_logloss: 0.100332\n",
      "[42]\ttraining's binary_logloss: 0.0542628\tvalid_1's binary_logloss: 0.100063\n",
      "[44]\ttraining's binary_logloss: 0.0528847\tvalid_1's binary_logloss: 0.0998178\n",
      "[46]\ttraining's binary_logloss: 0.0516234\tvalid_1's binary_logloss: 0.0996943\n",
      "[48]\ttraining's binary_logloss: 0.0503664\tvalid_1's binary_logloss: 0.0996568\n",
      "[50]\ttraining's binary_logloss: 0.0492921\tvalid_1's binary_logloss: 0.099557\n",
      "[52]\ttraining's binary_logloss: 0.04799\tvalid_1's binary_logloss: 0.0995287\n",
      "[54]\ttraining's binary_logloss: 0.0469428\tvalid_1's binary_logloss: 0.0994644\n",
      "[56]\ttraining's binary_logloss: 0.0458545\tvalid_1's binary_logloss: 0.0991623\n",
      "[58]\ttraining's binary_logloss: 0.0450031\tvalid_1's binary_logloss: 0.099104\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.045395\tvalid_1's binary_logloss: 0.0990797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098223:  90%|########1| 18/20 [01:41<00:10,  5.30s/it][I 2020-09-29 12:24:25,185] Trial 24 finished with value: 0.09907968305146529 and parameters: {'num_leaves': 67}. Best is trial 19 with value: 0.09822346584920524.\n",
      "num_leaves, val_score: 0.098223:  90%|########1| 18/20 [01:41<00:10,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.119646\tvalid_1's binary_logloss: 0.131182\n",
      "[4]\ttraining's binary_logloss: 0.106647\tvalid_1's binary_logloss: 0.124022\n",
      "[6]\ttraining's binary_logloss: 0.0969482\tvalid_1's binary_logloss: 0.119346\n",
      "[8]\ttraining's binary_logloss: 0.0892219\tvalid_1's binary_logloss: 0.115361\n",
      "[10]\ttraining's binary_logloss: 0.0829483\tvalid_1's binary_logloss: 0.112476\n",
      "[12]\ttraining's binary_logloss: 0.0776842\tvalid_1's binary_logloss: 0.110056\n",
      "[14]\ttraining's binary_logloss: 0.0729823\tvalid_1's binary_logloss: 0.108308\n",
      "[16]\ttraining's binary_logloss: 0.0687468\tvalid_1's binary_logloss: 0.106852\n",
      "[18]\ttraining's binary_logloss: 0.0646593\tvalid_1's binary_logloss: 0.105658\n",
      "[20]\ttraining's binary_logloss: 0.0611129\tvalid_1's binary_logloss: 0.104741\n",
      "[22]\ttraining's binary_logloss: 0.0578578\tvalid_1's binary_logloss: 0.103938\n",
      "[24]\ttraining's binary_logloss: 0.0548047\tvalid_1's binary_logloss: 0.103279\n",
      "[26]\ttraining's binary_logloss: 0.0520969\tvalid_1's binary_logloss: 0.10297\n",
      "[28]\ttraining's binary_logloss: 0.049592\tvalid_1's binary_logloss: 0.102289\n",
      "[30]\ttraining's binary_logloss: 0.0471955\tvalid_1's binary_logloss: 0.101653\n",
      "[32]\ttraining's binary_logloss: 0.0449617\tvalid_1's binary_logloss: 0.101615\n",
      "[34]\ttraining's binary_logloss: 0.0430412\tvalid_1's binary_logloss: 0.101469\n",
      "[36]\ttraining's binary_logloss: 0.0410868\tvalid_1's binary_logloss: 0.10128\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.0420579\tvalid_1's binary_logloss: 0.101172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098223:  95%|########5| 19/20 [01:45<00:05,  5.00s/it][I 2020-09-29 12:24:29,500] Trial 25 finished with value: 0.10117163539264455 and parameters: {'num_leaves': 128}. Best is trial 19 with value: 0.09822346584920524.\n",
      "num_leaves, val_score: 0.098223:  95%|########5| 19/20 [01:45<00:05,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.121972\tvalid_1's binary_logloss: 0.131664\n",
      "[4]\ttraining's binary_logloss: 0.11018\tvalid_1's binary_logloss: 0.124652\n",
      "[6]\ttraining's binary_logloss: 0.101442\tvalid_1's binary_logloss: 0.119732\n",
      "[8]\ttraining's binary_logloss: 0.0948363\tvalid_1's binary_logloss: 0.115483\n",
      "[10]\ttraining's binary_logloss: 0.0893202\tvalid_1's binary_logloss: 0.112373\n",
      "[12]\ttraining's binary_logloss: 0.0846115\tvalid_1's binary_logloss: 0.109639\n",
      "[14]\ttraining's binary_logloss: 0.0802877\tvalid_1's binary_logloss: 0.108031\n",
      "[16]\ttraining's binary_logloss: 0.0763768\tvalid_1's binary_logloss: 0.106379\n",
      "[18]\ttraining's binary_logloss: 0.0726845\tvalid_1's binary_logloss: 0.105207\n",
      "[20]\ttraining's binary_logloss: 0.0694507\tvalid_1's binary_logloss: 0.104109\n",
      "[22]\ttraining's binary_logloss: 0.0666195\tvalid_1's binary_logloss: 0.103446\n",
      "[24]\ttraining's binary_logloss: 0.0638743\tvalid_1's binary_logloss: 0.102735\n",
      "[26]\ttraining's binary_logloss: 0.0613717\tvalid_1's binary_logloss: 0.10213\n",
      "[28]\ttraining's binary_logloss: 0.0590627\tvalid_1's binary_logloss: 0.101758\n",
      "[30]\ttraining's binary_logloss: 0.0568774\tvalid_1's binary_logloss: 0.101051\n",
      "[32]\ttraining's binary_logloss: 0.0548466\tvalid_1's binary_logloss: 0.100454\n",
      "[34]\ttraining's binary_logloss: 0.0528005\tvalid_1's binary_logloss: 0.0999484\n",
      "[36]\ttraining's binary_logloss: 0.0509014\tvalid_1's binary_logloss: 0.09954\n",
      "[38]\ttraining's binary_logloss: 0.0492524\tvalid_1's binary_logloss: 0.0994466\n",
      "[40]\ttraining's binary_logloss: 0.0476537\tvalid_1's binary_logloss: 0.0993254\n",
      "[42]\ttraining's binary_logloss: 0.046063\tvalid_1's binary_logloss: 0.0992498\n",
      "[44]\ttraining's binary_logloss: 0.0446683\tvalid_1's binary_logloss: 0.0990491\n",
      "[46]\ttraining's binary_logloss: 0.0431604\tvalid_1's binary_logloss: 0.0992663\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's binary_logloss: 0.0446683\tvalid_1's binary_logloss: 0.0990491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.098223: 100%|#########| 20/20 [01:50<00:00,  4.95s/it][I 2020-09-29 12:24:34,327] Trial 26 finished with value: 0.09904907337079219 and parameters: {'num_leaves': 89}. Best is trial 19 with value: 0.09822346584920524.\n",
      "num_leaves, val_score: 0.098223: 100%|#########| 20/20 [01:50<00:00,  5.51s/it]\n",
      "bagging, val_score: 0.098223:   0%|                     | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.129724\tvalid_1's binary_logloss: 0.133172\n",
      "[4]\ttraining's binary_logloss: 0.119176\tvalid_1's binary_logloss: 0.125531\n",
      "[6]\ttraining's binary_logloss: 0.111474\tvalid_1's binary_logloss: 0.120055\n",
      "[8]\ttraining's binary_logloss: 0.106043\tvalid_1's binary_logloss: 0.116437\n",
      "[10]\ttraining's binary_logloss: 0.10143\tvalid_1's binary_logloss: 0.114345\n",
      "[12]\ttraining's binary_logloss: 0.0975686\tvalid_1's binary_logloss: 0.112138\n",
      "[14]\ttraining's binary_logloss: 0.0937635\tvalid_1's binary_logloss: 0.11043\n",
      "[16]\ttraining's binary_logloss: 0.0906651\tvalid_1's binary_logloss: 0.109354\n",
      "[18]\ttraining's binary_logloss: 0.0880457\tvalid_1's binary_logloss: 0.108243\n",
      "[20]\ttraining's binary_logloss: 0.0856137\tvalid_1's binary_logloss: 0.107315\n",
      "[22]\ttraining's binary_logloss: 0.0832459\tvalid_1's binary_logloss: 0.106373\n",
      "[24]\ttraining's binary_logloss: 0.0809831\tvalid_1's binary_logloss: 0.10589\n",
      "[26]\ttraining's binary_logloss: 0.0789157\tvalid_1's binary_logloss: 0.105313\n",
      "[28]\ttraining's binary_logloss: 0.0768386\tvalid_1's binary_logloss: 0.104847\n",
      "[30]\ttraining's binary_logloss: 0.0748016\tvalid_1's binary_logloss: 0.103643\n",
      "[32]\ttraining's binary_logloss: 0.0732261\tvalid_1's binary_logloss: 0.102986\n",
      "[34]\ttraining's binary_logloss: 0.0714123\tvalid_1's binary_logloss: 0.102472\n",
      "[36]\ttraining's binary_logloss: 0.069686\tvalid_1's binary_logloss: 0.102352\n",
      "[38]\ttraining's binary_logloss: 0.0680121\tvalid_1's binary_logloss: 0.102397\n",
      "[40]\ttraining's binary_logloss: 0.066534\tvalid_1's binary_logloss: 0.102031\n",
      "[42]\ttraining's binary_logloss: 0.0649283\tvalid_1's binary_logloss: 0.101873\n",
      "[44]\ttraining's binary_logloss: 0.0633961\tvalid_1's binary_logloss: 0.10166\n",
      "[46]\ttraining's binary_logloss: 0.0620373\tvalid_1's binary_logloss: 0.101268\n",
      "[48]\ttraining's binary_logloss: 0.060734\tvalid_1's binary_logloss: 0.101248\n",
      "[50]\ttraining's binary_logloss: 0.05936\tvalid_1's binary_logloss: 0.101238\n",
      "[52]\ttraining's binary_logloss: 0.0579217\tvalid_1's binary_logloss: 0.101194\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.0585638\tvalid_1's binary_logloss: 0.10113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.098223:  10%|#3           | 1/10 [00:03<00:30,  3.37s/it][I 2020-09-29 12:24:37,726] Trial 27 finished with value: 0.10113043962194646 and parameters: {'bagging_fraction': 0.4288797767975273, 'bagging_freq': 2}. Best is trial 27 with value: 0.10113043962194646.\n",
      "bagging, val_score: 0.098223:  10%|#3           | 1/10 [00:03<00:30,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125038\tvalid_1's binary_logloss: 0.132399\n",
      "[4]\ttraining's binary_logloss: 0.114827\tvalid_1's binary_logloss: 0.125834\n",
      "[6]\ttraining's binary_logloss: 0.107143\tvalid_1's binary_logloss: 0.120538\n",
      "[8]\ttraining's binary_logloss: 0.101516\tvalid_1's binary_logloss: 0.116662\n",
      "[10]\ttraining's binary_logloss: 0.0968672\tvalid_1's binary_logloss: 0.113898\n",
      "[12]\ttraining's binary_logloss: 0.0926258\tvalid_1's binary_logloss: 0.111491\n",
      "[14]\ttraining's binary_logloss: 0.0892932\tvalid_1's binary_logloss: 0.109599\n",
      "[16]\ttraining's binary_logloss: 0.085962\tvalid_1's binary_logloss: 0.108233\n",
      "[18]\ttraining's binary_logloss: 0.0831095\tvalid_1's binary_logloss: 0.106772\n",
      "[20]\ttraining's binary_logloss: 0.0804129\tvalid_1's binary_logloss: 0.105635\n",
      "[22]\ttraining's binary_logloss: 0.0779053\tvalid_1's binary_logloss: 0.104434\n",
      "[24]\ttraining's binary_logloss: 0.075811\tvalid_1's binary_logloss: 0.103566\n",
      "[26]\ttraining's binary_logloss: 0.0738259\tvalid_1's binary_logloss: 0.102977\n",
      "[28]\ttraining's binary_logloss: 0.0717586\tvalid_1's binary_logloss: 0.102471\n",
      "[30]\ttraining's binary_logloss: 0.0698973\tvalid_1's binary_logloss: 0.101987\n",
      "[32]\ttraining's binary_logloss: 0.068055\tvalid_1's binary_logloss: 0.101718\n",
      "[34]\ttraining's binary_logloss: 0.0662868\tvalid_1's binary_logloss: 0.101279\n",
      "[36]\ttraining's binary_logloss: 0.06466\tvalid_1's binary_logloss: 0.100717\n",
      "[38]\ttraining's binary_logloss: 0.063052\tvalid_1's binary_logloss: 0.100763\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's binary_logloss: 0.06466\tvalid_1's binary_logloss: 0.100717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.098223:  20%|##6          | 2/10 [00:07<00:29,  3.70s/it][I 2020-09-29 12:24:42,209] Trial 28 finished with value: 0.10071660333011255 and parameters: {'bagging_fraction': 0.9964346928975613, 'bagging_freq': 6}. Best is trial 28 with value: 0.10071660333011255.\n",
      "bagging, val_score: 0.098223:  20%|##6          | 2/10 [00:07<00:29,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125434\tvalid_1's binary_logloss: 0.131058\n",
      "[4]\ttraining's binary_logloss: 0.1157\tvalid_1's binary_logloss: 0.124221\n",
      "[6]\ttraining's binary_logloss: 0.108574\tvalid_1's binary_logloss: 0.11871\n",
      "[8]\ttraining's binary_logloss: 0.102782\tvalid_1's binary_logloss: 0.114941\n",
      "[10]\ttraining's binary_logloss: 0.0977652\tvalid_1's binary_logloss: 0.112178\n",
      "[12]\ttraining's binary_logloss: 0.0937093\tvalid_1's binary_logloss: 0.109756\n",
      "[14]\ttraining's binary_logloss: 0.0905237\tvalid_1's binary_logloss: 0.107881\n",
      "[16]\ttraining's binary_logloss: 0.0871627\tvalid_1's binary_logloss: 0.106176\n",
      "[18]\ttraining's binary_logloss: 0.0844741\tvalid_1's binary_logloss: 0.10539\n",
      "[20]\ttraining's binary_logloss: 0.0819351\tvalid_1's binary_logloss: 0.104519\n",
      "[22]\ttraining's binary_logloss: 0.0795126\tvalid_1's binary_logloss: 0.103923\n",
      "[24]\ttraining's binary_logloss: 0.0769742\tvalid_1's binary_logloss: 0.103416\n",
      "[26]\ttraining's binary_logloss: 0.0747267\tvalid_1's binary_logloss: 0.102895\n",
      "[28]\ttraining's binary_logloss: 0.0726942\tvalid_1's binary_logloss: 0.102613\n",
      "[30]\ttraining's binary_logloss: 0.0705697\tvalid_1's binary_logloss: 0.101863\n",
      "[32]\ttraining's binary_logloss: 0.0686662\tvalid_1's binary_logloss: 0.101477\n",
      "[34]\ttraining's binary_logloss: 0.0669504\tvalid_1's binary_logloss: 0.101025\n",
      "[36]\ttraining's binary_logloss: 0.0653961\tvalid_1's binary_logloss: 0.100637\n",
      "[38]\ttraining's binary_logloss: 0.0638994\tvalid_1's binary_logloss: 0.10034\n",
      "[40]\ttraining's binary_logloss: 0.0624432\tvalid_1's binary_logloss: 0.100134\n",
      "[42]\ttraining's binary_logloss: 0.0610762\tvalid_1's binary_logloss: 0.100039\n",
      "[44]\ttraining's binary_logloss: 0.0596729\tvalid_1's binary_logloss: 0.0999892\n",
      "[46]\ttraining's binary_logloss: 0.0585586\tvalid_1's binary_logloss: 0.0999281\n",
      "[48]\ttraining's binary_logloss: 0.0575546\tvalid_1's binary_logloss: 0.0999818\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.058035\tvalid_1's binary_logloss: 0.0999218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.098223:  30%|###9         | 3/10 [00:12<00:28,  4.06s/it][I 2020-09-29 12:24:47,104] Trial 29 finished with value: 0.09992184336570929 and parameters: {'bagging_fraction': 0.8008229250438512, 'bagging_freq': 7}. Best is trial 29 with value: 0.09992184336570929.\n",
      "bagging, val_score: 0.098223:  30%|###9         | 3/10 [00:12<00:28,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.129265\tvalid_1's binary_logloss: 0.133008\n",
      "[4]\ttraining's binary_logloss: 0.118263\tvalid_1's binary_logloss: 0.125513\n",
      "[6]\ttraining's binary_logloss: 0.110964\tvalid_1's binary_logloss: 0.120491\n",
      "[8]\ttraining's binary_logloss: 0.105102\tvalid_1's binary_logloss: 0.116694\n",
      "[10]\ttraining's binary_logloss: 0.100386\tvalid_1's binary_logloss: 0.113674\n",
      "[12]\ttraining's binary_logloss: 0.0962768\tvalid_1's binary_logloss: 0.111368\n",
      "[14]\ttraining's binary_logloss: 0.0926919\tvalid_1's binary_logloss: 0.10979\n",
      "[16]\ttraining's binary_logloss: 0.0895418\tvalid_1's binary_logloss: 0.108498\n",
      "[18]\ttraining's binary_logloss: 0.0868969\tvalid_1's binary_logloss: 0.107287\n",
      "[20]\ttraining's binary_logloss: 0.0843575\tvalid_1's binary_logloss: 0.106266\n",
      "[22]\ttraining's binary_logloss: 0.0817429\tvalid_1's binary_logloss: 0.10555\n",
      "[24]\ttraining's binary_logloss: 0.079394\tvalid_1's binary_logloss: 0.104617\n",
      "[26]\ttraining's binary_logloss: 0.0773568\tvalid_1's binary_logloss: 0.104068\n",
      "[28]\ttraining's binary_logloss: 0.0751766\tvalid_1's binary_logloss: 0.103737\n",
      "[30]\ttraining's binary_logloss: 0.0733003\tvalid_1's binary_logloss: 0.103182\n",
      "[32]\ttraining's binary_logloss: 0.0713704\tvalid_1's binary_logloss: 0.102754\n",
      "[34]\ttraining's binary_logloss: 0.0695873\tvalid_1's binary_logloss: 0.102317\n",
      "[36]\ttraining's binary_logloss: 0.0678528\tvalid_1's binary_logloss: 0.102154\n",
      "[38]\ttraining's binary_logloss: 0.0660953\tvalid_1's binary_logloss: 0.102085\n",
      "[40]\ttraining's binary_logloss: 0.0646649\tvalid_1's binary_logloss: 0.102095\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's binary_logloss: 0.0654382\tvalid_1's binary_logloss: 0.101913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.098223:  40%|#####2       | 4/10 [00:16<00:23,  3.86s/it][I 2020-09-29 12:24:50,498] Trial 30 finished with value: 0.10191261184511637 and parameters: {'bagging_fraction': 0.4698632359507269, 'bagging_freq': 1}. Best is trial 29 with value: 0.09992184336570929.\n",
      "bagging, val_score: 0.098223:  40%|#####2       | 4/10 [00:16<00:23,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.127473\tvalid_1's binary_logloss: 0.131959\n",
      "[4]\ttraining's binary_logloss: 0.117446\tvalid_1's binary_logloss: 0.12446\n",
      "[6]\ttraining's binary_logloss: 0.110022\tvalid_1's binary_logloss: 0.120114\n",
      "[8]\ttraining's binary_logloss: 0.104286\tvalid_1's binary_logloss: 0.116943\n",
      "[10]\ttraining's binary_logloss: 0.0991939\tvalid_1's binary_logloss: 0.114322\n",
      "[12]\ttraining's binary_logloss: 0.0952024\tvalid_1's binary_logloss: 0.112583\n",
      "[14]\ttraining's binary_logloss: 0.0912659\tvalid_1's binary_logloss: 0.111152\n",
      "[16]\ttraining's binary_logloss: 0.0883259\tvalid_1's binary_logloss: 0.10991\n",
      "[18]\ttraining's binary_logloss: 0.0855292\tvalid_1's binary_logloss: 0.108506\n",
      "[20]\ttraining's binary_logloss: 0.0831806\tvalid_1's binary_logloss: 0.107679\n",
      "[22]\ttraining's binary_logloss: 0.0806729\tvalid_1's binary_logloss: 0.107071\n",
      "[24]\ttraining's binary_logloss: 0.078464\tvalid_1's binary_logloss: 0.106444\n",
      "[26]\ttraining's binary_logloss: 0.0765804\tvalid_1's binary_logloss: 0.105761\n",
      "[28]\ttraining's binary_logloss: 0.0745339\tvalid_1's binary_logloss: 0.104998\n",
      "[30]\ttraining's binary_logloss: 0.0723295\tvalid_1's binary_logloss: 0.104359\n",
      "[32]\ttraining's binary_logloss: 0.0701344\tvalid_1's binary_logloss: 0.103764\n",
      "[34]\ttraining's binary_logloss: 0.0684782\tvalid_1's binary_logloss: 0.103657\n",
      "[36]\ttraining's binary_logloss: 0.066924\tvalid_1's binary_logloss: 0.103525\n",
      "[38]\ttraining's binary_logloss: 0.0651949\tvalid_1's binary_logloss: 0.103363\n",
      "[40]\ttraining's binary_logloss: 0.0636513\tvalid_1's binary_logloss: 0.103441\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's binary_logloss: 0.0651949\tvalid_1's binary_logloss: 0.103363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.098223:  50%|######5      | 5/10 [00:19<00:18,  3.64s/it][I 2020-09-29 12:24:53,629] Trial 31 finished with value: 0.10336336978231415 and parameters: {'bagging_fraction': 0.6610452491137009, 'bagging_freq': 4}. Best is trial 29 with value: 0.09992184336570929.\n",
      "bagging, val_score: 0.098223:  50%|######5      | 5/10 [00:19<00:18,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125026\tvalid_1's binary_logloss: 0.132379\n",
      "[4]\ttraining's binary_logloss: 0.114794\tvalid_1's binary_logloss: 0.125829\n",
      "[6]\ttraining's binary_logloss: 0.107326\tvalid_1's binary_logloss: 0.120667\n",
      "[8]\ttraining's binary_logloss: 0.101675\tvalid_1's binary_logloss: 0.116814\n",
      "[10]\ttraining's binary_logloss: 0.0968544\tvalid_1's binary_logloss: 0.114115\n",
      "[12]\ttraining's binary_logloss: 0.0927936\tvalid_1's binary_logloss: 0.111713\n",
      "[14]\ttraining's binary_logloss: 0.08922\tvalid_1's binary_logloss: 0.109746\n",
      "[16]\ttraining's binary_logloss: 0.0860683\tvalid_1's binary_logloss: 0.108427\n",
      "[18]\ttraining's binary_logloss: 0.0834009\tvalid_1's binary_logloss: 0.106912\n",
      "[20]\ttraining's binary_logloss: 0.0807839\tvalid_1's binary_logloss: 0.105606\n",
      "[22]\ttraining's binary_logloss: 0.0781253\tvalid_1's binary_logloss: 0.104755\n",
      "[24]\ttraining's binary_logloss: 0.0757224\tvalid_1's binary_logloss: 0.103955\n",
      "[26]\ttraining's binary_logloss: 0.0735732\tvalid_1's binary_logloss: 0.103116\n",
      "[28]\ttraining's binary_logloss: 0.0715459\tvalid_1's binary_logloss: 0.102621\n",
      "[30]\ttraining's binary_logloss: 0.0694719\tvalid_1's binary_logloss: 0.102255\n",
      "[32]\ttraining's binary_logloss: 0.0676449\tvalid_1's binary_logloss: 0.101713\n",
      "[34]\ttraining's binary_logloss: 0.065838\tvalid_1's binary_logloss: 0.101149\n",
      "[36]\ttraining's binary_logloss: 0.0640813\tvalid_1's binary_logloss: 0.100927\n",
      "[38]\ttraining's binary_logloss: 0.0625016\tvalid_1's binary_logloss: 0.100484\n",
      "[40]\ttraining's binary_logloss: 0.0609863\tvalid_1's binary_logloss: 0.100159\n",
      "[42]\ttraining's binary_logloss: 0.0596265\tvalid_1's binary_logloss: 0.099689\n",
      "[44]\ttraining's binary_logloss: 0.0582554\tvalid_1's binary_logloss: 0.0994719\n",
      "[46]\ttraining's binary_logloss: 0.0570266\tvalid_1's binary_logloss: 0.099287\n",
      "[48]\ttraining's binary_logloss: 0.056033\tvalid_1's binary_logloss: 0.0991724\n",
      "[50]\ttraining's binary_logloss: 0.0549286\tvalid_1's binary_logloss: 0.0988943\n",
      "[52]\ttraining's binary_logloss: 0.0537429\tvalid_1's binary_logloss: 0.098715\n",
      "[54]\ttraining's binary_logloss: 0.0527292\tvalid_1's binary_logloss: 0.0987892\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's binary_logloss: 0.0537429\tvalid_1's binary_logloss: 0.098715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.098223:  60%|#######8     | 6/10 [00:24<00:16,  4.05s/it][I 2020-09-29 12:24:58,620] Trial 32 finished with value: 0.09871499488154345 and parameters: {'bagging_fraction': 0.9962751961430532, 'bagging_freq': 4}. Best is trial 32 with value: 0.09871499488154345.\n",
      "bagging, val_score: 0.098223:  60%|#######8     | 6/10 [00:24<00:16,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125263\tvalid_1's binary_logloss: 0.132379\n",
      "[4]\ttraining's binary_logloss: 0.115062\tvalid_1's binary_logloss: 0.125603\n",
      "[6]\ttraining's binary_logloss: 0.107566\tvalid_1's binary_logloss: 0.120182\n",
      "[8]\ttraining's binary_logloss: 0.101797\tvalid_1's binary_logloss: 0.116413\n",
      "[10]\ttraining's binary_logloss: 0.0969853\tvalid_1's binary_logloss: 0.11342\n",
      "[12]\ttraining's binary_logloss: 0.0930729\tvalid_1's binary_logloss: 0.111006\n",
      "[14]\ttraining's binary_logloss: 0.0893176\tvalid_1's binary_logloss: 0.108927\n",
      "[16]\ttraining's binary_logloss: 0.086229\tvalid_1's binary_logloss: 0.107606\n",
      "[18]\ttraining's binary_logloss: 0.0829494\tvalid_1's binary_logloss: 0.106409\n",
      "[20]\ttraining's binary_logloss: 0.08021\tvalid_1's binary_logloss: 0.105509\n",
      "[22]\ttraining's binary_logloss: 0.0778843\tvalid_1's binary_logloss: 0.104272\n",
      "[24]\ttraining's binary_logloss: 0.075656\tvalid_1's binary_logloss: 0.103743\n",
      "[26]\ttraining's binary_logloss: 0.0737359\tvalid_1's binary_logloss: 0.103144\n",
      "[28]\ttraining's binary_logloss: 0.0718372\tvalid_1's binary_logloss: 0.102635\n",
      "[30]\ttraining's binary_logloss: 0.0699781\tvalid_1's binary_logloss: 0.102332\n",
      "[32]\ttraining's binary_logloss: 0.0681482\tvalid_1's binary_logloss: 0.101751\n",
      "[34]\ttraining's binary_logloss: 0.0662548\tvalid_1's binary_logloss: 0.10137\n",
      "[36]\ttraining's binary_logloss: 0.0644283\tvalid_1's binary_logloss: 0.100753\n",
      "[38]\ttraining's binary_logloss: 0.0628206\tvalid_1's binary_logloss: 0.100461\n",
      "[40]\ttraining's binary_logloss: 0.0613275\tvalid_1's binary_logloss: 0.10023\n",
      "[42]\ttraining's binary_logloss: 0.0598756\tvalid_1's binary_logloss: 0.100072\n",
      "[44]\ttraining's binary_logloss: 0.058523\tvalid_1's binary_logloss: 0.0998704\n",
      "[46]\ttraining's binary_logloss: 0.0572753\tvalid_1's binary_logloss: 0.0997931\n",
      "[48]\ttraining's binary_logloss: 0.0560831\tvalid_1's binary_logloss: 0.0997476\n",
      "[50]\ttraining's binary_logloss: 0.0549549\tvalid_1's binary_logloss: 0.0994321\n",
      "[52]\ttraining's binary_logloss: 0.0537765\tvalid_1's binary_logloss: 0.0992253\n",
      "[54]\ttraining's binary_logloss: 0.0527909\tvalid_1's binary_logloss: 0.0991283\n",
      "[56]\ttraining's binary_logloss: 0.0518435\tvalid_1's binary_logloss: 0.0989123\n",
      "[58]\ttraining's binary_logloss: 0.0509511\tvalid_1's binary_logloss: 0.0987828\n",
      "[60]\ttraining's binary_logloss: 0.0500811\tvalid_1's binary_logloss: 0.0985944\n",
      "[62]\ttraining's binary_logloss: 0.0491711\tvalid_1's binary_logloss: 0.0985335\n",
      "[64]\ttraining's binary_logloss: 0.048393\tvalid_1's binary_logloss: 0.0987748\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's binary_logloss: 0.0491711\tvalid_1's binary_logloss: 0.0985335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.098223:  70%|#########1   | 7/10 [00:30<00:14,  4.78s/it][I 2020-09-29 12:25:05,116] Trial 33 finished with value: 0.0985335144251636 and parameters: {'bagging_fraction': 0.99808366855015, 'bagging_freq': 4}. Best is trial 33 with value: 0.0985335144251636.\n",
      "bagging, val_score: 0.098223:  70%|#########1   | 7/10 [00:30<00:14,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125066\tvalid_1's binary_logloss: 0.13248\n",
      "[4]\ttraining's binary_logloss: 0.11474\tvalid_1's binary_logloss: 0.125314\n",
      "[6]\ttraining's binary_logloss: 0.107286\tvalid_1's binary_logloss: 0.120175\n",
      "[8]\ttraining's binary_logloss: 0.101718\tvalid_1's binary_logloss: 0.116408\n",
      "[10]\ttraining's binary_logloss: 0.0968453\tvalid_1's binary_logloss: 0.113789\n",
      "[12]\ttraining's binary_logloss: 0.0928216\tvalid_1's binary_logloss: 0.111348\n",
      "[14]\ttraining's binary_logloss: 0.0893522\tvalid_1's binary_logloss: 0.10954\n",
      "[16]\ttraining's binary_logloss: 0.0856971\tvalid_1's binary_logloss: 0.107734\n",
      "[18]\ttraining's binary_logloss: 0.0829755\tvalid_1's binary_logloss: 0.106626\n",
      "[20]\ttraining's binary_logloss: 0.0804147\tvalid_1's binary_logloss: 0.105638\n",
      "[22]\ttraining's binary_logloss: 0.0778354\tvalid_1's binary_logloss: 0.104889\n",
      "[24]\ttraining's binary_logloss: 0.0756069\tvalid_1's binary_logloss: 0.104005\n",
      "[26]\ttraining's binary_logloss: 0.0734848\tvalid_1's binary_logloss: 0.103207\n",
      "[28]\ttraining's binary_logloss: 0.0714252\tvalid_1's binary_logloss: 0.10262\n",
      "[30]\ttraining's binary_logloss: 0.069377\tvalid_1's binary_logloss: 0.102024\n",
      "[32]\ttraining's binary_logloss: 0.0675353\tvalid_1's binary_logloss: 0.10168\n",
      "[34]\ttraining's binary_logloss: 0.0658697\tvalid_1's binary_logloss: 0.101679\n",
      "[36]\ttraining's binary_logloss: 0.0642339\tvalid_1's binary_logloss: 0.101338\n",
      "[38]\ttraining's binary_logloss: 0.0626966\tvalid_1's binary_logloss: 0.100743\n",
      "[40]\ttraining's binary_logloss: 0.0611645\tvalid_1's binary_logloss: 0.100369\n",
      "[42]\ttraining's binary_logloss: 0.0598114\tvalid_1's binary_logloss: 0.0999814\n",
      "[44]\ttraining's binary_logloss: 0.0585533\tvalid_1's binary_logloss: 0.0994767\n",
      "[46]\ttraining's binary_logloss: 0.0572241\tvalid_1's binary_logloss: 0.0990845\n",
      "[48]\ttraining's binary_logloss: 0.056051\tvalid_1's binary_logloss: 0.0986822\n",
      "[50]\ttraining's binary_logloss: 0.0548538\tvalid_1's binary_logloss: 0.0986293\n",
      "[52]\ttraining's binary_logloss: 0.0538775\tvalid_1's binary_logloss: 0.0983253\n",
      "[54]\ttraining's binary_logloss: 0.0528224\tvalid_1's binary_logloss: 0.0981997\n",
      "[56]\ttraining's binary_logloss: 0.051829\tvalid_1's binary_logloss: 0.0980381\n",
      "[58]\ttraining's binary_logloss: 0.0509168\tvalid_1's binary_logloss: 0.097876\n",
      "[60]\ttraining's binary_logloss: 0.0499428\tvalid_1's binary_logloss: 0.0980415\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's binary_logloss: 0.0509168\tvalid_1's binary_logloss: 0.097876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.097876:  80%|##########4  | 8/10 [00:36<00:10,  5.14s/it][I 2020-09-29 12:25:11,084] Trial 34 finished with value: 0.09787598913695472 and parameters: {'bagging_fraction': 0.9932402489103072, 'bagging_freq': 4}. Best is trial 34 with value: 0.09787598913695472.\n",
      "bagging, val_score: 0.097876:  80%|##########4  | 8/10 [00:36<00:10,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125634\tvalid_1's binary_logloss: 0.131837\n",
      "[4]\ttraining's binary_logloss: 0.1154\tvalid_1's binary_logloss: 0.124648\n",
      "[6]\ttraining's binary_logloss: 0.108106\tvalid_1's binary_logloss: 0.120166\n",
      "[8]\ttraining's binary_logloss: 0.102367\tvalid_1's binary_logloss: 0.116423\n",
      "[10]\ttraining's binary_logloss: 0.0975182\tvalid_1's binary_logloss: 0.113795\n",
      "[12]\ttraining's binary_logloss: 0.0936531\tvalid_1's binary_logloss: 0.111563\n",
      "[14]\ttraining's binary_logloss: 0.0900165\tvalid_1's binary_logloss: 0.110133\n",
      "[16]\ttraining's binary_logloss: 0.0868772\tvalid_1's binary_logloss: 0.108571\n",
      "[18]\ttraining's binary_logloss: 0.0840492\tvalid_1's binary_logloss: 0.10741\n",
      "[20]\ttraining's binary_logloss: 0.0815563\tvalid_1's binary_logloss: 0.106457\n",
      "[22]\ttraining's binary_logloss: 0.0789808\tvalid_1's binary_logloss: 0.105764\n",
      "[24]\ttraining's binary_logloss: 0.0766798\tvalid_1's binary_logloss: 0.105132\n",
      "[26]\ttraining's binary_logloss: 0.0744663\tvalid_1's binary_logloss: 0.104064\n",
      "[28]\ttraining's binary_logloss: 0.0723194\tvalid_1's binary_logloss: 0.103537\n",
      "[30]\ttraining's binary_logloss: 0.0704021\tvalid_1's binary_logloss: 0.102871\n",
      "[32]\ttraining's binary_logloss: 0.0685513\tvalid_1's binary_logloss: 0.102406\n",
      "[34]\ttraining's binary_logloss: 0.0667856\tvalid_1's binary_logloss: 0.102089\n",
      "[36]\ttraining's binary_logloss: 0.0653092\tvalid_1's binary_logloss: 0.101678\n",
      "[38]\ttraining's binary_logloss: 0.0636255\tvalid_1's binary_logloss: 0.101342\n",
      "[40]\ttraining's binary_logloss: 0.062115\tvalid_1's binary_logloss: 0.101146\n",
      "[42]\ttraining's binary_logloss: 0.0608127\tvalid_1's binary_logloss: 0.100753\n",
      "[44]\ttraining's binary_logloss: 0.059396\tvalid_1's binary_logloss: 0.100445\n",
      "[46]\ttraining's binary_logloss: 0.0579937\tvalid_1's binary_logloss: 0.0998921\n",
      "[48]\ttraining's binary_logloss: 0.0568172\tvalid_1's binary_logloss: 0.0998391\n",
      "[50]\ttraining's binary_logloss: 0.0555782\tvalid_1's binary_logloss: 0.0997068\n",
      "[52]\ttraining's binary_logloss: 0.0545063\tvalid_1's binary_logloss: 0.0996055\n",
      "[54]\ttraining's binary_logloss: 0.0534277\tvalid_1's binary_logloss: 0.0995375\n",
      "[56]\ttraining's binary_logloss: 0.0523433\tvalid_1's binary_logloss: 0.0993622\n",
      "[58]\ttraining's binary_logloss: 0.0513199\tvalid_1's binary_logloss: 0.099205\n",
      "[60]\ttraining's binary_logloss: 0.0503142\tvalid_1's binary_logloss: 0.099007\n",
      "[62]\ttraining's binary_logloss: 0.0492798\tvalid_1's binary_logloss: 0.0988599\n",
      "[64]\ttraining's binary_logloss: 0.0484371\tvalid_1's binary_logloss: 0.0987817\n",
      "[66]\ttraining's binary_logloss: 0.0475686\tvalid_1's binary_logloss: 0.0987066\n",
      "[68]\ttraining's binary_logloss: 0.0466608\tvalid_1's binary_logloss: 0.0987293\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's binary_logloss: 0.0475686\tvalid_1's binary_logloss: 0.0987066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.097876:  90%|###########7 | 9/10 [00:43<00:05,  5.51s/it][I 2020-09-29 12:25:17,480] Trial 35 finished with value: 0.09870664619288624 and parameters: {'bagging_fraction': 0.8754495750007614, 'bagging_freq': 3}. Best is trial 34 with value: 0.09787598913695472.\n",
      "bagging, val_score: 0.097876:  90%|###########7 | 9/10 [00:43<00:05,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125063\tvalid_1's binary_logloss: 0.132348\n",
      "[4]\ttraining's binary_logloss: 0.114834\tvalid_1's binary_logloss: 0.125137\n",
      "[6]\ttraining's binary_logloss: 0.1074\tvalid_1's binary_logloss: 0.119856\n",
      "[8]\ttraining's binary_logloss: 0.101608\tvalid_1's binary_logloss: 0.115972\n",
      "[10]\ttraining's binary_logloss: 0.0968091\tvalid_1's binary_logloss: 0.113349\n",
      "[12]\ttraining's binary_logloss: 0.0927514\tvalid_1's binary_logloss: 0.11106\n",
      "[14]\ttraining's binary_logloss: 0.0891994\tvalid_1's binary_logloss: 0.109149\n",
      "[16]\ttraining's binary_logloss: 0.0859197\tvalid_1's binary_logloss: 0.107705\n",
      "[18]\ttraining's binary_logloss: 0.0832324\tvalid_1's binary_logloss: 0.106493\n",
      "[20]\ttraining's binary_logloss: 0.0804005\tvalid_1's binary_logloss: 0.105576\n",
      "[22]\ttraining's binary_logloss: 0.0778422\tvalid_1's binary_logloss: 0.105004\n",
      "[24]\ttraining's binary_logloss: 0.0757541\tvalid_1's binary_logloss: 0.104312\n",
      "[26]\ttraining's binary_logloss: 0.0736391\tvalid_1's binary_logloss: 0.103439\n",
      "[28]\ttraining's binary_logloss: 0.0715998\tvalid_1's binary_logloss: 0.102977\n",
      "[30]\ttraining's binary_logloss: 0.0696593\tvalid_1's binary_logloss: 0.102259\n",
      "[32]\ttraining's binary_logloss: 0.0678945\tvalid_1's binary_logloss: 0.101791\n",
      "[34]\ttraining's binary_logloss: 0.0661587\tvalid_1's binary_logloss: 0.101496\n",
      "[36]\ttraining's binary_logloss: 0.0643543\tvalid_1's binary_logloss: 0.101032\n",
      "[38]\ttraining's binary_logloss: 0.0629938\tvalid_1's binary_logloss: 0.100756\n",
      "[40]\ttraining's binary_logloss: 0.0614328\tvalid_1's binary_logloss: 0.100405\n",
      "[42]\ttraining's binary_logloss: 0.0601395\tvalid_1's binary_logloss: 0.100324\n",
      "[44]\ttraining's binary_logloss: 0.0588882\tvalid_1's binary_logloss: 0.100137\n",
      "[46]\ttraining's binary_logloss: 0.0576281\tvalid_1's binary_logloss: 0.100018\n",
      "[48]\ttraining's binary_logloss: 0.0564558\tvalid_1's binary_logloss: 0.0999887\n",
      "[50]\ttraining's binary_logloss: 0.0552976\tvalid_1's binary_logloss: 0.0998716\n",
      "[52]\ttraining's binary_logloss: 0.0541722\tvalid_1's binary_logloss: 0.0996718\n",
      "[54]\ttraining's binary_logloss: 0.0531149\tvalid_1's binary_logloss: 0.099524\n",
      "[56]\ttraining's binary_logloss: 0.0521012\tvalid_1's binary_logloss: 0.0994208\n",
      "[58]\ttraining's binary_logloss: 0.0512442\tvalid_1's binary_logloss: 0.0994081\n",
      "[60]\ttraining's binary_logloss: 0.0504123\tvalid_1's binary_logloss: 0.0994446\n",
      "[62]\ttraining's binary_logloss: 0.0495568\tvalid_1's binary_logloss: 0.0995254\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's binary_logloss: 0.0499592\tvalid_1's binary_logloss: 0.0993723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.097876: 100%|############| 10/10 [00:50<00:00,  6.11s/it][I 2020-09-29 12:25:24,986] Trial 36 finished with value: 0.09937233428384779 and parameters: {'bagging_fraction': 0.9937906761794086, 'bagging_freq': 5}. Best is trial 34 with value: 0.09787598913695472.\n",
      "bagging, val_score: 0.097876: 100%|############| 10/10 [00:50<00:00,  5.07s/it]\n",
      "feature_fraction_stage2, val_score: 0.097876:   0%|      | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125144\tvalid_1's binary_logloss: 0.132317\n",
      "[4]\ttraining's binary_logloss: 0.115146\tvalid_1's binary_logloss: 0.125218\n",
      "[6]\ttraining's binary_logloss: 0.107692\tvalid_1's binary_logloss: 0.120187\n",
      "[8]\ttraining's binary_logloss: 0.101715\tvalid_1's binary_logloss: 0.116487\n",
      "[10]\ttraining's binary_logloss: 0.0971104\tvalid_1's binary_logloss: 0.113524\n",
      "[12]\ttraining's binary_logloss: 0.0933831\tvalid_1's binary_logloss: 0.111369\n",
      "[14]\ttraining's binary_logloss: 0.0897336\tvalid_1's binary_logloss: 0.109358\n",
      "[16]\ttraining's binary_logloss: 0.086522\tvalid_1's binary_logloss: 0.10753\n",
      "[18]\ttraining's binary_logloss: 0.08351\tvalid_1's binary_logloss: 0.106368\n",
      "[20]\ttraining's binary_logloss: 0.0807626\tvalid_1's binary_logloss: 0.105318\n",
      "[22]\ttraining's binary_logloss: 0.0784152\tvalid_1's binary_logloss: 0.104464\n",
      "[24]\ttraining's binary_logloss: 0.076116\tvalid_1's binary_logloss: 0.103851\n",
      "[26]\ttraining's binary_logloss: 0.0738573\tvalid_1's binary_logloss: 0.102949\n",
      "[28]\ttraining's binary_logloss: 0.071919\tvalid_1's binary_logloss: 0.10271\n",
      "[30]\ttraining's binary_logloss: 0.0699697\tvalid_1's binary_logloss: 0.10246\n",
      "[32]\ttraining's binary_logloss: 0.0678798\tvalid_1's binary_logloss: 0.102082\n",
      "[34]\ttraining's binary_logloss: 0.0661783\tvalid_1's binary_logloss: 0.101729\n",
      "[36]\ttraining's binary_logloss: 0.0645172\tvalid_1's binary_logloss: 0.101521\n",
      "[38]\ttraining's binary_logloss: 0.0630413\tvalid_1's binary_logloss: 0.101234\n",
      "[40]\ttraining's binary_logloss: 0.0616626\tvalid_1's binary_logloss: 0.101022\n",
      "[42]\ttraining's binary_logloss: 0.0603226\tvalid_1's binary_logloss: 0.100715\n",
      "[44]\ttraining's binary_logloss: 0.0589662\tvalid_1's binary_logloss: 0.100412\n",
      "[46]\ttraining's binary_logloss: 0.0577957\tvalid_1's binary_logloss: 0.100385\n",
      "[48]\ttraining's binary_logloss: 0.0565886\tvalid_1's binary_logloss: 0.100275\n",
      "[50]\ttraining's binary_logloss: 0.0554831\tvalid_1's binary_logloss: 0.100147\n",
      "[52]\ttraining's binary_logloss: 0.0544394\tvalid_1's binary_logloss: 0.100013\n",
      "[54]\ttraining's binary_logloss: 0.0533479\tvalid_1's binary_logloss: 0.100106\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's binary_logloss: 0.0544394\tvalid_1's binary_logloss: 0.100013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.097876:  33%|3| 1/3 [00:12<00:24, 12.09s/[I 2020-09-29 12:25:37,129] Trial 37 finished with value: 0.1000134430477904 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 37 with value: 0.1000134430477904.\n",
      "feature_fraction_stage2, val_score: 0.097876:  33%|3| 1/3 [00:12<00:24, 12.09s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125181\tvalid_1's binary_logloss: 0.132281\n",
      "[4]\ttraining's binary_logloss: 0.115249\tvalid_1's binary_logloss: 0.125078\n",
      "[6]\ttraining's binary_logloss: 0.10766\tvalid_1's binary_logloss: 0.120116\n",
      "[8]\ttraining's binary_logloss: 0.101787\tvalid_1's binary_logloss: 0.116379\n",
      "[10]\ttraining's binary_logloss: 0.0970545\tvalid_1's binary_logloss: 0.113735\n",
      "[12]\ttraining's binary_logloss: 0.0931871\tvalid_1's binary_logloss: 0.111653\n",
      "[14]\ttraining's binary_logloss: 0.0896145\tvalid_1's binary_logloss: 0.109806\n",
      "[16]\ttraining's binary_logloss: 0.0866198\tvalid_1's binary_logloss: 0.108512\n",
      "[18]\ttraining's binary_logloss: 0.0837478\tvalid_1's binary_logloss: 0.107479\n",
      "[20]\ttraining's binary_logloss: 0.0808855\tvalid_1's binary_logloss: 0.106601\n",
      "[22]\ttraining's binary_logloss: 0.0784625\tvalid_1's binary_logloss: 0.105584\n",
      "[24]\ttraining's binary_logloss: 0.0762068\tvalid_1's binary_logloss: 0.104997\n",
      "[26]\ttraining's binary_logloss: 0.0741202\tvalid_1's binary_logloss: 0.104235\n",
      "[28]\ttraining's binary_logloss: 0.0721263\tvalid_1's binary_logloss: 0.10359\n",
      "[30]\ttraining's binary_logloss: 0.0701802\tvalid_1's binary_logloss: 0.102925\n",
      "[32]\ttraining's binary_logloss: 0.0683551\tvalid_1's binary_logloss: 0.102572\n",
      "[34]\ttraining's binary_logloss: 0.0665703\tvalid_1's binary_logloss: 0.102378\n",
      "[36]\ttraining's binary_logloss: 0.0649348\tvalid_1's binary_logloss: 0.101805\n",
      "[38]\ttraining's binary_logloss: 0.0632988\tvalid_1's binary_logloss: 0.101318\n",
      "[40]\ttraining's binary_logloss: 0.0618237\tvalid_1's binary_logloss: 0.100887\n",
      "[42]\ttraining's binary_logloss: 0.0604791\tvalid_1's binary_logloss: 0.100851\n",
      "[44]\ttraining's binary_logloss: 0.0592168\tvalid_1's binary_logloss: 0.100596\n",
      "[46]\ttraining's binary_logloss: 0.0579718\tvalid_1's binary_logloss: 0.100542\n",
      "[48]\ttraining's binary_logloss: 0.0568353\tvalid_1's binary_logloss: 0.100376\n",
      "[50]\ttraining's binary_logloss: 0.0556479\tvalid_1's binary_logloss: 0.100248\n",
      "[52]\ttraining's binary_logloss: 0.05462\tvalid_1's binary_logloss: 0.100186\n",
      "[54]\ttraining's binary_logloss: 0.053533\tvalid_1's binary_logloss: 0.100017\n",
      "[56]\ttraining's binary_logloss: 0.0527035\tvalid_1's binary_logloss: 0.100099\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.053533\tvalid_1's binary_logloss: 0.100017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.097876:  67%|6| 2/3 [00:30<00:14, 14.12s/[I 2020-09-29 12:25:55,984] Trial 38 finished with value: 0.10001673895081752 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 37 with value: 0.1000134430477904.\n",
      "feature_fraction_stage2, val_score: 0.097876:  67%|6| 2/3 [00:30<00:14, 14.12s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.12515\tvalid_1's binary_logloss: 0.132387\n",
      "[4]\ttraining's binary_logloss: 0.11518\tvalid_1's binary_logloss: 0.12537\n",
      "[6]\ttraining's binary_logloss: 0.107686\tvalid_1's binary_logloss: 0.120354\n",
      "[8]\ttraining's binary_logloss: 0.101919\tvalid_1's binary_logloss: 0.11699\n",
      "[10]\ttraining's binary_logloss: 0.0973332\tvalid_1's binary_logloss: 0.114075\n",
      "[12]\ttraining's binary_logloss: 0.0934643\tvalid_1's binary_logloss: 0.111926\n",
      "[14]\ttraining's binary_logloss: 0.0899128\tvalid_1's binary_logloss: 0.110026\n",
      "[16]\ttraining's binary_logloss: 0.0868201\tvalid_1's binary_logloss: 0.108319\n",
      "[18]\ttraining's binary_logloss: 0.0839603\tvalid_1's binary_logloss: 0.106786\n",
      "[20]\ttraining's binary_logloss: 0.0811776\tvalid_1's binary_logloss: 0.105678\n",
      "[22]\ttraining's binary_logloss: 0.0786975\tvalid_1's binary_logloss: 0.104893\n",
      "[24]\ttraining's binary_logloss: 0.0763561\tvalid_1's binary_logloss: 0.104125\n",
      "[26]\ttraining's binary_logloss: 0.0742765\tvalid_1's binary_logloss: 0.103537\n",
      "[28]\ttraining's binary_logloss: 0.0723528\tvalid_1's binary_logloss: 0.102952\n",
      "[30]\ttraining's binary_logloss: 0.0702774\tvalid_1's binary_logloss: 0.10246\n",
      "[32]\ttraining's binary_logloss: 0.0684612\tvalid_1's binary_logloss: 0.102144\n",
      "[34]\ttraining's binary_logloss: 0.0667654\tvalid_1's binary_logloss: 0.101769\n",
      "[36]\ttraining's binary_logloss: 0.0650684\tvalid_1's binary_logloss: 0.101361\n",
      "[38]\ttraining's binary_logloss: 0.063477\tvalid_1's binary_logloss: 0.10098\n",
      "[40]\ttraining's binary_logloss: 0.0618698\tvalid_1's binary_logloss: 0.100842\n",
      "[42]\ttraining's binary_logloss: 0.0605614\tvalid_1's binary_logloss: 0.100509\n",
      "[44]\ttraining's binary_logloss: 0.0591933\tvalid_1's binary_logloss: 0.100416\n",
      "[46]\ttraining's binary_logloss: 0.0579678\tvalid_1's binary_logloss: 0.100277\n",
      "[48]\ttraining's binary_logloss: 0.0567517\tvalid_1's binary_logloss: 0.100339\n",
      "[50]\ttraining's binary_logloss: 0.0556836\tvalid_1's binary_logloss: 0.100126\n",
      "[52]\ttraining's binary_logloss: 0.0545378\tvalid_1's binary_logloss: 0.100046\n",
      "[54]\ttraining's binary_logloss: 0.053507\tvalid_1's binary_logloss: 0.099933\n",
      "[56]\ttraining's binary_logloss: 0.0524002\tvalid_1's binary_logloss: 0.0997198\n",
      "[58]\ttraining's binary_logloss: 0.0515028\tvalid_1's binary_logloss: 0.0997523\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.0524002\tvalid_1's binary_logloss: 0.0997198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.097876: 100%|#| 3/3 [00:39<00:00, 12.49s/[I 2020-09-29 12:26:04,673] Trial 39 finished with value: 0.09971976929832876 and parameters: {'feature_fraction': 0.92}. Best is trial 39 with value: 0.09971976929832876.\n",
      "feature_fraction_stage2, val_score: 0.097876: 100%|#| 3/3 [00:39<00:00, 13.22s/\n",
      "regularization_factors, val_score: 0.097876:   0%|      | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.12506\tvalid_1's binary_logloss: 0.132483\n",
      "[4]\ttraining's binary_logloss: 0.114847\tvalid_1's binary_logloss: 0.125233\n",
      "[6]\ttraining's binary_logloss: 0.107395\tvalid_1's binary_logloss: 0.120037\n",
      "[8]\ttraining's binary_logloss: 0.101775\tvalid_1's binary_logloss: 0.1163\n",
      "[10]\ttraining's binary_logloss: 0.0971328\tvalid_1's binary_logloss: 0.113405\n",
      "[12]\ttraining's binary_logloss: 0.0929995\tvalid_1's binary_logloss: 0.111199\n",
      "[14]\ttraining's binary_logloss: 0.0894521\tvalid_1's binary_logloss: 0.109158\n",
      "[16]\ttraining's binary_logloss: 0.086333\tvalid_1's binary_logloss: 0.107783\n",
      "[18]\ttraining's binary_logloss: 0.0837162\tvalid_1's binary_logloss: 0.106476\n",
      "[20]\ttraining's binary_logloss: 0.080926\tvalid_1's binary_logloss: 0.105405\n",
      "[22]\ttraining's binary_logloss: 0.0783267\tvalid_1's binary_logloss: 0.10425\n",
      "[24]\ttraining's binary_logloss: 0.0759793\tvalid_1's binary_logloss: 0.103429\n",
      "[26]\ttraining's binary_logloss: 0.0739206\tvalid_1's binary_logloss: 0.102653\n",
      "[28]\ttraining's binary_logloss: 0.0719935\tvalid_1's binary_logloss: 0.102037\n",
      "[30]\ttraining's binary_logloss: 0.0698592\tvalid_1's binary_logloss: 0.101529\n",
      "[32]\ttraining's binary_logloss: 0.0680164\tvalid_1's binary_logloss: 0.101215\n",
      "[34]\ttraining's binary_logloss: 0.0661757\tvalid_1's binary_logloss: 0.100637\n",
      "[36]\ttraining's binary_logloss: 0.0646293\tvalid_1's binary_logloss: 0.100318\n",
      "[38]\ttraining's binary_logloss: 0.0632366\tvalid_1's binary_logloss: 0.0999763\n",
      "[40]\ttraining's binary_logloss: 0.0617853\tvalid_1's binary_logloss: 0.0996006\n",
      "[42]\ttraining's binary_logloss: 0.0602343\tvalid_1's binary_logloss: 0.099404\n",
      "[44]\ttraining's binary_logloss: 0.0589597\tvalid_1's binary_logloss: 0.0991898\n",
      "[46]\ttraining's binary_logloss: 0.057712\tvalid_1's binary_logloss: 0.0990709\n",
      "[48]\ttraining's binary_logloss: 0.0566253\tvalid_1's binary_logloss: 0.0988551\n",
      "[50]\ttraining's binary_logloss: 0.0555892\tvalid_1's binary_logloss: 0.0987862\n",
      "[52]\ttraining's binary_logloss: 0.0545876\tvalid_1's binary_logloss: 0.0985366\n",
      "[54]\ttraining's binary_logloss: 0.0535604\tvalid_1's binary_logloss: 0.0985338\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's binary_logloss: 0.0541538\tvalid_1's binary_logloss: 0.0984723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:   5%| | 1/20 [00:09<02:59,  9.45s/[I 2020-09-29 12:26:14,146] Trial 40 finished with value: 0.09847234852149336 and parameters: {'lambda_l1': 4.3025271258528724e-07, 'lambda_l2': 0.0010099548309149158}. Best is trial 40 with value: 0.09847234852149336.\n",
      "regularization_factors, val_score: 0.097876:   5%| | 1/20 [00:09<02:59,  9.45s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125062\tvalid_1's binary_logloss: 0.132484\n",
      "[4]\ttraining's binary_logloss: 0.114848\tvalid_1's binary_logloss: 0.125234\n",
      "[6]\ttraining's binary_logloss: 0.107399\tvalid_1's binary_logloss: 0.120072\n",
      "[8]\ttraining's binary_logloss: 0.10178\tvalid_1's binary_logloss: 0.116333\n",
      "[10]\ttraining's binary_logloss: 0.0971367\tvalid_1's binary_logloss: 0.113435\n",
      "[12]\ttraining's binary_logloss: 0.0930052\tvalid_1's binary_logloss: 0.111256\n",
      "[14]\ttraining's binary_logloss: 0.0894539\tvalid_1's binary_logloss: 0.109232\n",
      "[16]\ttraining's binary_logloss: 0.0865038\tvalid_1's binary_logloss: 0.107756\n",
      "[18]\ttraining's binary_logloss: 0.0833906\tvalid_1's binary_logloss: 0.106857\n",
      "[20]\ttraining's binary_logloss: 0.0806462\tvalid_1's binary_logloss: 0.105702\n",
      "[22]\ttraining's binary_logloss: 0.0782089\tvalid_1's binary_logloss: 0.104923\n",
      "[24]\ttraining's binary_logloss: 0.0759954\tvalid_1's binary_logloss: 0.10405\n",
      "[26]\ttraining's binary_logloss: 0.0738499\tvalid_1's binary_logloss: 0.103473\n",
      "[28]\ttraining's binary_logloss: 0.0718603\tvalid_1's binary_logloss: 0.103018\n",
      "[30]\ttraining's binary_logloss: 0.0699588\tvalid_1's binary_logloss: 0.102579\n",
      "[32]\ttraining's binary_logloss: 0.0680893\tvalid_1's binary_logloss: 0.101984\n",
      "[34]\ttraining's binary_logloss: 0.0663189\tvalid_1's binary_logloss: 0.101749\n",
      "[36]\ttraining's binary_logloss: 0.0646557\tvalid_1's binary_logloss: 0.101194\n",
      "[38]\ttraining's binary_logloss: 0.063109\tvalid_1's binary_logloss: 0.100818\n",
      "[40]\ttraining's binary_logloss: 0.0615321\tvalid_1's binary_logloss: 0.100359\n",
      "[42]\ttraining's binary_logloss: 0.0602396\tvalid_1's binary_logloss: 0.100056\n",
      "[44]\ttraining's binary_logloss: 0.0588607\tvalid_1's binary_logloss: 0.0999379\n",
      "[46]\ttraining's binary_logloss: 0.0576307\tvalid_1's binary_logloss: 0.0996179\n",
      "[48]\ttraining's binary_logloss: 0.0565067\tvalid_1's binary_logloss: 0.0994361\n",
      "[50]\ttraining's binary_logloss: 0.0554075\tvalid_1's binary_logloss: 0.099193\n",
      "[52]\ttraining's binary_logloss: 0.0543809\tvalid_1's binary_logloss: 0.0990558\n",
      "[54]\ttraining's binary_logloss: 0.0533175\tvalid_1's binary_logloss: 0.0990036\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's binary_logloss: 0.0538618\tvalid_1's binary_logloss: 0.098909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  10%|1| 2/20 [00:15<02:31,  8.44s/[I 2020-09-29 12:26:20,243] Trial 41 finished with value: 0.09890898554724209 and parameters: {'lambda_l1': 2.5193549861924895e-07, 'lambda_l2': 0.0011613217861778428}. Best is trial 40 with value: 0.09847234852149336.\n",
      "regularization_factors, val_score: 0.097876:  10%|1| 2/20 [00:15<02:31,  8.44s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125047\tvalid_1's binary_logloss: 0.132476\n",
      "[4]\ttraining's binary_logloss: 0.114803\tvalid_1's binary_logloss: 0.125216\n",
      "[6]\ttraining's binary_logloss: 0.10736\tvalid_1's binary_logloss: 0.120064\n",
      "[8]\ttraining's binary_logloss: 0.101645\tvalid_1's binary_logloss: 0.116267\n",
      "[10]\ttraining's binary_logloss: 0.0970625\tvalid_1's binary_logloss: 0.113456\n",
      "[12]\ttraining's binary_logloss: 0.0931239\tvalid_1's binary_logloss: 0.111329\n",
      "[14]\ttraining's binary_logloss: 0.0896357\tvalid_1's binary_logloss: 0.109428\n",
      "[16]\ttraining's binary_logloss: 0.0864862\tvalid_1's binary_logloss: 0.108138\n",
      "[18]\ttraining's binary_logloss: 0.0834792\tvalid_1's binary_logloss: 0.106833\n",
      "[20]\ttraining's binary_logloss: 0.0808249\tvalid_1's binary_logloss: 0.106075\n",
      "[22]\ttraining's binary_logloss: 0.0784013\tvalid_1's binary_logloss: 0.105067\n",
      "[24]\ttraining's binary_logloss: 0.076089\tvalid_1's binary_logloss: 0.104038\n",
      "[26]\ttraining's binary_logloss: 0.0737704\tvalid_1's binary_logloss: 0.103238\n",
      "[28]\ttraining's binary_logloss: 0.071873\tvalid_1's binary_logloss: 0.102824\n",
      "[30]\ttraining's binary_logloss: 0.070006\tvalid_1's binary_logloss: 0.102328\n",
      "[32]\ttraining's binary_logloss: 0.0681975\tvalid_1's binary_logloss: 0.101757\n",
      "[34]\ttraining's binary_logloss: 0.0664545\tvalid_1's binary_logloss: 0.101588\n",
      "[36]\ttraining's binary_logloss: 0.0648441\tvalid_1's binary_logloss: 0.101152\n",
      "[38]\ttraining's binary_logloss: 0.0631846\tvalid_1's binary_logloss: 0.100881\n",
      "[40]\ttraining's binary_logloss: 0.0617937\tvalid_1's binary_logloss: 0.100635\n",
      "[42]\ttraining's binary_logloss: 0.0605513\tvalid_1's binary_logloss: 0.100318\n",
      "[44]\ttraining's binary_logloss: 0.0593081\tvalid_1's binary_logloss: 0.0999912\n",
      "[46]\ttraining's binary_logloss: 0.0580519\tvalid_1's binary_logloss: 0.0998273\n",
      "[48]\ttraining's binary_logloss: 0.0569037\tvalid_1's binary_logloss: 0.0996109\n",
      "[50]\ttraining's binary_logloss: 0.0556988\tvalid_1's binary_logloss: 0.099429\n",
      "[52]\ttraining's binary_logloss: 0.0546238\tvalid_1's binary_logloss: 0.0993872\n",
      "[54]\ttraining's binary_logloss: 0.0536727\tvalid_1's binary_logloss: 0.0993595\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's binary_logloss: 0.0541509\tvalid_1's binary_logloss: 0.0992865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  15%|1| 3/20 [00:20<02:05,  7.37s/[I 2020-09-29 12:26:25,115] Trial 42 finished with value: 0.09928649830574651 and parameters: {'lambda_l1': 0.000145481287761838, 'lambda_l2': 3.987389594375408e-08}. Best is trial 40 with value: 0.09847234852149336.\n",
      "regularization_factors, val_score: 0.097876:  15%|1| 3/20 [00:20<02:05,  7.37s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.138356\tvalid_1's binary_logloss: 0.139395\n",
      "[4]\ttraining's binary_logloss: 0.127756\tvalid_1's binary_logloss: 0.130461\n",
      "[6]\ttraining's binary_logloss: 0.120606\tvalid_1's binary_logloss: 0.124906\n",
      "[8]\ttraining's binary_logloss: 0.115201\tvalid_1's binary_logloss: 0.120612\n",
      "[10]\ttraining's binary_logloss: 0.110811\tvalid_1's binary_logloss: 0.117394\n",
      "[12]\ttraining's binary_logloss: 0.107375\tvalid_1's binary_logloss: 0.114802\n",
      "[14]\ttraining's binary_logloss: 0.104385\tvalid_1's binary_logloss: 0.112629\n",
      "[16]\ttraining's binary_logloss: 0.101707\tvalid_1's binary_logloss: 0.110855\n",
      "[18]\ttraining's binary_logloss: 0.0994339\tvalid_1's binary_logloss: 0.109557\n",
      "[20]\ttraining's binary_logloss: 0.0973348\tvalid_1's binary_logloss: 0.108534\n",
      "[22]\ttraining's binary_logloss: 0.0955082\tvalid_1's binary_logloss: 0.107568\n",
      "[24]\ttraining's binary_logloss: 0.0937608\tvalid_1's binary_logloss: 0.106889\n",
      "[26]\ttraining's binary_logloss: 0.0921188\tvalid_1's binary_logloss: 0.105995\n",
      "[28]\ttraining's binary_logloss: 0.0906728\tvalid_1's binary_logloss: 0.105445\n",
      "[30]\ttraining's binary_logloss: 0.0892751\tvalid_1's binary_logloss: 0.104773\n",
      "[32]\ttraining's binary_logloss: 0.0879234\tvalid_1's binary_logloss: 0.104027\n",
      "[34]\ttraining's binary_logloss: 0.0865916\tvalid_1's binary_logloss: 0.103701\n",
      "[36]\ttraining's binary_logloss: 0.0854425\tvalid_1's binary_logloss: 0.103448\n",
      "[38]\ttraining's binary_logloss: 0.0842646\tvalid_1's binary_logloss: 0.10304\n",
      "[40]\ttraining's binary_logloss: 0.0831335\tvalid_1's binary_logloss: 0.102753\n",
      "[42]\ttraining's binary_logloss: 0.0820917\tvalid_1's binary_logloss: 0.102456\n",
      "[44]\ttraining's binary_logloss: 0.0810479\tvalid_1's binary_logloss: 0.102228\n",
      "[46]\ttraining's binary_logloss: 0.0799823\tvalid_1's binary_logloss: 0.101938\n",
      "[48]\ttraining's binary_logloss: 0.078965\tvalid_1's binary_logloss: 0.101606\n",
      "[50]\ttraining's binary_logloss: 0.0780063\tvalid_1's binary_logloss: 0.10133\n",
      "[52]\ttraining's binary_logloss: 0.0770131\tvalid_1's binary_logloss: 0.1011\n",
      "[54]\ttraining's binary_logloss: 0.0761947\tvalid_1's binary_logloss: 0.101113\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's binary_logloss: 0.0770131\tvalid_1's binary_logloss: 0.1011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  20%|2| 4/20 [00:25<01:46,  6.65s/[I 2020-09-29 12:26:30,096] Trial 43 finished with value: 0.10109956273773944 and parameters: {'lambda_l1': 1.1808000657482259e-08, 'lambda_l2': 8.080569715396804}. Best is trial 40 with value: 0.09847234852149336.\n",
      "regularization_factors, val_score: 0.097876:  20%|2| 4/20 [00:25<01:46,  6.65s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125821\tvalid_1's binary_logloss: 0.132469\n",
      "[4]\ttraining's binary_logloss: 0.116108\tvalid_1's binary_logloss: 0.125134\n",
      "[6]\ttraining's binary_logloss: 0.108998\tvalid_1's binary_logloss: 0.120307\n",
      "[8]\ttraining's binary_logloss: 0.103661\tvalid_1's binary_logloss: 0.116785\n",
      "[10]\ttraining's binary_logloss: 0.0991434\tvalid_1's binary_logloss: 0.113874\n",
      "[12]\ttraining's binary_logloss: 0.0953554\tvalid_1's binary_logloss: 0.111636\n",
      "[14]\ttraining's binary_logloss: 0.0920877\tvalid_1's binary_logloss: 0.109757\n",
      "[16]\ttraining's binary_logloss: 0.0893467\tvalid_1's binary_logloss: 0.108437\n",
      "[18]\ttraining's binary_logloss: 0.0867297\tvalid_1's binary_logloss: 0.10731\n",
      "[20]\ttraining's binary_logloss: 0.0843424\tvalid_1's binary_logloss: 0.106201\n",
      "[22]\ttraining's binary_logloss: 0.082144\tvalid_1's binary_logloss: 0.105213\n",
      "[24]\ttraining's binary_logloss: 0.0798433\tvalid_1's binary_logloss: 0.104008\n",
      "[26]\ttraining's binary_logloss: 0.0780103\tvalid_1's binary_logloss: 0.103155\n",
      "[28]\ttraining's binary_logloss: 0.0761507\tvalid_1's binary_logloss: 0.102601\n",
      "[30]\ttraining's binary_logloss: 0.0743993\tvalid_1's binary_logloss: 0.101713\n",
      "[32]\ttraining's binary_logloss: 0.0726111\tvalid_1's binary_logloss: 0.101562\n",
      "[34]\ttraining's binary_logloss: 0.0707944\tvalid_1's binary_logloss: 0.101381\n",
      "[36]\ttraining's binary_logloss: 0.0691675\tvalid_1's binary_logloss: 0.100992\n",
      "[38]\ttraining's binary_logloss: 0.0677453\tvalid_1's binary_logloss: 0.100637\n",
      "[40]\ttraining's binary_logloss: 0.0663927\tvalid_1's binary_logloss: 0.100305\n",
      "[42]\ttraining's binary_logloss: 0.065102\tvalid_1's binary_logloss: 0.100202\n",
      "[44]\ttraining's binary_logloss: 0.0639083\tvalid_1's binary_logloss: 0.10003\n",
      "[46]\ttraining's binary_logloss: 0.0626209\tvalid_1's binary_logloss: 0.0999507\n",
      "[48]\ttraining's binary_logloss: 0.0615709\tvalid_1's binary_logloss: 0.0999785\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's binary_logloss: 0.0626209\tvalid_1's binary_logloss: 0.0999507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  25%|2| 5/20 [00:28<01:22,  5.47s/[I 2020-09-29 12:26:32,819] Trial 44 finished with value: 0.09995068787494356 and parameters: {'lambda_l1': 0.34183479718742465, 'lambda_l2': 0.0009413178296993306}. Best is trial 40 with value: 0.09847234852149336.\n",
      "regularization_factors, val_score: 0.097876:  25%|2| 5/20 [00:28<01:22,  5.47s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125066\tvalid_1's binary_logloss: 0.13248\n",
      "[4]\ttraining's binary_logloss: 0.11474\tvalid_1's binary_logloss: 0.125314\n",
      "[6]\ttraining's binary_logloss: 0.107286\tvalid_1's binary_logloss: 0.120175\n",
      "[8]\ttraining's binary_logloss: 0.101724\tvalid_1's binary_logloss: 0.116398\n",
      "[10]\ttraining's binary_logloss: 0.0969133\tvalid_1's binary_logloss: 0.11375\n",
      "[12]\ttraining's binary_logloss: 0.0929664\tvalid_1's binary_logloss: 0.111784\n",
      "[14]\ttraining's binary_logloss: 0.0894207\tvalid_1's binary_logloss: 0.109797\n",
      "[16]\ttraining's binary_logloss: 0.0860577\tvalid_1's binary_logloss: 0.108495\n",
      "[18]\ttraining's binary_logloss: 0.0831825\tvalid_1's binary_logloss: 0.107296\n",
      "[20]\ttraining's binary_logloss: 0.0805181\tvalid_1's binary_logloss: 0.106304\n",
      "[22]\ttraining's binary_logloss: 0.0779025\tvalid_1's binary_logloss: 0.105384\n",
      "[24]\ttraining's binary_logloss: 0.0757853\tvalid_1's binary_logloss: 0.104507\n",
      "[26]\ttraining's binary_logloss: 0.07376\tvalid_1's binary_logloss: 0.103705\n",
      "[28]\ttraining's binary_logloss: 0.0718425\tvalid_1's binary_logloss: 0.103071\n",
      "[30]\ttraining's binary_logloss: 0.0697167\tvalid_1's binary_logloss: 0.102389\n",
      "[32]\ttraining's binary_logloss: 0.0678628\tvalid_1's binary_logloss: 0.10183\n",
      "[34]\ttraining's binary_logloss: 0.0662106\tvalid_1's binary_logloss: 0.101505\n",
      "[36]\ttraining's binary_logloss: 0.064589\tvalid_1's binary_logloss: 0.101114\n",
      "[38]\ttraining's binary_logloss: 0.0630205\tvalid_1's binary_logloss: 0.100696\n",
      "[40]\ttraining's binary_logloss: 0.0614845\tvalid_1's binary_logloss: 0.10009\n",
      "[42]\ttraining's binary_logloss: 0.0599996\tvalid_1's binary_logloss: 0.0998838\n",
      "[44]\ttraining's binary_logloss: 0.0585992\tvalid_1's binary_logloss: 0.0997069\n",
      "[46]\ttraining's binary_logloss: 0.0573602\tvalid_1's binary_logloss: 0.0997537\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's binary_logloss: 0.0585992\tvalid_1's binary_logloss: 0.0997069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  30%|3| 6/20 [00:32<01:10,  5.01s/[I 2020-09-29 12:26:36,729] Trial 45 finished with value: 0.09970690463113346 and parameters: {'lambda_l1': 1.1400680801427387e-05, 'lambda_l2': 5.853313445116741e-07}. Best is trial 40 with value: 0.09847234852149336.\n",
      "regularization_factors, val_score: 0.097876:  30%|3| 6/20 [00:32<01:10,  5.01s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.129451\tvalid_1's binary_logloss: 0.134178\n",
      "[4]\ttraining's binary_logloss: 0.119229\tvalid_1's binary_logloss: 0.126425\n",
      "[6]\ttraining's binary_logloss: 0.111684\tvalid_1's binary_logloss: 0.120571\n",
      "[8]\ttraining's binary_logloss: 0.106081\tvalid_1's binary_logloss: 0.116913\n",
      "[10]\ttraining's binary_logloss: 0.101676\tvalid_1's binary_logloss: 0.114026\n",
      "[12]\ttraining's binary_logloss: 0.0979198\tvalid_1's binary_logloss: 0.111749\n",
      "[14]\ttraining's binary_logloss: 0.0947038\tvalid_1's binary_logloss: 0.109778\n",
      "[16]\ttraining's binary_logloss: 0.0919343\tvalid_1's binary_logloss: 0.108169\n",
      "[18]\ttraining's binary_logloss: 0.089452\tvalid_1's binary_logloss: 0.106797\n",
      "[20]\ttraining's binary_logloss: 0.0871461\tvalid_1's binary_logloss: 0.105724\n",
      "[22]\ttraining's binary_logloss: 0.0850341\tvalid_1's binary_logloss: 0.104704\n",
      "[24]\ttraining's binary_logloss: 0.0830793\tvalid_1's binary_logloss: 0.103959\n",
      "[26]\ttraining's binary_logloss: 0.0812908\tvalid_1's binary_logloss: 0.103184\n",
      "[28]\ttraining's binary_logloss: 0.0795574\tvalid_1's binary_logloss: 0.102504\n",
      "[30]\ttraining's binary_logloss: 0.0777603\tvalid_1's binary_logloss: 0.10193\n",
      "[32]\ttraining's binary_logloss: 0.0762381\tvalid_1's binary_logloss: 0.101719\n",
      "[34]\ttraining's binary_logloss: 0.0746699\tvalid_1's binary_logloss: 0.101278\n",
      "[36]\ttraining's binary_logloss: 0.0732268\tvalid_1's binary_logloss: 0.100621\n",
      "[38]\ttraining's binary_logloss: 0.0719575\tvalid_1's binary_logloss: 0.100366\n",
      "[40]\ttraining's binary_logloss: 0.0707218\tvalid_1's binary_logloss: 0.100101\n",
      "[42]\ttraining's binary_logloss: 0.0696162\tvalid_1's binary_logloss: 0.0998413\n",
      "[44]\ttraining's binary_logloss: 0.0683888\tvalid_1's binary_logloss: 0.0994368\n",
      "[46]\ttraining's binary_logloss: 0.0671933\tvalid_1's binary_logloss: 0.0993863\n",
      "[48]\ttraining's binary_logloss: 0.0661626\tvalid_1's binary_logloss: 0.0992609\n",
      "[50]\ttraining's binary_logloss: 0.0652508\tvalid_1's binary_logloss: 0.0991903\n",
      "[52]\ttraining's binary_logloss: 0.0643554\tvalid_1's binary_logloss: 0.0989819\n",
      "[54]\ttraining's binary_logloss: 0.0635083\tvalid_1's binary_logloss: 0.0987707\n",
      "[56]\ttraining's binary_logloss: 0.0624887\tvalid_1's binary_logloss: 0.0984054\n",
      "[58]\ttraining's binary_logloss: 0.061522\tvalid_1's binary_logloss: 0.0982815\n",
      "[60]\ttraining's binary_logloss: 0.0606593\tvalid_1's binary_logloss: 0.0981317\n",
      "[62]\ttraining's binary_logloss: 0.0596912\tvalid_1's binary_logloss: 0.0980303\n",
      "[64]\ttraining's binary_logloss: 0.0589198\tvalid_1's binary_logloss: 0.0980093\n",
      "[66]\ttraining's binary_logloss: 0.0580901\tvalid_1's binary_logloss: 0.097943\n",
      "[68]\ttraining's binary_logloss: 0.0574431\tvalid_1's binary_logloss: 0.0979873\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's binary_logloss: 0.0580901\tvalid_1's binary_logloss: 0.097943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  35%|3| 7/20 [00:37<01:05,  5.02s/[I 2020-09-29 12:26:41,799] Trial 46 finished with value: 0.09794304097983553 and parameters: {'lambda_l1': 0.22288954985499404, 'lambda_l2': 0.6345716760704124}. Best is trial 46 with value: 0.09794304097983553.\n",
      "regularization_factors, val_score: 0.097876:  35%|3| 7/20 [00:37<01:05,  5.02s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.134116\tvalid_1's binary_logloss: 0.136205\n",
      "[4]\ttraining's binary_logloss: 0.123839\tvalid_1's binary_logloss: 0.127832\n",
      "[6]\ttraining's binary_logloss: 0.116405\tvalid_1's binary_logloss: 0.122323\n",
      "[8]\ttraining's binary_logloss: 0.110955\tvalid_1's binary_logloss: 0.118333\n",
      "[10]\ttraining's binary_logloss: 0.106626\tvalid_1's binary_logloss: 0.115325\n",
      "[12]\ttraining's binary_logloss: 0.102877\tvalid_1's binary_logloss: 0.112901\n",
      "[14]\ttraining's binary_logloss: 0.0999316\tvalid_1's binary_logloss: 0.110952\n",
      "[16]\ttraining's binary_logloss: 0.0972829\tvalid_1's binary_logloss: 0.109316\n",
      "[18]\ttraining's binary_logloss: 0.0950308\tvalid_1's binary_logloss: 0.107991\n",
      "[20]\ttraining's binary_logloss: 0.092858\tvalid_1's binary_logloss: 0.106959\n",
      "[22]\ttraining's binary_logloss: 0.0908793\tvalid_1's binary_logloss: 0.105978\n",
      "[24]\ttraining's binary_logloss: 0.0889751\tvalid_1's binary_logloss: 0.10509\n",
      "[26]\ttraining's binary_logloss: 0.0874797\tvalid_1's binary_logloss: 0.104626\n",
      "[28]\ttraining's binary_logloss: 0.0859095\tvalid_1's binary_logloss: 0.104019\n",
      "[30]\ttraining's binary_logloss: 0.0844171\tvalid_1's binary_logloss: 0.103521\n",
      "[32]\ttraining's binary_logloss: 0.0828788\tvalid_1's binary_logloss: 0.103132\n",
      "[34]\ttraining's binary_logloss: 0.0815556\tvalid_1's binary_logloss: 0.102664\n",
      "[36]\ttraining's binary_logloss: 0.0803515\tvalid_1's binary_logloss: 0.102262\n",
      "[38]\ttraining's binary_logloss: 0.0791209\tvalid_1's binary_logloss: 0.101847\n",
      "[40]\ttraining's binary_logloss: 0.077977\tvalid_1's binary_logloss: 0.101562\n",
      "[42]\ttraining's binary_logloss: 0.0768393\tvalid_1's binary_logloss: 0.101547\n",
      "[44]\ttraining's binary_logloss: 0.0758222\tvalid_1's binary_logloss: 0.101295\n",
      "[46]\ttraining's binary_logloss: 0.0747828\tvalid_1's binary_logloss: 0.100932\n",
      "[48]\ttraining's binary_logloss: 0.0737711\tvalid_1's binary_logloss: 0.100769\n",
      "[50]\ttraining's binary_logloss: 0.0728133\tvalid_1's binary_logloss: 0.100618\n",
      "[52]\ttraining's binary_logloss: 0.071911\tvalid_1's binary_logloss: 0.100444\n",
      "[54]\ttraining's binary_logloss: 0.0710069\tvalid_1's binary_logloss: 0.100296\n",
      "[56]\ttraining's binary_logloss: 0.0702318\tvalid_1's binary_logloss: 0.100147\n",
      "[58]\ttraining's binary_logloss: 0.0694337\tvalid_1's binary_logloss: 0.100145\n",
      "[60]\ttraining's binary_logloss: 0.0686001\tvalid_1's binary_logloss: 0.100024\n",
      "[62]\ttraining's binary_logloss: 0.0678558\tvalid_1's binary_logloss: 0.0999074\n",
      "[64]\ttraining's binary_logloss: 0.0671402\tvalid_1's binary_logloss: 0.0997747\n",
      "[66]\ttraining's binary_logloss: 0.0664155\tvalid_1's binary_logloss: 0.0997373\n",
      "[68]\ttraining's binary_logloss: 0.0657559\tvalid_1's binary_logloss: 0.0996186\n",
      "[70]\ttraining's binary_logloss: 0.0650895\tvalid_1's binary_logloss: 0.0995449\n",
      "[72]\ttraining's binary_logloss: 0.0644577\tvalid_1's binary_logloss: 0.099378\n",
      "[74]\ttraining's binary_logloss: 0.0638877\tvalid_1's binary_logloss: 0.0993215\n",
      "[76]\ttraining's binary_logloss: 0.0632644\tvalid_1's binary_logloss: 0.0992314\n",
      "[78]\ttraining's binary_logloss: 0.0627101\tvalid_1's binary_logloss: 0.0992127\n",
      "[80]\ttraining's binary_logloss: 0.0621836\tvalid_1's binary_logloss: 0.0990781\n",
      "[82]\ttraining's binary_logloss: 0.0615817\tvalid_1's binary_logloss: 0.0991358\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.0621836\tvalid_1's binary_logloss: 0.0990781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  40%|4| 8/20 [00:44<01:07,  5.60s/[I 2020-09-29 12:26:48,731] Trial 47 finished with value: 0.09907808206074671 and parameters: {'lambda_l1': 0.4671632870687575, 'lambda_l2': 2.6986698327410568}. Best is trial 46 with value: 0.09794304097983553.\n",
      "regularization_factors, val_score: 0.097876:  40%|4| 8/20 [00:44<01:07,  5.60s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.12581\tvalid_1's binary_logloss: 0.132417\n",
      "[4]\ttraining's binary_logloss: 0.115565\tvalid_1's binary_logloss: 0.125369\n",
      "[6]\ttraining's binary_logloss: 0.108192\tvalid_1's binary_logloss: 0.12034\n",
      "[8]\ttraining's binary_logloss: 0.102609\tvalid_1's binary_logloss: 0.116628\n",
      "[10]\ttraining's binary_logloss: 0.0979472\tvalid_1's binary_logloss: 0.114065\n",
      "[12]\ttraining's binary_logloss: 0.0940227\tvalid_1's binary_logloss: 0.11148\n",
      "[14]\ttraining's binary_logloss: 0.0906093\tvalid_1's binary_logloss: 0.109529\n",
      "[16]\ttraining's binary_logloss: 0.0877867\tvalid_1's binary_logloss: 0.108117\n",
      "[18]\ttraining's binary_logloss: 0.084869\tvalid_1's binary_logloss: 0.106499\n",
      "[20]\ttraining's binary_logloss: 0.0823064\tvalid_1's binary_logloss: 0.105451\n",
      "[22]\ttraining's binary_logloss: 0.0798616\tvalid_1's binary_logloss: 0.104474\n",
      "[24]\ttraining's binary_logloss: 0.0776486\tvalid_1's binary_logloss: 0.103562\n",
      "[26]\ttraining's binary_logloss: 0.0757087\tvalid_1's binary_logloss: 0.103046\n",
      "[28]\ttraining's binary_logloss: 0.073858\tvalid_1's binary_logloss: 0.102598\n",
      "[30]\ttraining's binary_logloss: 0.0719084\tvalid_1's binary_logloss: 0.102088\n",
      "[32]\ttraining's binary_logloss: 0.0702283\tvalid_1's binary_logloss: 0.101622\n",
      "[34]\ttraining's binary_logloss: 0.0684254\tvalid_1's binary_logloss: 0.101123\n",
      "[36]\ttraining's binary_logloss: 0.0667136\tvalid_1's binary_logloss: 0.100746\n",
      "[38]\ttraining's binary_logloss: 0.0652491\tvalid_1's binary_logloss: 0.100359\n",
      "[40]\ttraining's binary_logloss: 0.0638621\tvalid_1's binary_logloss: 0.10019\n",
      "[42]\ttraining's binary_logloss: 0.0625207\tvalid_1's binary_logloss: 0.0999058\n",
      "[44]\ttraining's binary_logloss: 0.0614068\tvalid_1's binary_logloss: 0.0997351\n",
      "[46]\ttraining's binary_logloss: 0.0600746\tvalid_1's binary_logloss: 0.0996891\n",
      "[48]\ttraining's binary_logloss: 0.0590311\tvalid_1's binary_logloss: 0.0995351\n",
      "[50]\ttraining's binary_logloss: 0.0580478\tvalid_1's binary_logloss: 0.0995078\n",
      "[52]\ttraining's binary_logloss: 0.057033\tvalid_1's binary_logloss: 0.0992811\n",
      "[54]\ttraining's binary_logloss: 0.0560661\tvalid_1's binary_logloss: 0.0991662\n",
      "[56]\ttraining's binary_logloss: 0.0551282\tvalid_1's binary_logloss: 0.0991489\n",
      "[58]\ttraining's binary_logloss: 0.0540299\tvalid_1's binary_logloss: 0.0992383\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.0545507\tvalid_1's binary_logloss: 0.0990677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  45%|4| 9/20 [02:02<05:03, 27.57s/[I 2020-09-29 12:28:07,584] Trial 48 finished with value: 0.09906768170253008 and parameters: {'lambda_l1': 0.019178885401419314, 'lambda_l2': 0.061887143086869614}. Best is trial 46 with value: 0.09794304097983553.\n",
      "regularization_factors, val_score: 0.097876:  45%|4| 9/20 [02:02<05:03, 27.57s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125144\tvalid_1's binary_logloss: 0.132252\n",
      "[4]\ttraining's binary_logloss: 0.115153\tvalid_1's binary_logloss: 0.125711\n",
      "[6]\ttraining's binary_logloss: 0.107736\tvalid_1's binary_logloss: 0.120881\n",
      "[8]\ttraining's binary_logloss: 0.102145\tvalid_1's binary_logloss: 0.117036\n",
      "[10]\ttraining's binary_logloss: 0.0974568\tvalid_1's binary_logloss: 0.114015\n",
      "[12]\ttraining's binary_logloss: 0.0935497\tvalid_1's binary_logloss: 0.111972\n",
      "[14]\ttraining's binary_logloss: 0.0897614\tvalid_1's binary_logloss: 0.109876\n",
      "[16]\ttraining's binary_logloss: 0.0866506\tvalid_1's binary_logloss: 0.108524\n",
      "[18]\ttraining's binary_logloss: 0.083865\tvalid_1's binary_logloss: 0.107027\n",
      "[20]\ttraining's binary_logloss: 0.0814584\tvalid_1's binary_logloss: 0.10593\n",
      "[22]\ttraining's binary_logloss: 0.0789532\tvalid_1's binary_logloss: 0.104859\n",
      "[24]\ttraining's binary_logloss: 0.0767078\tvalid_1's binary_logloss: 0.10389\n",
      "[26]\ttraining's binary_logloss: 0.0746983\tvalid_1's binary_logloss: 0.103314\n",
      "[28]\ttraining's binary_logloss: 0.0728229\tvalid_1's binary_logloss: 0.102807\n",
      "[30]\ttraining's binary_logloss: 0.0709683\tvalid_1's binary_logloss: 0.102518\n",
      "[32]\ttraining's binary_logloss: 0.0690837\tvalid_1's binary_logloss: 0.102165\n",
      "[34]\ttraining's binary_logloss: 0.0672877\tvalid_1's binary_logloss: 0.101397\n",
      "[36]\ttraining's binary_logloss: 0.0656294\tvalid_1's binary_logloss: 0.101141\n",
      "[38]\ttraining's binary_logloss: 0.0640899\tvalid_1's binary_logloss: 0.100769\n",
      "[40]\ttraining's binary_logloss: 0.0627343\tvalid_1's binary_logloss: 0.100596\n",
      "[42]\ttraining's binary_logloss: 0.0613836\tvalid_1's binary_logloss: 0.100452\n",
      "[44]\ttraining's binary_logloss: 0.0599923\tvalid_1's binary_logloss: 0.10039\n",
      "[46]\ttraining's binary_logloss: 0.0587784\tvalid_1's binary_logloss: 0.0999959\n",
      "[48]\ttraining's binary_logloss: 0.0575078\tvalid_1's binary_logloss: 0.0997777\n",
      "[50]\ttraining's binary_logloss: 0.0564582\tvalid_1's binary_logloss: 0.0996637\n",
      "[52]\ttraining's binary_logloss: 0.0554863\tvalid_1's binary_logloss: 0.0994998\n",
      "[54]\ttraining's binary_logloss: 0.0543799\tvalid_1's binary_logloss: 0.0994412\n",
      "[56]\ttraining's binary_logloss: 0.053402\tvalid_1's binary_logloss: 0.0993949\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's binary_logloss: 0.0538805\tvalid_1's binary_logloss: 0.0993219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  50%|5| 10/20 [02:09<03:34, 21.41s[I 2020-09-29 12:28:14,600] Trial 49 finished with value: 0.09932186120922946 and parameters: {'lambda_l1': 0.004514905309915543, 'lambda_l2': 8.807106618884327e-06}. Best is trial 46 with value: 0.09794304097983553.\n",
      "regularization_factors, val_score: 0.097876:  50%|5| 10/20 [02:09<03:34, 21.41s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.127024\tvalid_1's binary_logloss: 0.133058\n",
      "[4]\ttraining's binary_logloss: 0.116656\tvalid_1's binary_logloss: 0.125773\n",
      "[6]\ttraining's binary_logloss: 0.109136\tvalid_1's binary_logloss: 0.120652\n",
      "[8]\ttraining's binary_logloss: 0.103335\tvalid_1's binary_logloss: 0.116509\n",
      "[10]\ttraining's binary_logloss: 0.0986973\tvalid_1's binary_logloss: 0.113702\n",
      "[12]\ttraining's binary_logloss: 0.0947674\tvalid_1's binary_logloss: 0.111646\n",
      "[14]\ttraining's binary_logloss: 0.0912701\tvalid_1's binary_logloss: 0.109702\n",
      "[16]\ttraining's binary_logloss: 0.0881858\tvalid_1's binary_logloss: 0.108327\n",
      "[18]\ttraining's binary_logloss: 0.0856381\tvalid_1's binary_logloss: 0.107328\n",
      "[20]\ttraining's binary_logloss: 0.0829398\tvalid_1's binary_logloss: 0.106054\n",
      "[22]\ttraining's binary_logloss: 0.080505\tvalid_1's binary_logloss: 0.105088\n",
      "[24]\ttraining's binary_logloss: 0.0783982\tvalid_1's binary_logloss: 0.104387\n",
      "[26]\ttraining's binary_logloss: 0.0763994\tvalid_1's binary_logloss: 0.103575\n",
      "[28]\ttraining's binary_logloss: 0.074588\tvalid_1's binary_logloss: 0.102838\n",
      "[30]\ttraining's binary_logloss: 0.0726884\tvalid_1's binary_logloss: 0.10218\n",
      "[32]\ttraining's binary_logloss: 0.0709481\tvalid_1's binary_logloss: 0.101752\n",
      "[34]\ttraining's binary_logloss: 0.0691914\tvalid_1's binary_logloss: 0.101247\n",
      "[36]\ttraining's binary_logloss: 0.0676004\tvalid_1's binary_logloss: 0.100654\n",
      "[38]\ttraining's binary_logloss: 0.0659871\tvalid_1's binary_logloss: 0.100133\n",
      "[40]\ttraining's binary_logloss: 0.0644594\tvalid_1's binary_logloss: 0.0997489\n",
      "[42]\ttraining's binary_logloss: 0.0630971\tvalid_1's binary_logloss: 0.0995117\n",
      "[44]\ttraining's binary_logloss: 0.0619426\tvalid_1's binary_logloss: 0.0994573\n",
      "[46]\ttraining's binary_logloss: 0.0609316\tvalid_1's binary_logloss: 0.0992209\n",
      "[48]\ttraining's binary_logloss: 0.0595682\tvalid_1's binary_logloss: 0.0991073\n",
      "[50]\ttraining's binary_logloss: 0.0585238\tvalid_1's binary_logloss: 0.0988236\n",
      "[52]\ttraining's binary_logloss: 0.0574109\tvalid_1's binary_logloss: 0.0989343\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's binary_logloss: 0.0585238\tvalid_1's binary_logloss: 0.0988236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  55%|5| 11/20 [02:16<02:32, 16.95s[I 2020-09-29 12:28:21,153] Trial 50 finished with value: 0.09882355237066545 and parameters: {'lambda_l1': 3.1448145202651566e-06, 'lambda_l2': 0.1891440941526291}. Best is trial 46 with value: 0.09794304097983553.\n",
      "regularization_factors, val_score: 0.097876:  55%|5| 11/20 [02:16<02:32, 16.95s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.13336\tvalid_1's binary_logloss: 0.135703\n",
      "[4]\ttraining's binary_logloss: 0.125369\tvalid_1's binary_logloss: 0.129031\n",
      "[6]\ttraining's binary_logloss: 0.119629\tvalid_1's binary_logloss: 0.124459\n",
      "[8]\ttraining's binary_logloss: 0.115254\tvalid_1's binary_logloss: 0.120751\n",
      "[10]\ttraining's binary_logloss: 0.111725\tvalid_1's binary_logloss: 0.117813\n",
      "[12]\ttraining's binary_logloss: 0.1091\tvalid_1's binary_logloss: 0.115745\n",
      "[14]\ttraining's binary_logloss: 0.106801\tvalid_1's binary_logloss: 0.11405\n",
      "[16]\ttraining's binary_logloss: 0.104677\tvalid_1's binary_logloss: 0.112479\n",
      "[18]\ttraining's binary_logloss: 0.10322\tvalid_1's binary_logloss: 0.11148\n",
      "[20]\ttraining's binary_logloss: 0.101809\tvalid_1's binary_logloss: 0.110593\n",
      "[22]\ttraining's binary_logloss: 0.100571\tvalid_1's binary_logloss: 0.109656\n",
      "[24]\ttraining's binary_logloss: 0.0995103\tvalid_1's binary_logloss: 0.109085\n",
      "[26]\ttraining's binary_logloss: 0.0984899\tvalid_1's binary_logloss: 0.108344\n",
      "[28]\ttraining's binary_logloss: 0.097712\tvalid_1's binary_logloss: 0.107687\n",
      "[30]\ttraining's binary_logloss: 0.0967617\tvalid_1's binary_logloss: 0.107147\n",
      "[32]\ttraining's binary_logloss: 0.0958236\tvalid_1's binary_logloss: 0.10655\n",
      "[34]\ttraining's binary_logloss: 0.0951029\tvalid_1's binary_logloss: 0.106109\n",
      "[36]\ttraining's binary_logloss: 0.0944849\tvalid_1's binary_logloss: 0.1058\n",
      "[38]\ttraining's binary_logloss: 0.0939091\tvalid_1's binary_logloss: 0.10553\n",
      "[40]\ttraining's binary_logloss: 0.0930966\tvalid_1's binary_logloss: 0.105187\n",
      "[42]\ttraining's binary_logloss: 0.0924866\tvalid_1's binary_logloss: 0.104975\n",
      "[44]\ttraining's binary_logloss: 0.0917906\tvalid_1's binary_logloss: 0.104585\n",
      "[46]\ttraining's binary_logloss: 0.0912608\tvalid_1's binary_logloss: 0.104447\n",
      "[48]\ttraining's binary_logloss: 0.090763\tvalid_1's binary_logloss: 0.104218\n",
      "[50]\ttraining's binary_logloss: 0.0903983\tvalid_1's binary_logloss: 0.104027\n",
      "[52]\ttraining's binary_logloss: 0.0899085\tvalid_1's binary_logloss: 0.103826\n",
      "[54]\ttraining's binary_logloss: 0.0895667\tvalid_1's binary_logloss: 0.103724\n",
      "[56]\ttraining's binary_logloss: 0.0892328\tvalid_1's binary_logloss: 0.103502\n",
      "[58]\ttraining's binary_logloss: 0.0889318\tvalid_1's binary_logloss: 0.103362\n",
      "[60]\ttraining's binary_logloss: 0.0886453\tvalid_1's binary_logloss: 0.103127\n",
      "[62]\ttraining's binary_logloss: 0.0883072\tvalid_1's binary_logloss: 0.102917\n",
      "[64]\ttraining's binary_logloss: 0.088072\tvalid_1's binary_logloss: 0.102721\n",
      "[66]\ttraining's binary_logloss: 0.0879101\tvalid_1's binary_logloss: 0.102587\n",
      "[68]\ttraining's binary_logloss: 0.0877299\tvalid_1's binary_logloss: 0.102425\n",
      "[70]\ttraining's binary_logloss: 0.087525\tvalid_1's binary_logloss: 0.102391\n",
      "[72]\ttraining's binary_logloss: 0.0873523\tvalid_1's binary_logloss: 0.102313\n",
      "[74]\ttraining's binary_logloss: 0.0872276\tvalid_1's binary_logloss: 0.102203\n",
      "[76]\ttraining's binary_logloss: 0.0870706\tvalid_1's binary_logloss: 0.102148\n",
      "[78]\ttraining's binary_logloss: 0.0868406\tvalid_1's binary_logloss: 0.102074\n",
      "[80]\ttraining's binary_logloss: 0.0867483\tvalid_1's binary_logloss: 0.102004\n",
      "[82]\ttraining's binary_logloss: 0.086681\tvalid_1's binary_logloss: 0.101961\n",
      "[84]\ttraining's binary_logloss: 0.0865426\tvalid_1's binary_logloss: 0.101951\n",
      "[86]\ttraining's binary_logloss: 0.0864616\tvalid_1's binary_logloss: 0.101885\n",
      "[88]\ttraining's binary_logloss: 0.0864136\tvalid_1's binary_logloss: 0.101879\n",
      "[90]\ttraining's binary_logloss: 0.0863445\tvalid_1's binary_logloss: 0.101836\n",
      "[92]\ttraining's binary_logloss: 0.0862992\tvalid_1's binary_logloss: 0.101778\n",
      "[94]\ttraining's binary_logloss: 0.0862788\tvalid_1's binary_logloss: 0.101766\n",
      "[96]\ttraining's binary_logloss: 0.0862611\tvalid_1's binary_logloss: 0.101752\n",
      "[98]\ttraining's binary_logloss: 0.086052\tvalid_1's binary_logloss: 0.10169\n",
      "[100]\ttraining's binary_logloss: 0.086019\tvalid_1's binary_logloss: 0.101658\n",
      "[102]\ttraining's binary_logloss: 0.0859996\tvalid_1's binary_logloss: 0.101628\n",
      "[104]\ttraining's binary_logloss: 0.0859862\tvalid_1's binary_logloss: 0.101622\n",
      "[106]\ttraining's binary_logloss: 0.0859611\tvalid_1's binary_logloss: 0.101605\n",
      "[108]\ttraining's binary_logloss: 0.0859383\tvalid_1's binary_logloss: 0.101588\n",
      "[110]\ttraining's binary_logloss: 0.085891\tvalid_1's binary_logloss: 0.101587\n",
      "[112]\ttraining's binary_logloss: 0.085874\tvalid_1's binary_logloss: 0.101584\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's binary_logloss: 0.0858849\tvalid_1's binary_logloss: 0.101577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  60%|6| 12/20 [02:26<01:57, 14.74s[I 2020-09-29 12:28:30,742] Trial 51 finished with value: 0.10157685509794102 and parameters: {'lambda_l1': 8.398804232189052, 'lambda_l2': 0.030514763972725824}. Best is trial 46 with value: 0.09794304097983553.\n",
      "regularization_factors, val_score: 0.097876:  60%|6| 12/20 [02:26<01:57, 14.74s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125066\tvalid_1's binary_logloss: 0.13248\n",
      "[4]\ttraining's binary_logloss: 0.11474\tvalid_1's binary_logloss: 0.125314\n",
      "[6]\ttraining's binary_logloss: 0.107286\tvalid_1's binary_logloss: 0.120175\n",
      "[8]\ttraining's binary_logloss: 0.101718\tvalid_1's binary_logloss: 0.116408\n",
      "[10]\ttraining's binary_logloss: 0.0968456\tvalid_1's binary_logloss: 0.113789\n",
      "[12]\ttraining's binary_logloss: 0.0927913\tvalid_1's binary_logloss: 0.111309\n",
      "[14]\ttraining's binary_logloss: 0.0893508\tvalid_1's binary_logloss: 0.10913\n",
      "[16]\ttraining's binary_logloss: 0.0860427\tvalid_1's binary_logloss: 0.107944\n",
      "[18]\ttraining's binary_logloss: 0.0830934\tvalid_1's binary_logloss: 0.106637\n",
      "[20]\ttraining's binary_logloss: 0.0801749\tvalid_1's binary_logloss: 0.105488\n",
      "[22]\ttraining's binary_logloss: 0.0777986\tvalid_1's binary_logloss: 0.104525\n",
      "[24]\ttraining's binary_logloss: 0.0755919\tvalid_1's binary_logloss: 0.103757\n",
      "[26]\ttraining's binary_logloss: 0.0733655\tvalid_1's binary_logloss: 0.102965\n",
      "[28]\ttraining's binary_logloss: 0.0714343\tvalid_1's binary_logloss: 0.102314\n",
      "[30]\ttraining's binary_logloss: 0.0695677\tvalid_1's binary_logloss: 0.101902\n",
      "[32]\ttraining's binary_logloss: 0.067654\tvalid_1's binary_logloss: 0.101106\n",
      "[34]\ttraining's binary_logloss: 0.0658945\tvalid_1's binary_logloss: 0.100929\n",
      "[36]\ttraining's binary_logloss: 0.0642856\tvalid_1's binary_logloss: 0.100689\n",
      "[38]\ttraining's binary_logloss: 0.0625637\tvalid_1's binary_logloss: 0.100446\n",
      "[40]\ttraining's binary_logloss: 0.0611755\tvalid_1's binary_logloss: 0.100345\n",
      "[42]\ttraining's binary_logloss: 0.0597824\tvalid_1's binary_logloss: 0.0999029\n",
      "[44]\ttraining's binary_logloss: 0.0584992\tvalid_1's binary_logloss: 0.0998104\n",
      "[46]\ttraining's binary_logloss: 0.0572036\tvalid_1's binary_logloss: 0.0996118\n",
      "[48]\ttraining's binary_logloss: 0.05593\tvalid_1's binary_logloss: 0.0994541\n",
      "[50]\ttraining's binary_logloss: 0.0548299\tvalid_1's binary_logloss: 0.0993489\n",
      "[52]\ttraining's binary_logloss: 0.053836\tvalid_1's binary_logloss: 0.0992184\n",
      "[54]\ttraining's binary_logloss: 0.0526883\tvalid_1's binary_logloss: 0.0990486\n",
      "[56]\ttraining's binary_logloss: 0.0517547\tvalid_1's binary_logloss: 0.0988575\n",
      "[58]\ttraining's binary_logloss: 0.0507497\tvalid_1's binary_logloss: 0.0987052\n",
      "[60]\ttraining's binary_logloss: 0.049914\tvalid_1's binary_logloss: 0.0987287\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's binary_logloss: 0.0503687\tvalid_1's binary_logloss: 0.0986938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  65%|6| 13/20 [02:46<01:54, 16.35s[I 2020-09-29 12:28:50,849] Trial 52 finished with value: 0.09869384749093776 and parameters: {'lambda_l1': 1.0032099727965524e-08, 'lambda_l2': 3.322550524736709e-05}. Best is trial 46 with value: 0.09794304097983553.\n",
      "regularization_factors, val_score: 0.097876:  65%|6| 13/20 [02:46<01:54, 16.35s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125201\tvalid_1's binary_logloss: 0.13227\n",
      "[4]\ttraining's binary_logloss: 0.115298\tvalid_1's binary_logloss: 0.125226\n",
      "[6]\ttraining's binary_logloss: 0.107847\tvalid_1's binary_logloss: 0.120192\n",
      "[8]\ttraining's binary_logloss: 0.10215\tvalid_1's binary_logloss: 0.116207\n",
      "[10]\ttraining's binary_logloss: 0.0973857\tvalid_1's binary_logloss: 0.113468\n",
      "[12]\ttraining's binary_logloss: 0.0935043\tvalid_1's binary_logloss: 0.111106\n",
      "[14]\ttraining's binary_logloss: 0.0898317\tvalid_1's binary_logloss: 0.10937\n",
      "[16]\ttraining's binary_logloss: 0.0869342\tvalid_1's binary_logloss: 0.107903\n",
      "[18]\ttraining's binary_logloss: 0.0837854\tvalid_1's binary_logloss: 0.106557\n",
      "[20]\ttraining's binary_logloss: 0.0813398\tvalid_1's binary_logloss: 0.105282\n",
      "[22]\ttraining's binary_logloss: 0.0786718\tvalid_1's binary_logloss: 0.104497\n",
      "[24]\ttraining's binary_logloss: 0.0763369\tvalid_1's binary_logloss: 0.103418\n",
      "[26]\ttraining's binary_logloss: 0.0741976\tvalid_1's binary_logloss: 0.102442\n",
      "[28]\ttraining's binary_logloss: 0.0722204\tvalid_1's binary_logloss: 0.101739\n",
      "[30]\ttraining's binary_logloss: 0.0702116\tvalid_1's binary_logloss: 0.101461\n",
      "[32]\ttraining's binary_logloss: 0.0683747\tvalid_1's binary_logloss: 0.101217\n",
      "[34]\ttraining's binary_logloss: 0.0666721\tvalid_1's binary_logloss: 0.100651\n",
      "[36]\ttraining's binary_logloss: 0.0650104\tvalid_1's binary_logloss: 0.100193\n",
      "[38]\ttraining's binary_logloss: 0.0634056\tvalid_1's binary_logloss: 0.0999356\n",
      "[40]\ttraining's binary_logloss: 0.0621025\tvalid_1's binary_logloss: 0.0995154\n",
      "[42]\ttraining's binary_logloss: 0.060633\tvalid_1's binary_logloss: 0.0993135\n",
      "[44]\ttraining's binary_logloss: 0.0593991\tvalid_1's binary_logloss: 0.098824\n",
      "[46]\ttraining's binary_logloss: 0.0581822\tvalid_1's binary_logloss: 0.0987401\n",
      "[48]\ttraining's binary_logloss: 0.0571605\tvalid_1's binary_logloss: 0.0987113\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.0576594\tvalid_1's binary_logloss: 0.0986582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  70%|7| 14/20 [02:50<01:16, 12.70s[I 2020-09-29 12:28:55,014] Trial 53 finished with value: 0.0986581852933436 and parameters: {'lambda_l1': 0.001592069437687116, 'lambda_l2': 0.005924172672968734}. Best is trial 46 with value: 0.09794304097983553.\n",
      "regularization_factors, val_score: 0.097876:  70%|7| 14/20 [02:50<01:16, 12.70s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.131307\tvalid_1's binary_logloss: 0.134509\n",
      "[4]\ttraining's binary_logloss: 0.120988\tvalid_1's binary_logloss: 0.126322\n",
      "[6]\ttraining's binary_logloss: 0.113597\tvalid_1's binary_logloss: 0.121007\n",
      "[8]\ttraining's binary_logloss: 0.10795\tvalid_1's binary_logloss: 0.117256\n",
      "[10]\ttraining's binary_logloss: 0.103454\tvalid_1's binary_logloss: 0.114425\n",
      "[12]\ttraining's binary_logloss: 0.0996141\tvalid_1's binary_logloss: 0.112267\n",
      "[14]\ttraining's binary_logloss: 0.0963106\tvalid_1's binary_logloss: 0.110365\n",
      "[16]\ttraining's binary_logloss: 0.0934019\tvalid_1's binary_logloss: 0.108789\n",
      "[18]\ttraining's binary_logloss: 0.0908612\tvalid_1's binary_logloss: 0.107438\n",
      "[20]\ttraining's binary_logloss: 0.0885949\tvalid_1's binary_logloss: 0.106175\n",
      "[22]\ttraining's binary_logloss: 0.0864252\tvalid_1's binary_logloss: 0.105249\n",
      "[24]\ttraining's binary_logloss: 0.0844176\tvalid_1's binary_logloss: 0.104469\n",
      "[26]\ttraining's binary_logloss: 0.082543\tvalid_1's binary_logloss: 0.103699\n",
      "[28]\ttraining's binary_logloss: 0.0808212\tvalid_1's binary_logloss: 0.103143\n",
      "[30]\ttraining's binary_logloss: 0.0792334\tvalid_1's binary_logloss: 0.102613\n",
      "[32]\ttraining's binary_logloss: 0.0776731\tvalid_1's binary_logloss: 0.10241\n",
      "[34]\ttraining's binary_logloss: 0.0760455\tvalid_1's binary_logloss: 0.101754\n",
      "[36]\ttraining's binary_logloss: 0.0746382\tvalid_1's binary_logloss: 0.101433\n",
      "[38]\ttraining's binary_logloss: 0.0732201\tvalid_1's binary_logloss: 0.101259\n",
      "[40]\ttraining's binary_logloss: 0.071923\tvalid_1's binary_logloss: 0.100965\n",
      "[42]\ttraining's binary_logloss: 0.0706779\tvalid_1's binary_logloss: 0.10073\n",
      "[44]\ttraining's binary_logloss: 0.0695338\tvalid_1's binary_logloss: 0.100395\n",
      "[46]\ttraining's binary_logloss: 0.0683536\tvalid_1's binary_logloss: 0.100131\n",
      "[48]\ttraining's binary_logloss: 0.0673028\tvalid_1's binary_logloss: 0.100063\n",
      "[50]\ttraining's binary_logloss: 0.0662501\tvalid_1's binary_logloss: 0.099863\n",
      "[52]\ttraining's binary_logloss: 0.0653616\tvalid_1's binary_logloss: 0.0996287\n",
      "[54]\ttraining's binary_logloss: 0.0643577\tvalid_1's binary_logloss: 0.0994525\n",
      "[56]\ttraining's binary_logloss: 0.0634461\tvalid_1's binary_logloss: 0.0991928\n",
      "[58]\ttraining's binary_logloss: 0.0625134\tvalid_1's binary_logloss: 0.099066\n",
      "[60]\ttraining's binary_logloss: 0.061657\tvalid_1's binary_logloss: 0.0991889\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's binary_logloss: 0.0621091\tvalid_1's binary_logloss: 0.0990659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  75%|7| 15/20 [02:55<00:51, 10.38s[I 2020-09-29 12:28:59,976] Trial 54 finished with value: 0.09906593224318126 and parameters: {'lambda_l1': 1.9946675410452228e-07, 'lambda_l2': 1.2869813463093942}. Best is trial 46 with value: 0.09794304097983553.\n",
      "regularization_factors, val_score: 0.097876:  75%|7| 15/20 [02:55<00:51, 10.38s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.133261\tvalid_1's binary_logloss: 0.135785\n",
      "[4]\ttraining's binary_logloss: 0.125198\tvalid_1's binary_logloss: 0.12891\n",
      "[6]\ttraining's binary_logloss: 0.119523\tvalid_1's binary_logloss: 0.124541\n",
      "[8]\ttraining's binary_logloss: 0.11513\tvalid_1's binary_logloss: 0.120867\n",
      "[10]\ttraining's binary_logloss: 0.111845\tvalid_1's binary_logloss: 0.118212\n",
      "[12]\ttraining's binary_logloss: 0.109118\tvalid_1's binary_logloss: 0.115912\n",
      "[14]\ttraining's binary_logloss: 0.106447\tvalid_1's binary_logloss: 0.114095\n",
      "[16]\ttraining's binary_logloss: 0.104377\tvalid_1's binary_logloss: 0.11262\n",
      "[18]\ttraining's binary_logloss: 0.102754\tvalid_1's binary_logloss: 0.111382\n",
      "[20]\ttraining's binary_logloss: 0.101346\tvalid_1's binary_logloss: 0.110431\n",
      "[22]\ttraining's binary_logloss: 0.100142\tvalid_1's binary_logloss: 0.109673\n",
      "[24]\ttraining's binary_logloss: 0.0988798\tvalid_1's binary_logloss: 0.108889\n",
      "[26]\ttraining's binary_logloss: 0.0977883\tvalid_1's binary_logloss: 0.108193\n",
      "[28]\ttraining's binary_logloss: 0.0968533\tvalid_1's binary_logloss: 0.107502\n",
      "[30]\ttraining's binary_logloss: 0.0959342\tvalid_1's binary_logloss: 0.106947\n",
      "[32]\ttraining's binary_logloss: 0.0951527\tvalid_1's binary_logloss: 0.106437\n",
      "[34]\ttraining's binary_logloss: 0.0944546\tvalid_1's binary_logloss: 0.106006\n",
      "[36]\ttraining's binary_logloss: 0.0937056\tvalid_1's binary_logloss: 0.105671\n",
      "[38]\ttraining's binary_logloss: 0.093109\tvalid_1's binary_logloss: 0.105454\n",
      "[40]\ttraining's binary_logloss: 0.0924074\tvalid_1's binary_logloss: 0.105174\n",
      "[42]\ttraining's binary_logloss: 0.0917857\tvalid_1's binary_logloss: 0.104843\n",
      "[44]\ttraining's binary_logloss: 0.0911529\tvalid_1's binary_logloss: 0.104656\n",
      "[46]\ttraining's binary_logloss: 0.0905668\tvalid_1's binary_logloss: 0.104297\n",
      "[48]\ttraining's binary_logloss: 0.0901737\tvalid_1's binary_logloss: 0.104193\n",
      "[50]\ttraining's binary_logloss: 0.0898788\tvalid_1's binary_logloss: 0.104032\n",
      "[52]\ttraining's binary_logloss: 0.0895249\tvalid_1's binary_logloss: 0.103891\n",
      "[54]\ttraining's binary_logloss: 0.0891883\tvalid_1's binary_logloss: 0.103781\n",
      "[56]\ttraining's binary_logloss: 0.08889\tvalid_1's binary_logloss: 0.103552\n",
      "[58]\ttraining's binary_logloss: 0.0885641\tvalid_1's binary_logloss: 0.103391\n",
      "[60]\ttraining's binary_logloss: 0.0882861\tvalid_1's binary_logloss: 0.103273\n",
      "[62]\ttraining's binary_logloss: 0.0880576\tvalid_1's binary_logloss: 0.103042\n",
      "[64]\ttraining's binary_logloss: 0.0878486\tvalid_1's binary_logloss: 0.102882\n",
      "[66]\ttraining's binary_logloss: 0.087645\tvalid_1's binary_logloss: 0.102797\n",
      "[68]\ttraining's binary_logloss: 0.0873929\tvalid_1's binary_logloss: 0.102676\n",
      "[70]\ttraining's binary_logloss: 0.0872306\tvalid_1's binary_logloss: 0.102609\n",
      "[72]\ttraining's binary_logloss: 0.0870474\tvalid_1's binary_logloss: 0.102556\n",
      "[74]\ttraining's binary_logloss: 0.0869487\tvalid_1's binary_logloss: 0.102494\n",
      "[76]\ttraining's binary_logloss: 0.0867947\tvalid_1's binary_logloss: 0.102459\n",
      "[78]\ttraining's binary_logloss: 0.0866461\tvalid_1's binary_logloss: 0.102379\n",
      "[80]\ttraining's binary_logloss: 0.0865409\tvalid_1's binary_logloss: 0.10237\n",
      "[82]\ttraining's binary_logloss: 0.0863773\tvalid_1's binary_logloss: 0.102288\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's binary_logloss: 0.0864265\tvalid_1's binary_logloss: 0.102282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  80%|8| 16/20 [03:00<00:35,  8.98s[I 2020-09-29 12:29:05,699] Trial 55 finished with value: 0.10228173372506515 and parameters: {'lambda_l1': 8.152812304183326, 'lambda_l2': 7.220588071417069e-05}. Best is trial 46 with value: 0.09794304097983553.\n",
      "regularization_factors, val_score: 0.097876:  80%|8| 16/20 [03:01<00:35,  8.98s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.127874\tvalid_1's binary_logloss: 0.133728\n",
      "[4]\ttraining's binary_logloss: 0.117747\tvalid_1's binary_logloss: 0.126364\n",
      "[6]\ttraining's binary_logloss: 0.110097\tvalid_1's binary_logloss: 0.120954\n",
      "[8]\ttraining's binary_logloss: 0.104392\tvalid_1's binary_logloss: 0.116803\n",
      "[10]\ttraining's binary_logloss: 0.0995138\tvalid_1's binary_logloss: 0.113712\n",
      "[12]\ttraining's binary_logloss: 0.0954628\tvalid_1's binary_logloss: 0.111338\n",
      "[14]\ttraining's binary_logloss: 0.092114\tvalid_1's binary_logloss: 0.10958\n",
      "[16]\ttraining's binary_logloss: 0.0890922\tvalid_1's binary_logloss: 0.108042\n",
      "[18]\ttraining's binary_logloss: 0.0865104\tvalid_1's binary_logloss: 0.107093\n",
      "[20]\ttraining's binary_logloss: 0.0841649\tvalid_1's binary_logloss: 0.106196\n",
      "[22]\ttraining's binary_logloss: 0.0817315\tvalid_1's binary_logloss: 0.105089\n",
      "[24]\ttraining's binary_logloss: 0.079619\tvalid_1's binary_logloss: 0.10424\n",
      "[26]\ttraining's binary_logloss: 0.0777881\tvalid_1's binary_logloss: 0.10363\n",
      "[28]\ttraining's binary_logloss: 0.0759219\tvalid_1's binary_logloss: 0.10303\n",
      "[30]\ttraining's binary_logloss: 0.0741319\tvalid_1's binary_logloss: 0.102562\n",
      "[32]\ttraining's binary_logloss: 0.0722864\tvalid_1's binary_logloss: 0.101924\n",
      "[34]\ttraining's binary_logloss: 0.0705414\tvalid_1's binary_logloss: 0.101279\n",
      "[36]\ttraining's binary_logloss: 0.0690409\tvalid_1's binary_logloss: 0.100916\n",
      "[38]\ttraining's binary_logloss: 0.0675779\tvalid_1's binary_logloss: 0.100533\n",
      "[40]\ttraining's binary_logloss: 0.0661902\tvalid_1's binary_logloss: 0.100238\n",
      "[42]\ttraining's binary_logloss: 0.0647452\tvalid_1's binary_logloss: 0.099996\n",
      "[44]\ttraining's binary_logloss: 0.0635451\tvalid_1's binary_logloss: 0.0998498\n",
      "[46]\ttraining's binary_logloss: 0.0622927\tvalid_1's binary_logloss: 0.099668\n",
      "[48]\ttraining's binary_logloss: 0.0612156\tvalid_1's binary_logloss: 0.0995857\n",
      "[50]\ttraining's binary_logloss: 0.0602445\tvalid_1's binary_logloss: 0.099613\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's binary_logloss: 0.0607127\tvalid_1's binary_logloss: 0.099562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  85%|8| 17/20 [03:05<00:22,  7.56s[I 2020-09-29 12:29:09,937] Trial 56 finished with value: 0.09956204114898483 and parameters: {'lambda_l1': 5.121506423753138e-05, 'lambda_l2': 0.3342718897721057}. Best is trial 46 with value: 0.09794304097983553.\n",
      "regularization_factors, val_score: 0.097876:  85%|8| 17/20 [03:05<00:22,  7.56s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125467\tvalid_1's binary_logloss: 0.132014\n",
      "[4]\ttraining's binary_logloss: 0.115516\tvalid_1's binary_logloss: 0.125087\n",
      "[6]\ttraining's binary_logloss: 0.108236\tvalid_1's binary_logloss: 0.120104\n",
      "[8]\ttraining's binary_logloss: 0.102774\tvalid_1's binary_logloss: 0.116469\n",
      "[10]\ttraining's binary_logloss: 0.0982493\tvalid_1's binary_logloss: 0.113627\n",
      "[12]\ttraining's binary_logloss: 0.0943916\tvalid_1's binary_logloss: 0.111217\n",
      "[14]\ttraining's binary_logloss: 0.0910393\tvalid_1's binary_logloss: 0.109719\n",
      "[16]\ttraining's binary_logloss: 0.0879557\tvalid_1's binary_logloss: 0.108272\n",
      "[18]\ttraining's binary_logloss: 0.0852744\tvalid_1's binary_logloss: 0.106717\n",
      "[20]\ttraining's binary_logloss: 0.0826703\tvalid_1's binary_logloss: 0.106003\n",
      "[22]\ttraining's binary_logloss: 0.0804349\tvalid_1's binary_logloss: 0.104943\n",
      "[24]\ttraining's binary_logloss: 0.0783438\tvalid_1's binary_logloss: 0.103834\n",
      "[26]\ttraining's binary_logloss: 0.076256\tvalid_1's binary_logloss: 0.102895\n",
      "[28]\ttraining's binary_logloss: 0.074414\tvalid_1's binary_logloss: 0.102226\n",
      "[30]\ttraining's binary_logloss: 0.0723319\tvalid_1's binary_logloss: 0.101869\n",
      "[32]\ttraining's binary_logloss: 0.0707278\tvalid_1's binary_logloss: 0.101294\n",
      "[34]\ttraining's binary_logloss: 0.0690852\tvalid_1's binary_logloss: 0.101348\n",
      "[36]\ttraining's binary_logloss: 0.0672395\tvalid_1's binary_logloss: 0.100965\n",
      "[38]\ttraining's binary_logloss: 0.065662\tvalid_1's binary_logloss: 0.100798\n",
      "[40]\ttraining's binary_logloss: 0.0643148\tvalid_1's binary_logloss: 0.100618\n",
      "[42]\ttraining's binary_logloss: 0.0629985\tvalid_1's binary_logloss: 0.100432\n",
      "[44]\ttraining's binary_logloss: 0.061792\tvalid_1's binary_logloss: 0.100199\n",
      "[46]\ttraining's binary_logloss: 0.0605613\tvalid_1's binary_logloss: 0.100057\n",
      "[48]\ttraining's binary_logloss: 0.0595284\tvalid_1's binary_logloss: 0.0999022\n",
      "[50]\ttraining's binary_logloss: 0.0582633\tvalid_1's binary_logloss: 0.0997907\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's binary_logloss: 0.0589019\tvalid_1's binary_logloss: 0.0997607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  90%|9| 18/20 [03:09<00:13,  6.50s[I 2020-09-29 12:29:13,982] Trial 57 finished with value: 0.09976066264994128 and parameters: {'lambda_l1': 0.12692206094565636, 'lambda_l2': 0.006467798772157317}. Best is trial 46 with value: 0.09794304097983553.\n",
      "regularization_factors, val_score: 0.097876:  90%|9| 18/20 [03:09<00:13,  6.50s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125066\tvalid_1's binary_logloss: 0.13248\n",
      "[4]\ttraining's binary_logloss: 0.11474\tvalid_1's binary_logloss: 0.125314\n",
      "[6]\ttraining's binary_logloss: 0.107286\tvalid_1's binary_logloss: 0.120175\n",
      "[8]\ttraining's binary_logloss: 0.101718\tvalid_1's binary_logloss: 0.116408\n",
      "[10]\ttraining's binary_logloss: 0.0968453\tvalid_1's binary_logloss: 0.113789\n",
      "[12]\ttraining's binary_logloss: 0.092791\tvalid_1's binary_logloss: 0.111309\n",
      "[14]\ttraining's binary_logloss: 0.0893506\tvalid_1's binary_logloss: 0.10913\n",
      "[16]\ttraining's binary_logloss: 0.0860424\tvalid_1's binary_logloss: 0.107944\n",
      "[18]\ttraining's binary_logloss: 0.0830931\tvalid_1's binary_logloss: 0.106637\n",
      "[20]\ttraining's binary_logloss: 0.0801746\tvalid_1's binary_logloss: 0.105488\n",
      "[22]\ttraining's binary_logloss: 0.0777982\tvalid_1's binary_logloss: 0.104525\n",
      "[24]\ttraining's binary_logloss: 0.0755916\tvalid_1's binary_logloss: 0.103757\n",
      "[26]\ttraining's binary_logloss: 0.0733651\tvalid_1's binary_logloss: 0.102965\n",
      "[28]\ttraining's binary_logloss: 0.0714339\tvalid_1's binary_logloss: 0.102314\n",
      "[30]\ttraining's binary_logloss: 0.0695673\tvalid_1's binary_logloss: 0.101902\n",
      "[32]\ttraining's binary_logloss: 0.0676542\tvalid_1's binary_logloss: 0.101106\n",
      "[34]\ttraining's binary_logloss: 0.0658947\tvalid_1's binary_logloss: 0.100928\n",
      "[36]\ttraining's binary_logloss: 0.0642857\tvalid_1's binary_logloss: 0.100688\n",
      "[38]\ttraining's binary_logloss: 0.0625637\tvalid_1's binary_logloss: 0.100445\n",
      "[40]\ttraining's binary_logloss: 0.0611755\tvalid_1's binary_logloss: 0.100344\n",
      "[42]\ttraining's binary_logloss: 0.0597824\tvalid_1's binary_logloss: 0.099902\n",
      "[44]\ttraining's binary_logloss: 0.0584947\tvalid_1's binary_logloss: 0.0998118\n",
      "[46]\ttraining's binary_logloss: 0.0571989\tvalid_1's binary_logloss: 0.099613\n",
      "[48]\ttraining's binary_logloss: 0.0559145\tvalid_1's binary_logloss: 0.0994714\n",
      "[50]\ttraining's binary_logloss: 0.0547733\tvalid_1's binary_logloss: 0.0993976\n",
      "[52]\ttraining's binary_logloss: 0.0537902\tvalid_1's binary_logloss: 0.0994109\n",
      "[54]\ttraining's binary_logloss: 0.0526737\tvalid_1's binary_logloss: 0.0990986\n",
      "[56]\ttraining's binary_logloss: 0.0516911\tvalid_1's binary_logloss: 0.099189\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.0526737\tvalid_1's binary_logloss: 0.0990986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876:  95%|9| 19/20 [03:13<00:05,  5.96s[I 2020-09-29 12:29:18,686] Trial 58 finished with value: 0.09909859183860237 and parameters: {'lambda_l1': 6.493920531668089e-07, 'lambda_l2': 2.4704634183320818e-06}. Best is trial 46 with value: 0.09794304097983553.\n",
      "regularization_factors, val_score: 0.097876:  95%|9| 19/20 [03:14<00:05,  5.96s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125075\tvalid_1's binary_logloss: 0.132509\n",
      "[4]\ttraining's binary_logloss: 0.114927\tvalid_1's binary_logloss: 0.125308\n",
      "[6]\ttraining's binary_logloss: 0.107606\tvalid_1's binary_logloss: 0.120419\n",
      "[8]\ttraining's binary_logloss: 0.102044\tvalid_1's binary_logloss: 0.11622\n",
      "[10]\ttraining's binary_logloss: 0.0974904\tvalid_1's binary_logloss: 0.113046\n",
      "[12]\ttraining's binary_logloss: 0.0935906\tvalid_1's binary_logloss: 0.111012\n",
      "[14]\ttraining's binary_logloss: 0.0898288\tvalid_1's binary_logloss: 0.108755\n",
      "[16]\ttraining's binary_logloss: 0.0868196\tvalid_1's binary_logloss: 0.107167\n",
      "[18]\ttraining's binary_logloss: 0.0840447\tvalid_1's binary_logloss: 0.10599\n",
      "[20]\ttraining's binary_logloss: 0.0817944\tvalid_1's binary_logloss: 0.105097\n",
      "[22]\ttraining's binary_logloss: 0.0790312\tvalid_1's binary_logloss: 0.104452\n",
      "[24]\ttraining's binary_logloss: 0.0767377\tvalid_1's binary_logloss: 0.103638\n",
      "[26]\ttraining's binary_logloss: 0.0747304\tvalid_1's binary_logloss: 0.102711\n",
      "[28]\ttraining's binary_logloss: 0.0727724\tvalid_1's binary_logloss: 0.102308\n",
      "[30]\ttraining's binary_logloss: 0.0708408\tvalid_1's binary_logloss: 0.101668\n",
      "[32]\ttraining's binary_logloss: 0.0687629\tvalid_1's binary_logloss: 0.101427\n",
      "[34]\ttraining's binary_logloss: 0.0670611\tvalid_1's binary_logloss: 0.10088\n",
      "[36]\ttraining's binary_logloss: 0.0653228\tvalid_1's binary_logloss: 0.100273\n",
      "[38]\ttraining's binary_logloss: 0.0636955\tvalid_1's binary_logloss: 0.0999455\n",
      "[40]\ttraining's binary_logloss: 0.0621331\tvalid_1's binary_logloss: 0.0995333\n",
      "[42]\ttraining's binary_logloss: 0.0607017\tvalid_1's binary_logloss: 0.0991851\n",
      "[44]\ttraining's binary_logloss: 0.0593078\tvalid_1's binary_logloss: 0.0990653\n",
      "[46]\ttraining's binary_logloss: 0.057934\tvalid_1's binary_logloss: 0.0988695\n",
      "[48]\ttraining's binary_logloss: 0.0568305\tvalid_1's binary_logloss: 0.098724\n",
      "[50]\ttraining's binary_logloss: 0.0557276\tvalid_1's binary_logloss: 0.0985807\n",
      "[52]\ttraining's binary_logloss: 0.0547466\tvalid_1's binary_logloss: 0.0982393\n",
      "[54]\ttraining's binary_logloss: 0.0536836\tvalid_1's binary_logloss: 0.0981642\n",
      "[56]\ttraining's binary_logloss: 0.0527189\tvalid_1's binary_logloss: 0.098061\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's binary_logloss: 0.0531946\tvalid_1's binary_logloss: 0.0980087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.097876: 100%|#| 20/20 [03:18<00:00,  5.59s[I 2020-09-29 12:29:23,411] Trial 59 finished with value: 0.09800874301474594 and parameters: {'lambda_l1': 0.001032125592700823, 'lambda_l2': 0.0002400204721314187}. Best is trial 46 with value: 0.09794304097983553.\n",
      "regularization_factors, val_score: 0.097876: 100%|#| 20/20 [03:18<00:00,  9.94s\n",
      "min_data_in_leaf, val_score: 0.097876:   0%|             | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.123058\tvalid_1's binary_logloss: 0.132617\n",
      "[4]\ttraining's binary_logloss: 0.111578\tvalid_1's binary_logloss: 0.125493\n",
      "[6]\ttraining's binary_logloss: 0.103753\tvalid_1's binary_logloss: 0.120374\n",
      "[8]\ttraining's binary_logloss: 0.0973186\tvalid_1's binary_logloss: 0.116467\n",
      "[10]\ttraining's binary_logloss: 0.0922235\tvalid_1's binary_logloss: 0.114664\n",
      "[12]\ttraining's binary_logloss: 0.0881541\tvalid_1's binary_logloss: 0.11246\n",
      "[14]\ttraining's binary_logloss: 0.0848678\tvalid_1's binary_logloss: 0.111244\n",
      "[16]\ttraining's binary_logloss: 0.08148\tvalid_1's binary_logloss: 0.109497\n",
      "[18]\ttraining's binary_logloss: 0.0783387\tvalid_1's binary_logloss: 0.108299\n",
      "[20]\ttraining's binary_logloss: 0.0744993\tvalid_1's binary_logloss: 0.107539\n",
      "[22]\ttraining's binary_logloss: 0.0718149\tvalid_1's binary_logloss: 0.106561\n",
      "[24]\ttraining's binary_logloss: 0.0694303\tvalid_1's binary_logloss: 0.105686\n",
      "[26]\ttraining's binary_logloss: 0.0673013\tvalid_1's binary_logloss: 0.10474\n",
      "[28]\ttraining's binary_logloss: 0.0647522\tvalid_1's binary_logloss: 0.104381\n",
      "[30]\ttraining's binary_logloss: 0.0628459\tvalid_1's binary_logloss: 0.103494\n",
      "[32]\ttraining's binary_logloss: 0.061094\tvalid_1's binary_logloss: 0.103046\n",
      "[34]\ttraining's binary_logloss: 0.059212\tvalid_1's binary_logloss: 0.102784\n",
      "[36]\ttraining's binary_logloss: 0.0574608\tvalid_1's binary_logloss: 0.102422\n",
      "[38]\ttraining's binary_logloss: 0.0559492\tvalid_1's binary_logloss: 0.10211\n",
      "[40]\ttraining's binary_logloss: 0.0545239\tvalid_1's binary_logloss: 0.101697\n",
      "[42]\ttraining's binary_logloss: 0.0531609\tvalid_1's binary_logloss: 0.101189\n",
      "[44]\ttraining's binary_logloss: 0.0515316\tvalid_1's binary_logloss: 0.101019\n",
      "[46]\ttraining's binary_logloss: 0.0502041\tvalid_1's binary_logloss: 0.100635\n",
      "[48]\ttraining's binary_logloss: 0.0490258\tvalid_1's binary_logloss: 0.100564\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.0496108\tvalid_1's binary_logloss: 0.100512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.097876:  20%|#    | 1/5 [00:04<00:17,  4.36s/it][I 2020-09-29 12:29:27,814] Trial 60 finished with value: 0.10051188105624766 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.10051188105624766.\n",
      "min_data_in_leaf, val_score: 0.097876:  20%|#    | 1/5 [00:04<00:17,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.123951\tvalid_1's binary_logloss: 0.131977\n",
      "[4]\ttraining's binary_logloss: 0.113749\tvalid_1's binary_logloss: 0.124974\n",
      "[6]\ttraining's binary_logloss: 0.105941\tvalid_1's binary_logloss: 0.120041\n",
      "[8]\ttraining's binary_logloss: 0.100164\tvalid_1's binary_logloss: 0.116292\n",
      "[10]\ttraining's binary_logloss: 0.0953134\tvalid_1's binary_logloss: 0.1135\n",
      "[12]\ttraining's binary_logloss: 0.091087\tvalid_1's binary_logloss: 0.111429\n",
      "[14]\ttraining's binary_logloss: 0.0874122\tvalid_1's binary_logloss: 0.109584\n",
      "[16]\ttraining's binary_logloss: 0.0842794\tvalid_1's binary_logloss: 0.108244\n",
      "[18]\ttraining's binary_logloss: 0.0812891\tvalid_1's binary_logloss: 0.106885\n",
      "[20]\ttraining's binary_logloss: 0.0779553\tvalid_1's binary_logloss: 0.105835\n",
      "[22]\ttraining's binary_logloss: 0.075427\tvalid_1's binary_logloss: 0.105236\n",
      "[24]\ttraining's binary_logloss: 0.0731012\tvalid_1's binary_logloss: 0.104244\n",
      "[26]\ttraining's binary_logloss: 0.0709165\tvalid_1's binary_logloss: 0.10385\n",
      "[28]\ttraining's binary_logloss: 0.068966\tvalid_1's binary_logloss: 0.103304\n",
      "[30]\ttraining's binary_logloss: 0.067078\tvalid_1's binary_logloss: 0.102776\n",
      "[32]\ttraining's binary_logloss: 0.0650697\tvalid_1's binary_logloss: 0.10233\n",
      "[34]\ttraining's binary_logloss: 0.0630117\tvalid_1's binary_logloss: 0.102257\n",
      "[36]\ttraining's binary_logloss: 0.0614661\tvalid_1's binary_logloss: 0.101772\n",
      "[38]\ttraining's binary_logloss: 0.0598692\tvalid_1's binary_logloss: 0.101405\n",
      "[40]\ttraining's binary_logloss: 0.0584314\tvalid_1's binary_logloss: 0.101266\n",
      "[42]\ttraining's binary_logloss: 0.0569891\tvalid_1's binary_logloss: 0.101138\n",
      "[44]\ttraining's binary_logloss: 0.0555804\tvalid_1's binary_logloss: 0.101011\n",
      "[46]\ttraining's binary_logloss: 0.0543146\tvalid_1's binary_logloss: 0.100898\n",
      "[48]\ttraining's binary_logloss: 0.0530906\tvalid_1's binary_logloss: 0.100642\n",
      "[50]\ttraining's binary_logloss: 0.0520415\tvalid_1's binary_logloss: 0.100432\n",
      "[52]\ttraining's binary_logloss: 0.0509847\tvalid_1's binary_logloss: 0.100399\n",
      "[54]\ttraining's binary_logloss: 0.0500063\tvalid_1's binary_logloss: 0.100193\n",
      "[56]\ttraining's binary_logloss: 0.0489045\tvalid_1's binary_logloss: 0.0999426\n",
      "[58]\ttraining's binary_logloss: 0.0480384\tvalid_1's binary_logloss: 0.100034\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.0489045\tvalid_1's binary_logloss: 0.0999426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.097876:  40%|##   | 2/5 [00:09<00:13,  4.54s/it][I 2020-09-29 12:29:32,774] Trial 61 finished with value: 0.0999425751979435 and parameters: {'min_child_samples': 10}. Best is trial 61 with value: 0.0999425751979435.\n",
      "min_data_in_leaf, val_score: 0.097876:  40%|##   | 2/5 [00:09<00:13,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.127473\tvalid_1's binary_logloss: 0.132543\n",
      "[4]\ttraining's binary_logloss: 0.1177\tvalid_1's binary_logloss: 0.124986\n",
      "[6]\ttraining's binary_logloss: 0.110658\tvalid_1's binary_logloss: 0.120246\n",
      "[8]\ttraining's binary_logloss: 0.104976\tvalid_1's binary_logloss: 0.116477\n",
      "[10]\ttraining's binary_logloss: 0.100455\tvalid_1's binary_logloss: 0.113499\n",
      "[12]\ttraining's binary_logloss: 0.0966209\tvalid_1's binary_logloss: 0.111353\n",
      "[14]\ttraining's binary_logloss: 0.0935308\tvalid_1's binary_logloss: 0.109274\n",
      "[16]\ttraining's binary_logloss: 0.0907091\tvalid_1's binary_logloss: 0.107768\n",
      "[18]\ttraining's binary_logloss: 0.0880341\tvalid_1's binary_logloss: 0.106702\n",
      "[20]\ttraining's binary_logloss: 0.0855176\tvalid_1's binary_logloss: 0.105675\n",
      "[22]\ttraining's binary_logloss: 0.0832278\tvalid_1's binary_logloss: 0.104615\n",
      "[24]\ttraining's binary_logloss: 0.0811442\tvalid_1's binary_logloss: 0.103665\n",
      "[26]\ttraining's binary_logloss: 0.0791241\tvalid_1's binary_logloss: 0.102723\n",
      "[28]\ttraining's binary_logloss: 0.0772292\tvalid_1's binary_logloss: 0.102103\n",
      "[30]\ttraining's binary_logloss: 0.0752484\tvalid_1's binary_logloss: 0.101649\n",
      "[32]\ttraining's binary_logloss: 0.0733371\tvalid_1's binary_logloss: 0.101039\n",
      "[34]\ttraining's binary_logloss: 0.0716608\tvalid_1's binary_logloss: 0.100702\n",
      "[36]\ttraining's binary_logloss: 0.0698826\tvalid_1's binary_logloss: 0.100231\n",
      "[38]\ttraining's binary_logloss: 0.0684107\tvalid_1's binary_logloss: 0.0998698\n",
      "[40]\ttraining's binary_logloss: 0.0670026\tvalid_1's binary_logloss: 0.099554\n",
      "[42]\ttraining's binary_logloss: 0.0657584\tvalid_1's binary_logloss: 0.0993255\n",
      "[44]\ttraining's binary_logloss: 0.064504\tvalid_1's binary_logloss: 0.09892\n",
      "[46]\ttraining's binary_logloss: 0.0633598\tvalid_1's binary_logloss: 0.0987111\n",
      "[48]\ttraining's binary_logloss: 0.0622541\tvalid_1's binary_logloss: 0.098726\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.0627859\tvalid_1's binary_logloss: 0.0986721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.097876:  60%|###  | 3/5 [00:13<00:08,  4.47s/it][I 2020-09-29 12:29:37,069] Trial 62 finished with value: 0.09867208263129111 and parameters: {'min_child_samples': 50}. Best is trial 62 with value: 0.09867208263129111.\n",
      "min_data_in_leaf, val_score: 0.097876:  60%|###  | 3/5 [00:13<00:08,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.131208\tvalid_1's binary_logloss: 0.133583\n",
      "[4]\ttraining's binary_logloss: 0.121463\tvalid_1's binary_logloss: 0.126089\n",
      "[6]\ttraining's binary_logloss: 0.114351\tvalid_1's binary_logloss: 0.120876\n",
      "[8]\ttraining's binary_logloss: 0.109012\tvalid_1's binary_logloss: 0.117184\n",
      "[10]\ttraining's binary_logloss: 0.104338\tvalid_1's binary_logloss: 0.114256\n",
      "[12]\ttraining's binary_logloss: 0.100616\tvalid_1's binary_logloss: 0.111891\n",
      "[14]\ttraining's binary_logloss: 0.0973492\tvalid_1's binary_logloss: 0.110054\n",
      "[16]\ttraining's binary_logloss: 0.0944917\tvalid_1's binary_logloss: 0.108451\n",
      "[18]\ttraining's binary_logloss: 0.0919122\tvalid_1's binary_logloss: 0.107553\n",
      "[20]\ttraining's binary_logloss: 0.08937\tvalid_1's binary_logloss: 0.106504\n",
      "[22]\ttraining's binary_logloss: 0.0871536\tvalid_1's binary_logloss: 0.105615\n",
      "[24]\ttraining's binary_logloss: 0.0850061\tvalid_1's binary_logloss: 0.104845\n",
      "[26]\ttraining's binary_logloss: 0.083045\tvalid_1's binary_logloss: 0.104105\n",
      "[28]\ttraining's binary_logloss: 0.0811714\tvalid_1's binary_logloss: 0.103449\n",
      "[30]\ttraining's binary_logloss: 0.0794164\tvalid_1's binary_logloss: 0.102963\n",
      "[32]\ttraining's binary_logloss: 0.0777423\tvalid_1's binary_logloss: 0.102694\n",
      "[34]\ttraining's binary_logloss: 0.0761069\tvalid_1's binary_logloss: 0.102158\n",
      "[36]\ttraining's binary_logloss: 0.0744313\tvalid_1's binary_logloss: 0.101503\n",
      "[38]\ttraining's binary_logloss: 0.0728617\tvalid_1's binary_logloss: 0.101459\n",
      "[40]\ttraining's binary_logloss: 0.0715179\tvalid_1's binary_logloss: 0.101372\n",
      "[42]\ttraining's binary_logloss: 0.0700758\tvalid_1's binary_logloss: 0.101049\n",
      "[44]\ttraining's binary_logloss: 0.0687253\tvalid_1's binary_logloss: 0.100771\n",
      "[46]\ttraining's binary_logloss: 0.0674769\tvalid_1's binary_logloss: 0.100365\n",
      "[48]\ttraining's binary_logloss: 0.0662663\tvalid_1's binary_logloss: 0.100136\n",
      "[50]\ttraining's binary_logloss: 0.0651812\tvalid_1's binary_logloss: 0.100061\n",
      "[52]\ttraining's binary_logloss: 0.064121\tvalid_1's binary_logloss: 0.100063\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's binary_logloss: 0.0651812\tvalid_1's binary_logloss: 0.100061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.097876:  80%|#### | 4/5 [00:18<00:04,  4.64s/it][I 2020-09-29 12:29:42,099] Trial 63 finished with value: 0.10006133871283734 and parameters: {'min_child_samples': 100}. Best is trial 62 with value: 0.09867208263129111.\n",
      "min_data_in_leaf, val_score: 0.097876:  80%|#### | 4/5 [00:18<00:04,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2 rounds\n",
      "[2]\ttraining's binary_logloss: 0.125856\tvalid_1's binary_logloss: 0.132588\n",
      "[4]\ttraining's binary_logloss: 0.115559\tvalid_1's binary_logloss: 0.125634\n",
      "[6]\ttraining's binary_logloss: 0.108173\tvalid_1's binary_logloss: 0.120597\n",
      "[8]\ttraining's binary_logloss: 0.102398\tvalid_1's binary_logloss: 0.117125\n",
      "[10]\ttraining's binary_logloss: 0.0978028\tvalid_1's binary_logloss: 0.114099\n",
      "[12]\ttraining's binary_logloss: 0.0938309\tvalid_1's binary_logloss: 0.112253\n",
      "[14]\ttraining's binary_logloss: 0.0902224\tvalid_1's binary_logloss: 0.110023\n",
      "[16]\ttraining's binary_logloss: 0.0871051\tvalid_1's binary_logloss: 0.108317\n",
      "[18]\ttraining's binary_logloss: 0.0843899\tvalid_1's binary_logloss: 0.107233\n",
      "[20]\ttraining's binary_logloss: 0.0818646\tvalid_1's binary_logloss: 0.10632\n",
      "[22]\ttraining's binary_logloss: 0.079168\tvalid_1's binary_logloss: 0.105147\n",
      "[24]\ttraining's binary_logloss: 0.0769965\tvalid_1's binary_logloss: 0.1045\n",
      "[26]\ttraining's binary_logloss: 0.0748039\tvalid_1's binary_logloss: 0.103962\n",
      "[28]\ttraining's binary_logloss: 0.0729106\tvalid_1's binary_logloss: 0.103419\n",
      "[30]\ttraining's binary_logloss: 0.0709545\tvalid_1's binary_logloss: 0.10293\n",
      "[32]\ttraining's binary_logloss: 0.0691307\tvalid_1's binary_logloss: 0.102456\n",
      "[34]\ttraining's binary_logloss: 0.067392\tvalid_1's binary_logloss: 0.102065\n",
      "[36]\ttraining's binary_logloss: 0.0655334\tvalid_1's binary_logloss: 0.101588\n",
      "[38]\ttraining's binary_logloss: 0.0640433\tvalid_1's binary_logloss: 0.101467\n",
      "[40]\ttraining's binary_logloss: 0.0627114\tvalid_1's binary_logloss: 0.101339\n",
      "[42]\ttraining's binary_logloss: 0.061231\tvalid_1's binary_logloss: 0.100968\n",
      "[44]\ttraining's binary_logloss: 0.0598743\tvalid_1's binary_logloss: 0.100821\n",
      "[46]\ttraining's binary_logloss: 0.0586104\tvalid_1's binary_logloss: 0.100534\n",
      "[48]\ttraining's binary_logloss: 0.0573653\tvalid_1's binary_logloss: 0.100108\n",
      "[50]\ttraining's binary_logloss: 0.0563339\tvalid_1's binary_logloss: 0.100086\n",
      "[52]\ttraining's binary_logloss: 0.0551372\tvalid_1's binary_logloss: 0.100041\n",
      "[54]\ttraining's binary_logloss: 0.0542108\tvalid_1's binary_logloss: 0.0999215\n",
      "[56]\ttraining's binary_logloss: 0.0532358\tvalid_1's binary_logloss: 0.0997703\n",
      "[58]\ttraining's binary_logloss: 0.0522438\tvalid_1's binary_logloss: 0.0997744\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.0532358\tvalid_1's binary_logloss: 0.0997703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.097876: 100%|#####| 5/5 [00:23<00:00,  4.84s/it][I 2020-09-29 12:29:47,399] Trial 64 finished with value: 0.09977029018787513 and parameters: {'min_child_samples': 25}. Best is trial 62 with value: 0.09867208263129111.\n",
      "min_data_in_leaf, val_score: 0.097876: 100%|#####| 5/5 [00:23<00:00,  4.79s/it]\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "    }\n",
    "\n",
    "model = lgb.train(\n",
    "        params, dtrain, valid_sets=[dtrain, dval], verbose_eval=2, early_stopping_rounds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'feature_pre_filter': False, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'num_leaves': 54, 'feature_fraction': 1.0, 'bagging_fraction': 0.9932402489103072, 'bagging_freq': 4, 'min_child_samples': 20}\n",
      "  Accuracy = 0.972002799720028\n",
      "  Params: \n"
     ]
    }
   ],
   "source": [
    "prediction = np.rint(model.predict(x_valid, num_iteration=model.best_iteration))\n",
    "accuracy = accuracy_score(y_valid, prediction)\n",
    "\n",
    "best_params = model.params\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"  Accuracy = {}\".format(accuracy))\n",
    "print(\"  Params: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.6492644774869676\n",
      "Accuracy Score : 0.972002799720028\n",
      "precision : 0.8345864661654135\n",
      "recall : 0.3008130081300813\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_valid, prediction)\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, prediction)\n",
    "\n",
    "print('AUC :',metrics.auc(fpr, tpr)) \n",
    "print('Accuracy Score :',accuracy_score(y_valid, prediction)) \n",
    "print('precision :',precision[1]) \n",
    "print('recall :',recall[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[9610   22]\n",
      " [ 258  111]]\n"
     ]
    }
   ],
   "source": [
    "results = confusion_matrix(y_valid, prediction) \n",
    "\n",
    "print('Confusion Matrix :')\n",
    "print(results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=1.0, bagging_freq=0,\n",
       "               feature_fraction=0.8999999999999999, feature_pre_filter=False,\n",
       "               lambda_l1=1.1223456089014623e-08,\n",
       "               lambda_l2=1.447432290967618e-08, metric='binary_logloss',\n",
       "               objective='binary', verbosity=-1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_n = LGBMClassifier(objective= 'binary', metric= 'binary_logloss', verbosity= -1, boosting_type= 'gbdt',\n",
    "                       feature_pre_filter= False, lambda_l1= 1.1223456089014623e-08, \n",
    "                       lambda_l2= 1.447432290967618e-08, num_leaves= 31, feature_fraction= 0.8999999999999999,\n",
    "                       bagging_fraction= 1.0, bagging_freq = 0,min_child_samples= 20)\n",
    "model_n.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litraincolOrg[model_n.feature_importances_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi=pd.DataFrame({'cols' : litraincolOrg, 'imp' : model_n.feature_importances_})\n",
    "fi = fi.sort_values('imp', ascending=False)\n",
    "top_50 = fi[0:50]\n",
    "top_50 = top_50.sort_values('imp', ascending=True)\n",
    "# Plot the bar chart\n",
    "top_50.plot(x='cols', kind='barh' , figsize=(15,18))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reducing stopping rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-160896283324>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best params:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "prediction = np.rint(model2.predict(x_valid, num_iteration=model2.best_iteration))\n",
    "accuracy = accuracy_score(y_valid, prediction)\n",
    "\n",
    "best_params = model2.params\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"  Accuracy = {}\".format(accuracy))\n",
    "print(\"  Params: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.9880932286085656, bagging_freq=7,\n",
       "               feature_fraction=0.8999999999999999, feature_pre_filter=False,\n",
       "               lambda_l1=2.7445577876565753e-06,\n",
       "               lambda_l2=1.0515291002147425e-06, metric='binary_logloss',\n",
       "               objective='binary', verbosity=-1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_n2 = LGBMClassifier(objective= 'binary', metric= 'binary_logloss', verbosity= -1, boosting_type= 'gbdt',\n",
    "                         feature_pre_filter= False, lambda_l1= 2.7445577876565753e-06, lambda_l2= 1.0515291002147425e-06, num_leaves= 31, feature_fraction= 0.8999999999999999, bagging_fraction= 0.9880932286085656, bagging_freq= 7, min_child_samples= 20)\n",
    "model_n2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1296 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fi=pd.DataFrame({'cols' : litraincolOrg, 'imp' : model_n2.feature_importances_})\n",
    "fi = fi.sort_values('imp', ascending=False)\n",
    "top_50 = fi[0:50]\n",
    "top_50 = top_50.sort_values('imp', ascending=True)\n",
    "# Plot the bar chart\n",
    "top_50.plot(x='cols', kind='barh' , figsize=(15,18))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_sklearn(truth, predictions):\n",
    "    return gini(truth, predictions) / gini(truth, truth)\n",
    "\n",
    "gini_scorer = make_scorer(gini_sklearn, greater_is_better=True, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(truth, predictions):\n",
    "    g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
    "    g = g[np.lexsort((g[:,2], -1*g[:,1]))]\n",
    "    gs = g[:,0].cumsum().sum() / g[:,0].sum()\n",
    "    gs -= (len(truth) + 1) / 2.\n",
    "    return gs / len(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini 0.709 params {'num_leaves': 126, 'colsample_bytree': '0.511', 'feature_fraction': '0.542', 'min_child_samples': 48, 'learning_rate': '0.274', 'max_depth': 2, 'scale_pos_weight': '0.222', 'min_child_weight': '0.257', 'subsample_for_bin': 26290}\n",
      "Gini 0.691 params {'num_leaves': 46, 'colsample_bytree': '0.606', 'feature_fraction': '0.592', 'min_child_samples': 124, 'learning_rate': '0.586', 'max_depth': 4, 'scale_pos_weight': '0.614', 'min_child_weight': '0.719', 'subsample_for_bin': 22100}\n",
      "Gini 0.667 params {'num_leaves': 64, 'colsample_bytree': '0.867', 'feature_fraction': '0.548', 'min_child_samples': 104, 'learning_rate': '0.801', 'max_depth': 4, 'scale_pos_weight': '0.392', 'min_child_weight': '0.504', 'subsample_for_bin': 1870}\n",
      "Gini 0.683 params {'num_leaves': 124, 'colsample_bytree': '0.775', 'feature_fraction': '0.369', 'min_child_samples': 90, 'learning_rate': '0.024', 'max_depth': 4, 'scale_pos_weight': '0.353', 'min_child_weight': '0.622', 'subsample_for_bin': 28760}\n",
      "Gini 0.720 params {'num_leaves': 60, 'colsample_bytree': '0.773', 'feature_fraction': '0.892', 'min_child_samples': 36, 'learning_rate': '0.048', 'max_depth': 4, 'scale_pos_weight': '0.945', 'min_child_weight': '0.205', 'subsample_for_bin': 35100}\n",
      "Gini 0.718 params {'num_leaves': 42, 'colsample_bytree': '0.948', 'feature_fraction': '0.897', 'min_child_samples': 92, 'learning_rate': '0.509', 'max_depth': 4, 'scale_pos_weight': '0.227', 'min_child_weight': '0.936', 'subsample_for_bin': 11910}\n",
      "Gini 0.733 params {'num_leaves': 52, 'colsample_bytree': '0.623', 'feature_fraction': '0.660', 'min_child_samples': 46, 'learning_rate': '0.204', 'max_depth': 4, 'scale_pos_weight': '0.430', 'min_child_weight': '0.301', 'subsample_for_bin': 9040}\n",
      "Gini 0.386 params {'num_leaves': 116, 'colsample_bytree': '0.305', 'feature_fraction': '0.771', 'min_child_samples': 34, 'learning_rate': '0.775', 'max_depth': 4, 'scale_pos_weight': '0.671', 'min_child_weight': '0.825', 'subsample_for_bin': 42120}\n",
      "Gini 0.728 params {'num_leaves': 42, 'colsample_bytree': '0.857', 'feature_fraction': '0.567', 'min_child_samples': 84, 'learning_rate': '0.244', 'max_depth': 4, 'scale_pos_weight': '0.938', 'min_child_weight': '0.087', 'subsample_for_bin': 21120}\n",
      "Gini 0.687 params {'num_leaves': 64, 'colsample_bytree': '0.822', 'feature_fraction': '0.907', 'min_child_samples': 92, 'learning_rate': '0.064', 'max_depth': 2, 'scale_pos_weight': '0.825', 'min_child_weight': '0.954', 'subsample_for_bin': 40410}\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:53<00:00, 17.38s/trial, best loss: 0.38576991734033717]\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    params = {\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "        'feature_fraction': '{:.3f}'.format(params['feature_fraction']),\n",
    "        'min_child_samples': int(params['min_child_samples']),        \n",
    "        'learning_rate' : '{:.3f}'.format(params['learning_rate']),\n",
    "        'max_depth' : int(params['max_depth']),\n",
    "        'scale_pos_weight': '{:.3f}'.format(params['scale_pos_weight']),\n",
    "        'min_child_weight': '{:.3f}'.format(params['min_child_weight']),\n",
    "        'subsample_for_bin':  int(params['subsample_for_bin'])\n",
    "    }\n",
    "    \n",
    "    clf = LGBMClassifier(\n",
    "        objective = 'binary',\n",
    "        metric = 'auc',\n",
    "        eval_metric = 'auc',\n",
    "        boosting_type= \"goss\",\n",
    "        \n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    score = cross_val_score(clf, x_train, y_train, scoring=gini_scorer, cv=StratifiedKFold()).mean()\n",
    "    print(\"Gini {:.3f} params {}\".format(score, params))\n",
    "    return score\n",
    "\n",
    "space = {\n",
    "    'num_leaves': hp.quniform('num_leaves', 8, 128, 2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.3, 1.0),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 8, 128, 2),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0,1),\n",
    "    'max_depth' :hp.quniform('max_depth', 1, 5, 2),\n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 0,1),\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 0,1),\n",
    "    'subsample_for_bin':  hp.quniform('subsample_for_bin', 100, 50000, 10)\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'colsample_bytree': 0.30462363080983534, 'feature_fraction': 0.77123971334186, 'learning_rate': 0.775422159445153, 'max_depth': 4.0, 'min_child_samples': 34.0, 'min_child_weight': 0.8253596822819328, 'num_leaves': 116.0, 'scale_pos_weight': 0.6708728256022322, 'subsample_for_bin': 42120.0}\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = LGBMClassifier(colsample_bytree= 0.6705459836183462, feature_fraction= 0.5243861441073344, \n",
    "                      learning_rate= 0.716932725777755, max_depth= 4, min_child_samples= 38, \n",
    "                      min_child_weight= 0.9388034294242809, num_leaves= 106, scale_pos_weight= 0.9616172899919058, \n",
    "                      subsample_for_bin= 390)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.6705459836183462,\n",
       "               feature_fraction=0.5243861441073344,\n",
       "               learning_rate=0.716932725777755, max_depth=4,\n",
       "               min_child_samples=38, min_child_weight=0.9388034294242809,\n",
       "               num_leaves=106, scale_pos_weight=0.9616172899919058,\n",
       "               subsample_for_bin=390)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.687796796175147\n",
      "Accuracy Score : 0.9682031796820318\n",
      "precision : 0.6025641025641025\n",
      "recall : 0.38524590163934425\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf2.fit(x_train,y_train)\n",
    "pred = clf2.predict(x_valid) \n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_valid, pred)\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, pred)\n",
    "\n",
    "print('AUC :',metrics.auc(fpr, tpr)) \n",
    "print('Accuracy Score :',accuracy_score(y_valid, pred)) \n",
    "print('precision :',precision[1]) \n",
    "print('recall :',recall[1]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fi=pd.DataFrame({'cols' : litraincolOrg, 'imp' : clf2.feature_importances_})\n",
    "fi = fi.sort_values('imp', ascending=False)\n",
    "top_50 = fi[0:10]\n",
    "top_50 = top_50.sort_values('imp', ascending=True)\n",
    "# Plot the bar chart\n",
    "top_50.plot(x='cols', kind='barh' , figsize=(7,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1023                C13_(-inf, 1.0]\n",
       "478            card5_(224.0, 226.0]\n",
       "9                      card6_credit\n",
       "966     TransactionAmt_(280.0, inf]\n",
       "2                       ProductCD_R\n",
       "                   ...             \n",
       "577                    V299_Missing\n",
       "578                    V151_Missing\n",
       "579               V151_(-inf, 25.3]\n",
       "580                V151_(25.3, inf]\n",
       "1205               V339_(50.0, inf]\n",
       "Name: cols, Length: 1206, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi['cols']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Bayesian HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | featur... | learni... | maxDepth  | minChi... | min_ch... | numLeaves | scale_... | subsam... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "0.8547662903207469\n",
      "|  1        |  0.8548   |  0.457    |  0.6052   |  0.1687   |  7.311    |  0.8496   |  25.28    |  4.246    |  0.1878   |  197.0    |\n",
      "0.8750434901251832\n",
      "|  2        |  0.875    |  0.8023   |  0.554    |  0.06783  |  9.132    |  0.8028   |  24.8     |  47.54    |  0.7506   |  2.073e+0 |\n",
      "0.6416737018339758\n",
      "|  3        |  0.6417   |  0.6369   |  0.6228   |  0.9659   |  5.458    |  0.5765   |  48.89    |  21.11    |  0.7512   |  256.9    |\n",
      "0.828182027492581\n",
      "|  4        |  0.8282   |  0.7907   |  0.2104   |  0.6248   |  6.133    |  0.4651   |  31.8     |  49.8     |  0.02709  |  36.9     |\n",
      "0.8627949085286126\n",
      "|  5        |  0.8628   |  0.6168   |  0.2437   |  0.2301   |  5.783    |  0.1777   |  35.89    |  48.15    |  0.4697   |  4.22e+03 |\n",
      "0.8103904446794237\n",
      "|  6        |  0.8104   |  0.1137   |  0.4389   |  0.6499   |  3.573    |  0.08236  |  41.13    |  48.56    |  0.3328   |  4.216e+0 |\n",
      "0.8210991063205648\n",
      "|  7        |  0.8211   |  0.5938   |  0.6132   |  0.8395   |  6.615    |  0.5771   |  25.96    |  55.22    |  0.03132  |  4.235e+0 |\n",
      "0.7417998374094668\n",
      "|  8        |  0.7418   |  0.5629   |  0.02037  |  0.7166   |  2.238    |  0.05405  |  7.966    |  12.59    |  0.8753   |  2.288e+0 |\n",
      "0.5738400501415561\n",
      "|  9        |  0.5738   |  0.3196   |  0.6025   |  0.8889   |  3.566    |  0.8208   |  18.69    |  45.14    |  0.6356   |  2.061e+0 |\n",
      "0.8698583586315107\n",
      "|  10       |  0.8699   |  0.8007   |  0.3359   |  0.06998  |  6.65     |  0.08121  |  23.3     |  55.36    |  0.2983   |  4.239e+0 |\n",
      "=====================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def lgb_evaluate(                \n",
    "                numLeaves,\n",
    "                maxDepth,\n",
    "                scale_pos_weight,\n",
    "                minChildWeight,\n",
    "                subsample_for_bin,\n",
    "                colsample_bytree,\n",
    "                learning_rate\n",
    "                ,min_child_samples, feature_fraction\n",
    "                ):\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(\n",
    "        objective = 'binary',\n",
    "        #metric= 'auc',\n",
    "        boosting_type = 'goss',\n",
    "        eval_metric= 'auc',\n",
    "        #reg_alpha= 0,\n",
    "        #reg_lambda= 2,\n",
    "        #bagging_fraction= 0.999,\n",
    "        #min_split_gain= 0,\n",
    "        #min_child_samples= 10,\n",
    "        #subsample_freq= 3,\n",
    "        #subsample_for_bin= 500,\n",
    "        #n_estimators= 9999999,\n",
    "        num_leaves= int(numLeaves),\n",
    "        max_depth= int(maxDepth),\n",
    "        scale_pos_weight= scale_pos_weight,\n",
    "        min_child_weight= minChildWeight,\n",
    "        subsample_for_bin= int(subsample_for_bin),\n",
    "        colsample_bytree= colsample_bytree,\n",
    "        learning_rate =learning_rate,\n",
    "        verbose =-1,\n",
    "        min_child_samples = int(min_child_samples),        feature_fraction = feature_fraction\n",
    "    )\n",
    "    \n",
    "    scores = cross_val_score(clf,x_train,y_train, cv=5, scoring='roc_auc')\n",
    "    print(np.mean(scores))\n",
    "\n",
    "    return np.mean(scores)\n",
    "   \n",
    "def bayesOpt(X, y):\n",
    "    lgbBO = BayesianOptimization(lgb_evaluate, {                                                \n",
    "                                                'numLeaves':  (2 ,128),\n",
    "                                                'maxDepth': (2, 10),\n",
    "                                                'scale_pos_weight': (0,1),\n",
    "                                                'minChildWeight': (0, 1),\n",
    "                                                'subsample_for_bin': (10,5000),\n",
    "                                                'colsample_bytree': (0,1),\n",
    "                                                'learning_rate' :(0,1),\n",
    "                                                 'min_child_samples': (2,50),\n",
    "                                                 'feature_fraction':(0, 1)\n",
    "        \n",
    "                                                \n",
    "                                            })\n",
    "\n",
    "\n",
    "    lgbBO.maximize(init_points=5, n_iter=5)\n",
    "\n",
    "    #print(lgbBO.res['max'])\n",
    "    \n",
    "\n",
    "bayesOpt(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = LGBMClassifier(colsample_bytree= 0.6915, feature_fraction=0.4943 , \n",
    "                      learning_rate= 0.3064 , max_depth= 6 , min_child_samples= 44  , \n",
    "                      min_child_weight= 0.8296  , num_leaves= 19, scale_pos_weight=  0.4535 , \n",
    "                      subsample_for_bin= 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsam... | featur... | learni... | maxDepth  | minChi... | min_ch... | numLeaves | scale_... | subsam... |\n",
    "0.6915   |  0.4943   |  0.3064   |  6.379    |  0.8296   |  44.5     |  19.06    |  0.4535   |  1.711e+0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.6557026834656209\n",
      "Accuracy Score : 0.9722027797220278\n",
      "precision : 0.8098591549295775\n",
      "recall : 0.31420765027322406\n"
     ]
    }
   ],
   "source": [
    "clf3.fit(x_train,y_train)\n",
    "pred3 = clf3.predict(x_valid) \n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_valid, pred3)\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, pred3)\n",
    "\n",
    "print('AUC :',metrics.auc(fpr, tpr)) \n",
    "print('Accuracy Score :',accuracy_score(y_valid, pred3)) \n",
    "print('precision :',precision[1]) \n",
    "print('recall :',recall[1]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fi=pd.DataFrame({'cols' : litraincolOrg, 'imp' : clf3.feature_importances_})\n",
    "fi = fi.sort_values('imp', ascending=False)\n",
    "top_50 = fi[0:10]\n",
    "top_50 = top_50.sort_values('imp', ascending=True)\n",
    "# Plot the bar chart\n",
    "top_50.plot(x='cols', kind='barh' , figsize=(7,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478     card5_(224.0, 226.0]\n",
       "9               card6_credit\n",
       "1016         C11_(-inf, 1.0]\n",
       "982           C1_(-inf, 1.0]\n",
       "476     card5_(195.0, 224.0]\n",
       "                ...         \n",
       "586          V228_(2.0, inf]\n",
       "587             V201_Missing\n",
       "589          V201_(1.0, 2.0]\n",
       "590          V201_(2.0, inf]\n",
       "1205        V339_(50.0, inf]\n",
       "Name: cols, Length: 1206, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi['cols']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid and Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "dtrain = lgbm.Dataset(x_train, label=y_train)\n",
    "dval = lgbm.Dataset(x_valid, label=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(objective='binary')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "clf_LGBM = lgbm.LGBMClassifier(objective='binary')\n",
    "clf_LGBM.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    #'n_estimators': [500, 600],\n",
    "    'colsample_bytree': [ 0,1],\n",
    "    'learning_rate': [0,1],\n",
    "    'max_depth': [15,20,25],\n",
    "    'num_leaves': [50, 100, 200],\n",
    "    'subsample': [0.7, 0.8, 0.9, ],\n",
    "    'min_child_samples': [2,50],\n",
    "    'scale_pos_weight': [0,1],\n",
    "    'minChildWeight': [0, 1],\n",
    "    'feature_fraction':[0, 1]                \n",
    "}\n",
    "clf_LGBM = lgbm.LGBMClassifier(objective='binary',is_unbalance= True,\n",
    "        boosting_type = 'goss',\n",
    "        eval_metric= 'auc')\n",
    "\n",
    "\n",
    "\n",
    "grid_search_lgbm= GridSearchCV(estimator = clf_LGBM, param_grid = param_grid,\n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1728 candidates, totalling 5184 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed: 18.2min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-d90b1a294425>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit the grid search to the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgrid_search_lgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgrid_search_lgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the grid search to the data \n",
    "grid_search_lgbm.fit(x_train, y_train)\n",
    "grid_search_lgbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.6414077584168256\n",
      "Accuracy Score : 0.5497450254974503\n",
      "precision : 0.05482972799314628\n",
      "recall : 0.7398843930635838\n"
     ]
    }
   ],
   "source": [
    "pred4 = grid_search_lgbm.predict(x_valid) \n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_valid, pred4)\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, pred4)\n",
    "\n",
    "print('AUC :',metrics.auc(fpr, tpr)) \n",
    "print('Accuracy Score :',accuracy_score(y_valid, pred4)) \n",
    "print('precision :',precision[1]) \n",
    "print('recall :',recall[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='goss', colsample_bytree=0, eval_metric='auc',\n",
       "               feature_fraction=1, learning_rate=1, max_depth=15,\n",
       "               min_child_samples=50, min_child_weight=0, num_leaves=50,\n",
       "               objective='binary', scale_pos_weight=1, subsample=0.7)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5 = LGBMClassifier(colsample_bytree= 0, feature_fraction=1 , \n",
    "                      learning_rate= 1 , max_depth= 15 , min_child_samples= 50  , \n",
    "                      min_child_weight= 0  , num_leaves= 50, scale_pos_weight=  1 , \n",
    "                      subsample= .7,objective='binary',\n",
    "        boosting_type = 'goss',\n",
    "        eval_metric= 'auc')\n",
    "clf5.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fi=pd.DataFrame({'cols' : litraincolOrg, 'imp' : clf5.feature_importances_ })\n",
    "fi = fi.sort_values('imp', ascending=False)\n",
    "top_50 = fi[0:10]\n",
    "top_50 = top_50.sort_values('imp', ascending=True)\n",
    "# Plot the bar chart\n",
    "top_50.plot(x='cols', kind='barh' , figsize=(7,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14                         M6_F\n",
       "984     P_emaildomain_gmail.com\n",
       "474        card5_(224.0, 226.0]\n",
       "1114         D15_(242.0, 381.0]\n",
       "15                         M6_T\n",
       "                 ...           \n",
       "431                    V23_Rare\n",
       "815                V273_Missing\n",
       "447                    V300_0.0\n",
       "812                V128_Missing\n",
       "609                V180_Missing\n",
       "Name: cols, Length: 1219, dtype: object"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi['cols']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.9,\n",
       " 'scale_pos_weight': 1,\n",
       " 'num_leaves': 200,\n",
       " 'min_child_samples': 2,\n",
       " 'minChildWeight': 1,\n",
       " 'max_depth': 25,\n",
       " 'learning_rate': 0.6,\n",
       " 'feature_fraction': 0.7,\n",
       " 'colsample_bytree': 1}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid1= {\n",
    "    'colsample_bytree': [ 0,1],\n",
    "    'learning_rate': [0.6,0.7, 0.8, 0.9],\n",
    "    'max_depth': [10,15,20,25],\n",
    "    'num_leaves': [50, 100, 200],\n",
    "    'subsample': [0.6,0.7, 0.8, 0.9 ],\n",
    "    'min_child_samples': [2,50],\n",
    "    'scale_pos_weight': [0,1],\n",
    "    'minChildWeight': [0, 1],\n",
    "    'feature_fraction':[0.6,0.7, 0.8, 0.9] \n",
    "  \n",
    "    \n",
    "}\n",
    "clf_LGBM1 = lgbm.LGBMClassifier(objective='binary',is_unbalance= True)\n",
    "\n",
    "\n",
    "Random_search_lgbm= RandomizedSearchCV(estimator = clf_LGBM1,  param_distributions= param_grid1, n_iter = 10,\n",
    "                          cv = 3, n_jobs = -1, verbose = 2, random_state=100 )\n",
    "\n",
    "\n",
    "# Fit the grid search to the data \n",
    "Random_search_lgbm.fit(x_train, y_train)\n",
    "Random_search_lgbm.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_lgbm1 = Random_search_lgbm.best_estimator_\n",
    "\n",
    "\n",
    "y_pred_train_random_rf1= Random_search_lgbm.predict(x_train)\n",
    "y_pred_grid_random_rf1= Random_search_lgbm.predict(x_valid)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "\n",
    "print(\"Train Accuracy:\",metrics.accuracy_score(y_train, y_pred_train_random_rf1)) \n",
    "\n",
    "print(\"Valid Accuracy:\",metrics.accuracy_score(y_valid, y_pred_grid_random_rf1))  \n",
    "print(classification_report(y_valid, y_pred_grid_valid_rf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.6797472333062926\n",
      "Accuracy Score : 0.6614338566143385\n",
      "precision : 0.06867196367763904\n",
      "recall : 0.6994219653179191\n"
     ]
    }
   ],
   "source": [
    "pred5 = Random_search_lgbm.predict(x_valid) \n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_valid, pred5)\n",
    "precision, recall, thresholds = precision_recall_curve(y_valid, pred5)\n",
    "\n",
    "print('AUC :',metrics.auc(fpr, tpr)) \n",
    "print('Accuracy Score :',accuracy_score(y_valid, pred5)) \n",
    "print('precision :',precision[1]) \n",
    "print('recall :',recall[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='goss', colsample_bytree=1, eval_metric='auc',\n",
       "               feature_fraction=0.7, learning_rate=0.6, max_depth=25,\n",
       "               min_child_samples=2, min_child_weight=1, num_leaves=200,\n",
       "               objective='binary', scale_pos_weight=1, subsample=0.9)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6 = LGBMClassifier(colsample_bytree= 1, feature_fraction=.7 , \n",
    "                      learning_rate= .6 , max_depth= 25 , min_child_samples= 2, \n",
    "                      min_child_weight= 1  , num_leaves= 200, scale_pos_weight=  1 , \n",
    "                      subsample= 0.9,objective='binary',\n",
    "        boosting_type = 'goss',\n",
    "        eval_metric= 'auc')\n",
    "clf6.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fi=pd.DataFrame({'cols' : litraincolOrg, 'imp' : clf6.feature_importances_ })\n",
    "fi = fi.sort_values('imp', ascending=False)\n",
    "top_50 = fi[0:10]\n",
    "top_50 = top_50.sort_values('imp', ascending=True)\n",
    "# Plot the bar chart\n",
    "top_50.plot(x='cols', kind='barh' , figsize=(7,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "984    P_emaildomain_gmail.com\n",
       "474       card5_(224.0, 226.0]\n",
       "8                  card6_debit\n",
       "5                   card4_visa\n",
       "472       card5_(126.0, 166.0]\n",
       "                ...           \n",
       "910               V186_Missing\n",
       "614           V253_(-inf, inf]\n",
       "615               V253_Missing\n",
       "907               V183_Missing\n",
       "609               V180_Missing\n",
       "Name: cols, Length: 1219, dtype: object"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi['cols']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MultiThreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cpu :  4\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from itertools import repeat\n",
    "from multiprocessing import Process, Manager\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "num_processes = mp.cpu_count()\n",
    "\n",
    "print(\"Number of cpu : \", num_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID of main process: 3132\n",
      "ID of process p1: 9648\n",
      "ID of process p2: 7376\n",
      "Both processes finished execution!\n",
      "Process p1 is alive: False\n",
      "Process p2 is alive: False\n"
     ]
    }
   ],
   "source": [
    "# importing the multiprocessing module \n",
    "import multiprocessing \n",
    "import os \n",
    "\n",
    "def worker1(): \n",
    "\t# printing process id \n",
    "\tprint(\"ID of process running worker1: {}\".format(os.getpid())) \n",
    "\n",
    "def worker2(): \n",
    "\t# printing process id \n",
    "\tprint(\"ID of process running worker2: {}\".format(os.getpid())) \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "\t# printing main program process id \n",
    "\tprint(\"ID of main process: {}\".format(os.getpid())) \n",
    "\n",
    "\t# creating processes \n",
    "\tp1 = multiprocessing.Process(target=worker1) \n",
    "\tp2 = multiprocessing.Process(target=worker2) \n",
    "\n",
    "\t# starting processes \n",
    "\tp1.start() \n",
    "\tp2.start() \n",
    "\n",
    "\t# process IDs \n",
    "\tprint(\"ID of process p1: {}\".format(p1.pid)) \n",
    "\tprint(\"ID of process p2: {}\".format(p2.pid)) \n",
    "\n",
    "\t# wait until processes are finished \n",
    "\tp1.join() \n",
    "\tp2.join() \n",
    "\n",
    "\t# both processes finished \n",
    "\tprint(\"Both processes finished execution!\") \n",
    "\n",
    "\t# check if processes are alive \n",
    "\tprint(\"Process p1 is alive: {}\".format(p1.is_alive())) \n",
    "\tprint(\"Process p2 is alive: {}\".format(p2.is_alive())) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def func1():\n",
    "    print('func1: starting') \n",
    "    for i in xrange(10000000): pass\n",
    "    print('func1: finishing')  #'func1: '\n",
    "    \n",
    "def func2():\n",
    "    print('func2: starting')\n",
    "    for i in xrange(10000000): pass\n",
    "    print('func2: finishing')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p1 = Process(target=func1)\n",
    "    p1.start()\n",
    "    p2 = Process(target=func2)\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runInParallel(*fns):\n",
    "    proc = []\n",
    "    for fn in fns:        \n",
    "        p = Process(target=fn)\n",
    "        p.start()\n",
    "        proc.append(p)\n",
    "    for p in proc:\n",
    "        p.join()\n",
    "\n",
    "runInParallel(func1, func2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'LGBMClassifier' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-187-5fc0c8ad1f54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mrunning_task\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mrun_io_tasks_in_parallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mli_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-187-5fc0c8ad1f54>\u001b[0m in \u001b[0;36mrun_io_tasks_in_parallel\u001b[1;34m(tasks)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mrunning_tasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtasks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrunning_task\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrunning_tasks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mrunning_task\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mrun_io_tasks_in_parallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mli_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda4\\lib\\concurrent\\futures\\thread.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'LGBMClassifier' object is not callable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\Anaconda4\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\user\\Anaconda4\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\user\\Anaconda4\\lib\\multiprocessing\\pool.py\", line 513, in _handle_workers\n",
      "    cls._maintain_pool(ctx, Process, processes, pool, inqueue,\n",
      "  File \"C:\\Users\\user\\Anaconda4\\lib\\multiprocessing\\pool.py\", line 337, in _maintain_pool\n",
      "    Pool._repopulate_pool_static(ctx, Process, processes, pool,\n",
      "  File \"C:\\Users\\user\\Anaconda4\\lib\\multiprocessing\\pool.py\", line 326, in _repopulate_pool_static\n",
      "    w.start()\n",
      "  File \"C:\\Users\\user\\Anaconda4\\lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"C:\\Users\\user\\Anaconda4\\lib\\multiprocessing\\context.py\", line 326, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"C:\\Users\\user\\Anaconda4\\lib\\multiprocessing\\popen_spawn_win32.py\", line 93, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"C:\\Users\\user\\Anaconda4\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "  File \"C:\\Users\\user\\Anaconda4\\lib\\multiprocessing\\synchronize.py\", line 104, in __getstate__\n",
      "    h = context.get_spawning_popen().duplicate_for_child(sl.handle)\n",
      "  File \"C:\\Users\\user\\Anaconda4\\lib\\multiprocessing\\popen_spawn_win32.py\", line 99, in duplicate_for_child\n",
      "    return reduction.duplicate(handle, self.sentinel)\n",
      "  File \"C:\\Users\\user\\Anaconda4\\lib\\multiprocessing\\reduction.py\", line 79, in duplicate\n",
      "    return _winapi.DuplicateHandle(\n",
      "PermissionError: [WinError 5] Access is denied\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def run_io_tasks_in_parallel(tasks):\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        running_tasks = [executor.submit(task) for task in tasks]\n",
    "        for running_task in running_tasks:\n",
    "            running_task.result()\n",
    "\n",
    "run_io_tasks_in_parallel(li_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_model=[]\n",
    "model_names = [clf_LGBM,clf3,clf5]\n",
    "for clf in model_names:\n",
    "    li_model.append(clf.fit(x_train,y_train))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unordered results:\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "from multiprocessing import Process, Queue, current_process, freeze_support\n",
    "\n",
    "#\n",
    "# Function run by worker processes\n",
    "#\n",
    "\n",
    "def worker(input, output):\n",
    "    for func, args in iter(input.get, 'STOP'):\n",
    "        result = calculate(func, args)\n",
    "        output.put(result)\n",
    "\n",
    "#\n",
    "# Function used to calculate result\n",
    "#\n",
    "\n",
    "def calculate(func, args):\n",
    "    result = func(*args)\n",
    "    return '%s says that %s%s = %s' % \\\n",
    "        (current_process().name, func.__name__, args, result)\n",
    "\n",
    "#\n",
    "# Functions referenced by tasks\n",
    "#\n",
    "\n",
    "def mul(a, b):\n",
    "    time.sleep(0.5*random.random())\n",
    "    return a * b\n",
    "\n",
    "def plus(a, b):\n",
    "    time.sleep(0.5*random.random())\n",
    "    return a + b\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "def test():\n",
    "    NUMBER_OF_PROCESSES = 4\n",
    "    TASKS1 = [(mul, (i, 7)) for i in range(20)]\n",
    "    TASKS2 = [(plus, (i, 8)) for i in range(10)]\n",
    "\n",
    "    # Create queues\n",
    "    task_queue = Queue()\n",
    "    done_queue = Queue()\n",
    "\n",
    "    # Submit tasks\n",
    "    for task in TASKS1:\n",
    "        task_queue.put(task)\n",
    "\n",
    "    # Start worker processes\n",
    "    for i in range(NUMBER_OF_PROCESSES):\n",
    "        Process(target=worker, args=(task_queue, done_queue)).start()\n",
    "\n",
    "    # Get and print results\n",
    "    print('Unordered results:')\n",
    "    for i in range(len(TASKS1)):\n",
    "        print('\\t', done_queue.get())\n",
    "\n",
    "    # Add more tasks using `put()`\n",
    "    for task in TASKS2:\n",
    "        task_queue.put(task)\n",
    "\n",
    "    # Get and print some more results\n",
    "    for i in range(len(TASKS2)):\n",
    "        print('\\t', done_queue.get())\n",
    "\n",
    "    # Tell child processes to stop\n",
    "    for i in range(NUMBER_OF_PROCESSES):\n",
    "        task_queue.put('STOP')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    freeze_support()\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df = pd.read_csv('employee.csv',low_memory=False)\n",
    "data_df = pd.read_csv('data.csv',low_memory=False)\n",
    "\n",
    "data_df['date']= pd.to_datetime(data_df['date']) \n",
    "\n",
    "print(employee_df.head())\n",
    "print(data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['clf_LGBM','clf3','clf5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {}\n",
    "for index,row in employee_df.iterrows():\n",
    "    name_dict[row['ecode']] = row['ename']\n",
    "\n",
    "empcodes= []\n",
    "empcodes.extend(list(data_df['employee_code'].unique()))\n",
    "\n",
    "    \n",
    "print(name_dict)\n",
    "print(empcodes[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_partitions = num_processes\n",
    "manager = Manager()\n",
    "d = manager.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = np.array_split(model_names, num_partitions)\n",
    "pool = Pool(num_processes)\n",
    "shared_arg = repeat(d,num_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for _ in tqdm.tqdm(pool.map(process_rows, zip(shared_arg,df_split)), total=num_partitions):\n",
    "    pass\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_rows(model_names,):\n",
    "    d = data[0]\n",
    "    df = data[1]\n",
    "    for index,row in df.iterrows():\n",
    "        ecode = int(row['employee_code'])\n",
    "        month = int(row['date'].month)\n",
    "        efficiency = int(row['efficiency'])\n",
    "        if (ecode,month) in list(d.keys()):\n",
    "            d[ecode,month] = (efficiency + d[ecode,month]) / 2\n",
    "        else:\n",
    "            d[ecode,month] = efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "months = []\n",
    "for i in range(1,13):\n",
    "    month = datetime.date(1900,i, 1).strftime('%B')\n",
    "    months.append(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "data = []\n",
    "for ecode in empcodes:\n",
    "    y_list = []\n",
    "    for i in range(1,13):\n",
    "        y_list.append(d[int(ecode),i])\n",
    "    data.append(go.Scatter(\n",
    "    x=months,\n",
    "    y=list(y_list),\n",
    "    name = name_dict[str(ecode)]\n",
    "    ))\n",
    "layout = go.Layout(\n",
    "    title='Employee Analysis',\n",
    "    xaxis=dict(title='Months in 2018',),\n",
    "    yaxis=dict(title='Average Production Efficieny per month',)\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "plot(fig, filename='Employee-Efficiency.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
